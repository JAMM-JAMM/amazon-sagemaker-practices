{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56775c9",
   "metadata": {},
   "source": [
    "### Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2591ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d82d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import psycopg2\n",
    "import base64\n",
    "import json\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import sagemaker\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, FloatSlider, Checkbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a46f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00e0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebfd2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 bucket:  sagemaker-ap-northeast-2-988889742134\n"
     ]
    }
   ],
   "source": [
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "print(\"s3 bucket: \", s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae54b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 prefix:  sagemaker/redshift-deepar-nyctaxi-demo-notebook\n"
     ]
    }
   ],
   "source": [
    "s3_prefix = 'sagemaker/redshift-deepar-nyctaxi-demo-notebook'\n",
    "print(\"s3 prefix: \", s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7080058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region name:  ap-northeast-2\n"
     ]
    }
   ],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "print(\"region name: \", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1484978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 input data path:  s3://sagemaker-ap-northeast-2-988889742134/sagemaker/redshift-deepar-nyctaxi-demo-notebook/data\n",
      "s3 output data path:  s3://sagemaker-ap-northeast-2-988889742134/sagemaker/redshift-deepar-nyctaxi-demo-notebook/output\n"
     ]
    }
   ],
   "source": [
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)\n",
    "print(\"s3 input data path: \", s3_data_path)\n",
    "print(\"s3 output data path: \", s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867b7e9",
   "metadata": {},
   "source": [
    "### Docker ECR Image URI - forcasting-deepar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd709917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d546213",
   "metadata": {},
   "source": [
    "### Redshift - Secretsmanager info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5dff066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_info(secret_name):\n",
    "    \n",
    "    session = boto3.session.Session()\n",
    "    secret_manager_client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        get_secret_value_response = secret_manager_client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS key.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            secret = json.loads(get_secret_value_response['SecretString'])\n",
    "        else:\n",
    "            secret = json.loads(base64.b64decode(get_secret_value_response['SecretBinary']))\n",
    "    \n",
    "    return secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9446d665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection info:  {'password': ':F3(ibLq9o[.:3CL', 'username': 'master', 'host': 'redshiftcluster-e6qymib7pem4.ctcezicvfjwc.ap-northeast-2.redshift.amazonaws.com', 'port': '8192', 'engine': 'redshift', 'dbClusterIdentifier': 'redshiftcluster-e6qymib7pem4'}\n"
     ]
    }
   ],
   "source": [
    "con_params = connection_info(secret_name)\n",
    "\n",
    "print(\"Connection info: \", con_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe27be9",
   "metadata": {},
   "source": [
    "### Redshift cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fa2a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(db_name, secret_name):\n",
    "    \n",
    "    con_params = connection_info(secret_name)\n",
    "#     print(\"Connection parameters: \", con_params)\n",
    "    print(\"Connection info retrieved from Secrets manager\")\n",
    "    \n",
    "    rsf_conn = psycopg2.connect(\n",
    "                dbname=db_name,\n",
    "                host=con_params['host'],\n",
    "                port=con_params['port'],\n",
    "                user=con_params['username'],\n",
    "                password=con_params['password']\n",
    "            )\n",
    "    \n",
    "    return rsf_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04ddcb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection info retrieved from Secrets manager\n"
     ]
    }
   ],
   "source": [
    "db_name = 'nyctaxi'\n",
    "secret_name = 'arn:aws:secretsmanager:ap-northeast-2:988889742134:secret:nyctaxisecret-7MXnAI'\n",
    "\n",
    "conn = get_connection(db_name, secret_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2296a9",
   "metadata": {},
   "source": [
    "### Redshift Query Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0881bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_query_execution(db_name, secret_name, sql):\n",
    "    \n",
    "    conn = get_connection(db_name=db_name, secret_name=secret_name)\n",
    "    cur = None\n",
    "    \n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        res = cur.execute(sql)\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5d7fb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection info retrieved from Secrets manager\n",
      "Result:  None\n"
     ]
    }
   ],
   "source": [
    "secret_name = 'arn:aws:secretsmanager:ap-northeast-2:988889742134:secret:nyctaxisecret-7MXnAI'\n",
    "timeout_statement = \"set statement_timeout = 1200000\"\n",
    "db_name = 'nyctaxi'\n",
    "\n",
    "result = get_redshift_query_execution(db_name=db_name, secret_name=secret_name, sql=timeout_statement)\n",
    "print(\"Result: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb5f9b",
   "metadata": {},
   "source": [
    "### Run sql start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5040bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_unload_path = s3_output_path + '/unload/'\n",
    "redshift_iam_role = \"arn:aws:iam::988889742134:role/Redshift-Analytics-Lab-RedshiftRole-1FKF6QKB14C58\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02a228f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "query_str = \"unload('select coalesce(v1.pickup_timestamp_norm, v2.pickup_timestamp_norm) as pickup_timestamp_norm \\\n",
    ", coalesce(v1.vendor_1, 0) as vendor_1 \\\n",
    ", coalesce(v2.vendor_2, 0) as vendor_2 \\\n",
    "from \\\n",
    "(select case when extract(minute from lpep_dropoff_datetime) between 0 and 14 then dateadd(minute, 0, date_trunc(''hour'', lpep_dropoff_datetime)) \\\n",
    "when extract(minute from lpep_dropoff_datetime) between 15 and 29 then dateadd(minute, 15, date_trunc(''hour'', lpep_dropoff_datetime)) \\\n",
    "when extract(minute from lpep_dropoff_datetime) between 30 and 44 then dateadd(minute, 30, date_trunc(''hour'', lpep_dropoff_datetime)) \\\n",
    "when extract(minute from lpep_dropoff_datetime) between 45 and 59 then dateadd(minute, 45, date_trunc(''hour'', lpep_dropoff_datetime)) end as pickup_timestamp_norm \\\n",
    ", count(1) as vendor_1 \\\n",
    "from taxischema.nyc_greentaxi \\\n",
    "where vendorid = 1 group by 1) v1 \\\n",
    "full outer join \\\n",
    "(select case when extract(minute from lpep_dropoff_datetime) between 0 and 14 then dateadd(minute, 0, date_trunc(''hour'', lpep_dropoff_datetime)) \\\n",
    "when extract(minute from lpep_dropoff_datetime) between 15 and 29 then dateadd(minute, 15, date_trunc(''hour'', lpep_dropoff_datetime)) \\\n",
    "when extract(minute from lpep_dropoff_datetime) between 30 and 44 then dateadd(minute, 30, date_trunc(''hour'', lpep_dropoff_datetime)) \\\n",
    "when extract(minute from lpep_dropoff_datetime) between 45 and 59 then dateadd(minute, 45, date_trunc(''hour'', lpep_dropoff_datetime)) end as pickup_timestamp_norm \\\n",
    ", count(1)  as vendor_2 \\\n",
    "from taxischema.nyc_greentaxi \\\n",
    "where vendorid = 2 group by 1) v2 on v1.pickup_timestamp_norm = v2.pickup_timestamp_norm order by pickup_timestamp_norm ;') to '\" \\\n",
    "+ redshift_unload_path + \"' iam_role '\" + redshift_iam_role + \"' format as CSV header ALLOWOVERWRITE GZIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66adc692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query string: \n",
      " unload('select coalesce(v1.pickup_timestamp_norm, v2.pickup_timestamp_norm) as pickup_timestamp_norm , coalesce(v1.vendor_1, 0) as vendor_1 , coalesce(v2.vendor_2, 0) as vendor_2 from (select case when extract(minute from lpep_dropoff_datetime) between 0 and 14 then dateadd(minute, 0, date_trunc(''hour'', lpep_dropoff_datetime)) when extract(minute from lpep_dropoff_datetime) between 15 and 29 then dateadd(minute, 15, date_trunc(''hour'', lpep_dropoff_datetime)) when extract(minute from lpep_dropoff_datetime) between 30 and 44 then dateadd(minute, 30, date_trunc(''hour'', lpep_dropoff_datetime)) when extract(minute from lpep_dropoff_datetime) between 45 and 59 then dateadd(minute, 45, date_trunc(''hour'', lpep_dropoff_datetime)) end as pickup_timestamp_norm , count(1) as vendor_1 from taxischema.nyc_greentaxi where vendorid = 1 group by 1) v1 full outer join (select case when extract(minute from lpep_dropoff_datetime) between 0 and 14 then dateadd(minute, 0, date_trunc(''hour'', lpep_dropoff_datetime)) when extract(minute from lpep_dropoff_datetime) between 15 and 29 then dateadd(minute, 15, date_trunc(''hour'', lpep_dropoff_datetime)) when extract(minute from lpep_dropoff_datetime) between 30 and 44 then dateadd(minute, 30, date_trunc(''hour'', lpep_dropoff_datetime)) when extract(minute from lpep_dropoff_datetime) between 45 and 59 then dateadd(minute, 45, date_trunc(''hour'', lpep_dropoff_datetime)) end as pickup_timestamp_norm , count(1)  as vendor_2 from taxischema.nyc_greentaxi where vendorid = 2 group by 1) v2 on v1.pickup_timestamp_norm = v2.pickup_timestamp_norm order by pickup_timestamp_norm ;') to 's3://sagemaker-ap-northeast-2-988889742134/sagemaker/redshift-deepar-nyctaxi-demo-notebook/output/unload/' iam_role 'arn:aws:iam::988889742134:role/Redshift-Analytics-Lab-RedshiftRole-1FKF6QKB14C58' format as CSV header ALLOWOVERWRITE GZIP\n"
     ]
    }
   ],
   "source": [
    "print(\"Query string: \\n\", query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1aa8b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection info retrieved from Secrets manager\n"
     ]
    }
   ],
   "source": [
    "query_result = get_redshift_query_execution(db_name=db_name, secret_name=secret_name, sql=query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40a52dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Result:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"Query Result: \", query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf375d",
   "metadata": {},
   "source": [
    "### Load dataframe from s3 .gzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f46ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def load_df_from_s3(s3_path):\n",
    "    \n",
    "    assert s3_path.startswith('s3://')\n",
    "    \n",
    "    s3_path_split_list = s3_path.split('/')\n",
    "    print(\"s3 path split list: \", s3_path_split_list)\n",
    "    \n",
    "    bucket_nm = s3_path_split_list[2]\n",
    "    print(\"s3 path bucket name: \", bucket_nm)\n",
    "    \n",
    "    bucket_prefix = '/'.join(s3_path_split_list[3:])\n",
    "    print(\"s3 path prefix name: \", bucket_prefix)\n",
    "    \n",
    "    datafiles = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_nm,\n",
    "        Prefix=bucket_prefix\n",
    "    )['Contents']\n",
    "    \n",
    "    prefix_df = []\n",
    "    \n",
    "    s3_fs = s3fs.S3FileSystem()\n",
    "    \n",
    "    for file in datafiles[0:]:\n",
    "        file_path = file['Key']\n",
    "        \n",
    "        with s3_fs.open('s3://' + bucket_nm + '/' + file_path) as f:\n",
    "            df = pd.read_csv(\n",
    "                f,\n",
    "                compression='gzip',\n",
    "                index_col=0,\n",
    "                parse_dates=True,\n",
    "                decimal=',',\n",
    "                sep=','\n",
    "            )\n",
    "            \n",
    "            prefix_df.append(df)\n",
    "            print(f\"File retrieved {file_path}\")\n",
    "            \n",
    "    return pd.concat(prefix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af5ebb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 path split list:  ['s3:', '', 'sagemaker-ap-northeast-2-988889742134', 'sagemaker', 'redshift-deepar-nyctaxi-demo-notebook', 'output', 'unload', '']\n",
      "s3 path bucket name:  sagemaker-ap-northeast-2-988889742134\n",
      "s3 path prefix name:  sagemaker/redshift-deepar-nyctaxi-demo-notebook/output/unload/\n",
      "File retrieved sagemaker/redshift-deepar-nyctaxi-demo-notebook/output/unload/0000_part_00.gz\n",
      "File retrieved sagemaker/redshift-deepar-nyctaxi-demo-notebook/output/unload/0001_part_00.gz\n",
      "File retrieved sagemaker/redshift-deepar-nyctaxi-demo-notebook/output/unload/0002_part_00.gz\n",
      "File retrieved sagemaker/redshift-deepar-nyctaxi-demo-notebook/output/unload/0003_part_00.gz\n"
     ]
    }
   ],
   "source": [
    "pd_df = load_df_from_s3(redshift_unload_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55253b",
   "metadata": {},
   "source": [
    "### Visualization dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1ada15cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17506, 2)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2151dbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_1</th>\n",
       "      <th>vendor_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_timestamp_norm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:45:00</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:15:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       vendor_1  vendor_2\n",
       "pickup_timestamp_norm                    \n",
       "2009-01-01 00:00:00           0         1\n",
       "2009-01-01 00:30:00           0         6\n",
       "2009-01-01 00:45:00           0         6\n",
       "2009-01-01 01:00:00           0         4\n",
       "2009-01-01 02:15:00           0         2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a2bbd372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timeseries:  2\n"
     ]
    }
   ],
   "source": [
    "num_timeseries = pd_df.shape[1]\n",
    "print('Num timeseries: ', num_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c6c07bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trip = pd_df.resample('2H').sum() / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "71326e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(\n",
    "        np.trim_zeros(\n",
    "            data_trip.iloc[:,i],\n",
    "            trim='f'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1d9061ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_timestamp_norm\n",
       "2018-09-13 12:00:00    0.125\n",
       "2018-09-13 14:00:00    0.000\n",
       "2018-09-13 16:00:00    0.000\n",
       "2018-09-13 18:00:00    0.000\n",
       "2018-09-13 20:00:00    0.000\n",
       "                       ...  \n",
       "2019-07-01 14:00:00    0.000\n",
       "2019-07-01 16:00:00    0.000\n",
       "2019-07-01 18:00:00    0.000\n",
       "2019-07-01 20:00:00    0.000\n",
       "2019-07-01 22:00:00    0.000\n",
       "Freq: 2H, Name: vendor_1, Length: 3498, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bcd24cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_timestamp_norm\n",
       "2008-12-31 22:00:00    0.750\n",
       "2009-01-01 00:00:00    4.125\n",
       "2009-01-01 02:00:00    0.625\n",
       "2009-01-01 04:00:00    0.125\n",
       "2009-01-01 06:00:00    0.000\n",
       "                       ...  \n",
       "2019-07-01 14:00:00    1.000\n",
       "2019-07-01 16:00:00    1.125\n",
       "2019-07-01 18:00:00    1.000\n",
       "2019-07-01 20:00:00    1.000\n",
       "2019-07-01 22:00:00    0.500\n",
       "Freq: 2H, Name: vendor_2, Length: 46009, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b0d381fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 2), sharex=True)\n",
    "axx = axs.ravel()\n",
    "for i in range(0, 2):\n",
    "    timeseries[i].loc[\"2018-10-01\":\"2019-12-31\"].plot(ax=axx[i])\n",
    "    axx[i].set_xlabel(\"date\")\n",
    "    axx[i].set_ylabel(\"Ride count\")\n",
    "    axx[i].grid(which='minor', axis='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "27d4d1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 2), sharex=True)\n",
    "axx = axs.ravel()\n",
    "for i in range(0, 2):\n",
    "    timeseries[i].loc[\"2019-01-01\":\"2019-08-01\"].plot(ax=axx[i])\n",
    "    axx[i].set_xlabel(\"date\")\n",
    "    axx[i].set_ylabel(\"Ride count\")\n",
    "    axx[i].grid(which='minor', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b8bdc",
   "metadata": {},
   "source": [
    "### Train and Test splits\n",
    "\n",
    "Often times one is interested in evaluating the model or tuning its hyperparameters by looking at error metrics on a hold-out test set. Here we split the available data into train and test sets for evaluating the trained model. For standard machine learning tasks such as classification and regression, one typically obtains this split by randomly separating examples into train and test sets. However, in forecasting it is important to do this train/test split based on time rather than by time series.\n",
    "\n",
    "In this example, we will reserve the last section of each of the time series for evalutation purpose and use only the first part as training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3b54dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 2 hour frequency for the time series\n",
    "freq = '2H'\n",
    "\n",
    "# we predict for 7 days\n",
    "prediction_length = 7 * 12\n",
    "\n",
    "# we also use 7 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 7 * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "be297a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we specify here the portion of the data that is used for training\n",
    "# the model sees data from '2019-01-01' to '2019-04-01' for training\n",
    "\n",
    "start_dataset = pd.Timestamp(\"2019-01-01 00:00:00\", freq=freq)\n",
    "\n",
    "end_training = pd.Timestamp(\"2019-04-01 00:00:00\", freq=freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a3061",
   "metadata": {},
   "source": [
    "The DeepAR JSON input format represents each time series as a JSON object. In the simplest case each time series just consists of a start time stamp (``start``) and a list of values (``target``). For more complex cases, DeepAR also supports the fields ``dynamic_feat`` for time-series features and ``cat`` for categorical features, which we will use  later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "74c7c016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  2019-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"start: \", str(start_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6f2e5eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "for ts in timeseries:\n",
    "    target_list = ts[start_dataset:end_training][:-1].tolist()\n",
    "    print(len(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a1d95ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_training][:-1].tolist()\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c17b87a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data[0]['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83211a",
   "metadata": {},
   "source": [
    "As test data, we will consider time series extending beyond the training range: these will be used for computing test scores, by using the trained model to forecast their trailing 7 days, and comparing predictions with actual values.\n",
    "To evaluate our model performance on more than one week, we generate test data that extends to 1, 2, 3, 4 weeks beyond the training range. This way we perform *rolling evaluation* of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2caf294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "num_test_windows = 4\n",
    "\n",
    "idx = []\n",
    "print(len(pd.date_range(start_dataset, end_training)))\n",
    "\n",
    "period_range = len(pd.date_range(start_dataset, end_training))\n",
    "\n",
    "for i in range(1, num_test_windows + 1):\n",
    "    idx.append(\n",
    "        pd.date_range(\n",
    "            start_dataset,\n",
    "            periods=period_range + (i * prediction_length),\n",
    "            freq=freq\n",
    "        )\n",
    "    )\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[idx[k]].tolist()\n",
    "    }\n",
    "    for k in range(0, num_test_windows)\n",
    "    for ts in timeseries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "260fd3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data[0][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "76a89380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f0f25992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.33 ms, total: 3.33 ms\n",
      "Wall time: 7.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"train.json\", training_data)\n",
    "write_dicts_to_file(\"test.json\", test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c6270",
   "metadata": {},
   "source": [
    "Now that we have the data files locally, let us copy them to S3 where DeepAR can access them. Depending on your connection, this may take a couple of minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31eb689",
   "metadata": {},
   "source": [
    "### Copy train/test split data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4b1bea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "def copy_to_s3(local_file, s3_path, override=True):\n",
    "    \n",
    "    assert s3_path.startswith('s3://')\n",
    "    \n",
    "    s3_path_split_list = s3_path.split('/')\n",
    "    print(\"s3 path split list: \", s3_path_split_list)\n",
    "    \n",
    "    bucket_nm = s3_path_split_list[2]\n",
    "    print(\"bucket name: \", bucket_nm)\n",
    "    \n",
    "    bucket_prefix = '/'.join(s3_path_split_list[3:])\n",
    "    print(\"bucket prefix: \", bucket_prefix)\n",
    "    \n",
    "    bucket_objects = s3_resource.Bucket(\n",
    "        bucket_nm\n",
    "    ).objects.filter(\n",
    "        Prefix=bucket_prefix\n",
    "    )\n",
    "    \n",
    "    if len(list(bucket_objects)) > 0:\n",
    "        if not override:\n",
    "            print(f\"File s3://{bucket_nm}/{bucket_prefix} already exists.\")\n",
    "            print(\"Set override to upload anyway\\n\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    \n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        s3_resource.Bucket(\n",
    "            bucket_nm\n",
    "        ).put_object(\n",
    "            Key=bucket_prefix,\n",
    "            Body=data\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5ed5d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 path split list:  ['s3:', '', 'sagemaker-ap-northeast-2-988889742134', 'sagemaker', 'redshift-deepar-nyctaxi-demo-notebook', 'data', 'train', 'train.json']\n",
      "bucket name:  sagemaker-ap-northeast-2-988889742134\n",
      "bucket prefix:  sagemaker/redshift-deepar-nyctaxi-demo-notebook/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://sagemaker-ap-northeast-2-988889742134/sagemaker/redshift-deepar-nyctaxi-demo-notebook/data/train/train.json\n"
     ]
    }
   ],
   "source": [
    "copy_to_s3(\"train.json\", s3_data_path + \"/train/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1006f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2019-01-01 00:00:00\", \"target\": [42.625, 42.125, 21.875, 14.25, 9.875, 13.375, 18.0, 26.5...\n"
     ]
    }
   ],
   "source": [
    "s3_file_system = s3fs.S3FileSystem()\n",
    "\n",
    "with s3_file_system.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7c6a5198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 path split list:  ['s3:', '', 'sagemaker-ap-northeast-2-988889742134', 'sagemaker', 'redshift-deepar-nyctaxi-demo-notebook', 'data', 'test', 'test.json']\n",
      "bucket name:  sagemaker-ap-northeast-2-988889742134\n",
      "bucket prefix:  sagemaker/redshift-deepar-nyctaxi-demo-notebook/data/test/test.json\n",
      "Uploading file to s3://sagemaker-ap-northeast-2-988889742134/sagemaker/redshift-deepar-nyctaxi-demo-notebook/data/test/test.json\n"
     ]
    }
   ],
   "source": [
    "copy_to_s3(\"test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "03d524f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2019-01-01 00:00:00\", \"target\": [42.625, 42.125, 21.875, 14.25, 9.875, 13.375, 18.0, 26.5...\n"
     ]
    }
   ],
   "source": [
    "s3_file_system = s3fs.S3FileSystem()\n",
    "\n",
    "with s3_file_system.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52703989",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "db266ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Here, we define the estimator that will launch the training job\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_uri=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='redshift-deepar-nyctaxi-demo',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7954cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "62dd3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8e95a1a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 06:54:05 Starting - Starting the training job...\n",
      "2022-04-07 06:54:33 Starting - Preparing the instances for trainingProfilerReport-1649314445: InProgress\n",
      "......\n",
      "2022-04-07 06:55:34 Downloading - Downloading input data...\n",
      "2022-04-07 06:56:06 Training - Downloading the training image...\n",
      "2022-04-07 06:56:30 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904 integration.py:592] worker started\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '84', 'early_stopping_patience': '40', 'epochs': '400', 'learning_rate': '5E-4', 'mini_batch_size': '64', 'prediction_length': '84', 'time_freq': '2H'}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '5E-4', 'likelihood': 'student-t', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '84', 'epochs': '400', 'prediction_length': '84', 'time_freq': '2H'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] random_seed is None\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Real time series\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] number of time series: 2\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] number of observations: 2160\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] mean target length: 1080.0\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] min/mean/max target: 2.875/104.59571759259259/407.5\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] mean abs(target): 104.59571759259259\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Small number of time series. Doing 320 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Test set statistics:\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Real time series\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] number of time series: 8\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] number of observations: 2408\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] mean target length: 301.0\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] min/mean/max target: 3.375/104.79396802325581/407.5\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] mean abs(target): 104.79396802325581\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] #memory_usage::<batchbuffer> = 20.827598571777344 mb\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] nvidia-smi took: 0.025173664093017578 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:35 INFO 139984794219904] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314595.5116358, \"EndTime\": 1649314596.1369174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 623.1224536895752, \"count\": 1, \"min\": 623.1224536895752, \"max\": 623.1224536895752}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:36 INFO 139984794219904] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:36 INFO 139984794219904] #memory_usage::<model> = 55 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314596.1370065, \"EndTime\": 1649314596.8758268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1364.0761375427246, \"count\": 1, \"min\": 1364.0761375427246, \"max\": 1364.0761375427246}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:37 INFO 139984794219904] Epoch[0] Batch[0] avg_epoch_loss=6.459419\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=6.459419250488281\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:38 INFO 139984794219904] Epoch[0] Batch[5] avg_epoch_loss=5.875492\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=5.8754918575286865\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:38 INFO 139984794219904] Epoch[0] Batch [5]#011Speed: 253.93 samples/sec#011loss=5.875492\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:39 INFO 139984794219904] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314596.8759236, \"EndTime\": 1649314599.9136689, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 400.0, \"count\": 1, \"min\": 400, \"max\": 400}, \"update.time\": {\"sum\": 3037.6386642456055, \"count\": 1, \"min\": 3037.6386642456055, \"max\": 3037.6386642456055}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:39 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.35028338689227 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:39 INFO 139984794219904] #progress_metric: host=algo-1, completed 0.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=0, train loss <loss>=5.616310071945191\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:39 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:40 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_5bafd86b-caae-4b1f-862f-163d2ea80391-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314599.9137726, \"EndTime\": 1649314600.002006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.65912055969238, \"count\": 1, \"min\": 87.65912055969238, \"max\": 87.65912055969238}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:40 INFO 139984794219904] Epoch[1] Batch[0] avg_epoch_loss=5.169462\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=5.169462203979492\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:41 INFO 139984794219904] Epoch[1] Batch[5] avg_epoch_loss=5.140198\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=5.1401980717976885\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:41 INFO 139984794219904] Epoch[1] Batch [5]#011Speed: 264.01 samples/sec#011loss=5.140198\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:42 INFO 139984794219904] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314600.0020907, \"EndTime\": 1649314602.783678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2781.520128250122, \"count\": 1, \"min\": 2781.520128250122, \"max\": 2781.520128250122}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:42 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.16914676477006 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:42 INFO 139984794219904] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=1, train loss <loss>=5.184433650970459\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:42 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:42 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_6bd93839-e6aa-4b04-b1a1-0ba4d1d1139c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314602.783785, \"EndTime\": 1649314602.8425913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 57.99603462219238, \"count\": 1, \"min\": 57.99603462219238, \"max\": 57.99603462219238}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:43 INFO 139984794219904] Epoch[2] Batch[0] avg_epoch_loss=5.042466\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=5.042466163635254\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:44 INFO 139984794219904] Epoch[2] Batch[5] avg_epoch_loss=4.900437\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=4.900436957677205\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:44 INFO 139984794219904] Epoch[2] Batch [5]#011Speed: 273.11 samples/sec#011loss=4.900437\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] Epoch[2] Batch[10] avg_epoch_loss=4.802667\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=4.685343647003174\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] Epoch[2] Batch [10]#011Speed: 252.97 samples/sec#011loss=4.685344\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314602.842686, \"EndTime\": 1649314605.8404825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2997.7188110351562, \"count\": 1, \"min\": 2997.7188110351562, \"max\": 2997.7188110351562}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.4835375235573 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] #progress_metric: host=algo-1, completed 0.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=2, train loss <loss>=4.802667271007191\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:45 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_484eaca3-ac3f-40d7-ba89-5a465a0c6a4a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314605.840624, \"EndTime\": 1649314605.9284375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.30292320251465, \"count\": 1, \"min\": 87.30292320251465, \"max\": 87.30292320251465}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:46 INFO 139984794219904] Epoch[3] Batch[0] avg_epoch_loss=4.850521\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=4.850521087646484\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:47 INFO 139984794219904] Epoch[3] Batch[5] avg_epoch_loss=4.861837\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=4.861836592356364\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:47 INFO 139984794219904] Epoch[3] Batch [5]#011Speed: 270.54 samples/sec#011loss=4.861837\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:48 INFO 139984794219904] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314605.928519, \"EndTime\": 1649314608.7128851, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2784.292459487915, \"count\": 1, \"min\": 2784.292459487915, \"max\": 2784.292459487915}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:48 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=227.6946754909002 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:48 INFO 139984794219904] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=3, train loss <loss>=4.8155029773712155\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:48 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:49 INFO 139984794219904] Epoch[4] Batch[0] avg_epoch_loss=4.558493\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=4.558493137359619\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:50 INFO 139984794219904] Epoch[4] Batch[5] avg_epoch_loss=4.592438\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=4.592438379923503\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:50 INFO 139984794219904] Epoch[4] Batch [5]#011Speed: 260.90 samples/sec#011loss=4.592438\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:51 INFO 139984794219904] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314608.712982, \"EndTime\": 1649314611.4797258, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2766.024112701416, \"count\": 1, \"min\": 2766.024112701416, \"max\": 2766.024112701416}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:51 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=227.75349360131315 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:51 INFO 139984794219904] #progress_metric: host=algo-1, completed 1.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=4, train loss <loss>=4.574956655502319\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:51 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:51 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_2044eacb-5f04-480c-8c97-c1b3cdee7b8b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314611.479812, \"EndTime\": 1649314611.5666707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.22288703918457, \"count\": 1, \"min\": 86.22288703918457, \"max\": 86.22288703918457}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:52 INFO 139984794219904] Epoch[5] Batch[0] avg_epoch_loss=4.425470\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=4.425470352172852\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:53 INFO 139984794219904] Epoch[5] Batch[5] avg_epoch_loss=4.325881\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=4.325881322224935\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:53 INFO 139984794219904] Epoch[5] Batch [5]#011Speed: 246.29 samples/sec#011loss=4.325881\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:54 INFO 139984794219904] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314611.566756, \"EndTime\": 1649314614.4660633, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2899.231433868408, \"count\": 1, \"min\": 2899.231433868408, \"max\": 2899.231433868408}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:54 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.08008105351811 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:54 INFO 139984794219904] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=5, train loss <loss>=4.23999764919281\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:54 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:54 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_17c9d57e-0583-44fe-b288-5d5a0eca7cbe-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314614.4661598, \"EndTime\": 1649314614.5522885, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 85.55364608764648, \"count\": 1, \"min\": 85.55364608764648, \"max\": 85.55364608764648}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:55 INFO 139984794219904] Epoch[6] Batch[0] avg_epoch_loss=4.497450\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=4.497450351715088\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:56 INFO 139984794219904] Epoch[6] Batch[5] avg_epoch_loss=4.276357\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=4.276357014973958\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:56 INFO 139984794219904] Epoch[6] Batch [5]#011Speed: 252.05 samples/sec#011loss=4.276357\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314614.5523684, \"EndTime\": 1649314617.4524949, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2900.0589847564697, \"count\": 1, \"min\": 2900.0589847564697, \"max\": 2900.0589847564697}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=217.5716216070686 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] #progress_metric: host=algo-1, completed 1.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=6, train loss <loss>=4.2720215797424315\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] Epoch[7] Batch[0] avg_epoch_loss=4.264755\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=4.2647552490234375\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:59 INFO 139984794219904] Epoch[7] Batch[5] avg_epoch_loss=4.117354\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=4.1173542737960815\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:56:59 INFO 139984794219904] Epoch[7] Batch [5]#011Speed: 246.94 samples/sec#011loss=4.117354\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314617.4525888, \"EndTime\": 1649314620.3165102, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2863.4252548217773, \"count\": 1, \"min\": 2863.4252548217773, \"max\": 2863.4252548217773}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.72082413242842 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=7, train loss <loss>=4.064551377296448\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_71724e1d-866b-423b-9c7f-9483e07f6cac-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314620.316594, \"EndTime\": 1649314620.4055066, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 88.10615539550781, \"count\": 1, \"min\": 88.10615539550781, \"max\": 88.10615539550781}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] Epoch[8] Batch[0] avg_epoch_loss=4.048672\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=4.048672199249268\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:02 INFO 139984794219904] Epoch[8] Batch[5] avg_epoch_loss=4.066395\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=4.066394964853923\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:02 INFO 139984794219904] Epoch[8] Batch [5]#011Speed: 256.31 samples/sec#011loss=4.066395\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] Epoch[8] Batch[10] avg_epoch_loss=3.990788\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.9000592708587645\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] Epoch[8] Batch [10]#011Speed: 258.62 samples/sec#011loss=3.900059\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314620.4055946, \"EndTime\": 1649314623.464261, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3058.5923194885254, \"count\": 1, \"min\": 3058.5923194885254, \"max\": 3058.5923194885254}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.43090045094104 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] #progress_metric: host=algo-1, completed 2.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.9907878312197598\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:03 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_f9a873f1-0aeb-441e-b0db-f6db817ec2a7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314623.464342, \"EndTime\": 1649314623.5511324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.23766899108887, \"count\": 1, \"min\": 86.23766899108887, \"max\": 86.23766899108887}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:04 INFO 139984794219904] Epoch[9] Batch[0] avg_epoch_loss=4.253121\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=4.253121376037598\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:05 INFO 139984794219904] Epoch[9] Batch[5] avg_epoch_loss=4.023298\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=4.0232975880304975\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:05 INFO 139984794219904] Epoch[9] Batch [5]#011Speed: 261.92 samples/sec#011loss=4.023298\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] Epoch[9] Batch[10] avg_epoch_loss=3.941683\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.8437463283538817\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] Epoch[9] Batch [10]#011Speed: 244.52 samples/sec#011loss=3.843746\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314623.5512192, \"EndTime\": 1649314626.6746163, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3123.3267784118652, \"count\": 1, \"min\": 3123.3267784118652, \"max\": 3123.3267784118652}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=217.06370276693164 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.941683379086581\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:06 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_7324c2fd-793b-473b-93cb-c121880d5d4c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314626.6747565, \"EndTime\": 1649314626.7359214, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 60.486793518066406, \"count\": 1, \"min\": 60.486793518066406, \"max\": 60.486793518066406}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:07 INFO 139984794219904] Epoch[10] Batch[0] avg_epoch_loss=3.877397\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.877396583557129\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:08 INFO 139984794219904] Epoch[10] Batch[5] avg_epoch_loss=3.894206\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.8942062060038247\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:08 INFO 139984794219904] Epoch[10] Batch [5]#011Speed: 237.80 samples/sec#011loss=3.894206\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] Epoch[10] Batch[10] avg_epoch_loss=3.819954\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.730850887298584\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] Epoch[10] Batch [10]#011Speed: 268.33 samples/sec#011loss=3.730851\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314626.7360055, \"EndTime\": 1649314629.8549473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3118.875741958618, \"count\": 1, \"min\": 3118.875741958618, \"max\": 3118.875741958618}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.11798534996217 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] #progress_metric: host=algo-1, completed 2.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.8199537884105337\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:09 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_8db50b03-2dfe-45d6-b0c6-76aa81f52fb3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314629.8550386, \"EndTime\": 1649314629.9418817, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.33852005004883, \"count\": 1, \"min\": 86.33852005004883, \"max\": 86.33852005004883}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:10 INFO 139984794219904] Epoch[11] Batch[0] avg_epoch_loss=3.777278\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.777277946472168\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:11 INFO 139984794219904] Epoch[11] Batch[5] avg_epoch_loss=3.862099\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.8620994488398233\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:11 INFO 139984794219904] Epoch[11] Batch [5]#011Speed: 254.09 samples/sec#011loss=3.862099\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:12 INFO 139984794219904] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314629.94197, \"EndTime\": 1649314632.7427459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2800.7078170776367, \"count\": 1, \"min\": 2800.7078170776367, \"max\": 2800.7078170776367}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:12 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.57686097248447 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:12 INFO 139984794219904] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.870835542678833\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:12 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:13 INFO 139984794219904] Epoch[12] Batch[0] avg_epoch_loss=3.970594\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=3.9705939292907715\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:14 INFO 139984794219904] Epoch[12] Batch[5] avg_epoch_loss=3.825076\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.8250755071640015\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:14 INFO 139984794219904] Epoch[12] Batch [5]#011Speed: 247.70 samples/sec#011loss=3.825076\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] Epoch[12] Batch[10] avg_epoch_loss=3.774327\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=3.7134284496307375\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] Epoch[12] Batch [10]#011Speed: 247.59 samples/sec#011loss=3.713428\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314632.7428408, \"EndTime\": 1649314635.8976438, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3154.2465686798096, \"count\": 1, \"min\": 3154.2465686798096, \"max\": 3154.2465686798096}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.74413358096527 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] #progress_metric: host=algo-1, completed 3.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.7743268446488814\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:15 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_07087a51-4890-437d-9a2f-21e60f7ca91e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314635.8977325, \"EndTime\": 1649314635.9825342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 84.28311347961426, \"count\": 1, \"min\": 84.28311347961426, \"max\": 84.28311347961426}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:16 INFO 139984794219904] Epoch[13] Batch[0] avg_epoch_loss=3.620160\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.6201601028442383\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:17 INFO 139984794219904] Epoch[13] Batch[5] avg_epoch_loss=3.679475\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.6794753869374595\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:17 INFO 139984794219904] Epoch[13] Batch [5]#011Speed: 250.55 samples/sec#011loss=3.679475\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] Epoch[13] Batch[10] avg_epoch_loss=3.756141\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=3.8481404304504396\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] Epoch[13] Batch [10]#011Speed: 253.29 samples/sec#011loss=3.848140\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314635.9826167, \"EndTime\": 1649314639.125612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3142.925500869751, \"count\": 1, \"min\": 3142.925500869751, \"max\": 3142.925500869751}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=205.21297059694302 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.7561413158069956\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_ea7f1edf-ae66-4bc1-8662-25da5789c0b1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314639.1257243, \"EndTime\": 1649314639.1775482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 51.236629486083984, \"count\": 1, \"min\": 51.236629486083984, \"max\": 51.236629486083984}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] Epoch[14] Batch[0] avg_epoch_loss=3.667947\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=3.6679468154907227\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:21 INFO 139984794219904] Epoch[14] Batch[5] avg_epoch_loss=3.661762\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.6617618799209595\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:21 INFO 139984794219904] Epoch[14] Batch [5]#011Speed: 246.28 samples/sec#011loss=3.661762\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] Epoch[14] Batch[10] avg_epoch_loss=3.699961\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=3.745799732208252\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] Epoch[14] Batch [10]#011Speed: 247.91 samples/sec#011loss=3.745800\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314639.1776125, \"EndTime\": 1649314642.329533, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3151.8425941467285, \"count\": 1, \"min\": 3151.8425941467285, \"max\": 3151.8425941467285}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.0749041403096 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] #progress_metric: host=algo-1, completed 3.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.6999609036879106\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_a27c832b-94dc-4e3e-a1b2-dc5cc3eee801-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314642.3296297, \"EndTime\": 1649314642.3869617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 56.72001838684082, \"count\": 1, \"min\": 56.72001838684082, \"max\": 56.72001838684082}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] Epoch[15] Batch[0] avg_epoch_loss=3.453553\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.453552722930908\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:24 INFO 139984794219904] Epoch[15] Batch[5] avg_epoch_loss=3.595990\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=3.59598974386851\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:24 INFO 139984794219904] Epoch[15] Batch [5]#011Speed: 247.81 samples/sec#011loss=3.595990\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] Epoch[15] Batch[10] avg_epoch_loss=3.632430\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=3.6761576175689696\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] Epoch[15] Batch [10]#011Speed: 241.82 samples/sec#011loss=3.676158\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314642.3870556, \"EndTime\": 1649314645.5693512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3182.2187900543213, \"count\": 1, \"min\": 3182.2187900543213, \"max\": 3182.2187900543213}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.59387437047312 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=15, train loss <loss>=3.632429686459628\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:25 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_ce7eb426-fd64-4eaf-93f9-5c712feaa619-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314645.5694363, \"EndTime\": 1649314645.657731, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.78095245361328, \"count\": 1, \"min\": 87.78095245361328, \"max\": 87.78095245361328}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:26 INFO 139984794219904] Epoch[16] Batch[0] avg_epoch_loss=3.657340\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=3.657339572906494\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:27 INFO 139984794219904] Epoch[16] Batch[5] avg_epoch_loss=3.637416\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=3.6374161640803018\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:27 INFO 139984794219904] Epoch[16] Batch [5]#011Speed: 268.69 samples/sec#011loss=3.637416\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] Epoch[16] Batch[10] avg_epoch_loss=3.533620\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=3.4090641498565675\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] Epoch[16] Batch [10]#011Speed: 263.31 samples/sec#011loss=3.409064\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314645.6578155, \"EndTime\": 1649314648.6402767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2982.386350631714, \"count\": 1, \"min\": 2982.386350631714, \"max\": 2982.386350631714}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.97734812751096 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 4.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=16, train loss <loss>=3.5336197939786045\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:28 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_34d59664-1aeb-4a69-a0d3-cdb231150add-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314648.6403735, \"EndTime\": 1649314648.7069094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 65.85121154785156, \"count\": 1, \"min\": 65.85121154785156, \"max\": 65.85121154785156}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:29 INFO 139984794219904] Epoch[17] Batch[0] avg_epoch_loss=3.605773\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=3.6057732105255127\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:30 INFO 139984794219904] Epoch[17] Batch[5] avg_epoch_loss=3.554836\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=3.5548355976740518\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:30 INFO 139984794219904] Epoch[17] Batch [5]#011Speed: 270.65 samples/sec#011loss=3.554836\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] Epoch[17] Batch[10] avg_epoch_loss=3.505761\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=3.446870470046997\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] Epoch[17] Batch [10]#011Speed: 256.25 samples/sec#011loss=3.446870\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314648.7070017, \"EndTime\": 1649314651.7177124, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3010.6375217437744, \"count\": 1, \"min\": 3010.6375217437744, \"max\": 3010.6375217437744}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.19858676987783 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=17, train loss <loss>=3.5057605396617544\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:31 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_6cc1cf4e-31a4-42a7-8b6b-9351ab8fc6d8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314651.7178, \"EndTime\": 1649314651.7690988, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 50.71687698364258, \"count\": 1, \"min\": 50.71687698364258, \"max\": 50.71687698364258}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:32 INFO 139984794219904] Epoch[18] Batch[0] avg_epoch_loss=3.565162\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.565162420272827\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:33 INFO 139984794219904] Epoch[18] Batch[5] avg_epoch_loss=3.579762\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=3.5797619819641113\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:33 INFO 139984794219904] Epoch[18] Batch [5]#011Speed: 274.66 samples/sec#011loss=3.579762\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] Epoch[18] Batch[10] avg_epoch_loss=3.566338\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=3.550230026245117\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] Epoch[18] Batch [10]#011Speed: 262.77 samples/sec#011loss=3.550230\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314651.7691905, \"EndTime\": 1649314654.7073028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2938.0388259887695, \"count\": 1, \"min\": 2938.0388259887695, \"max\": 2938.0388259887695}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.54625017030423 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] #progress_metric: host=algo-1, completed 4.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=18, train loss <loss>=3.566338365728205\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:34 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:35 INFO 139984794219904] Epoch[19] Batch[0] avg_epoch_loss=3.639787\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=3.639787435531616\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:36 INFO 139984794219904] Epoch[19] Batch[5] avg_epoch_loss=3.449547\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=3.449547290802002\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:36 INFO 139984794219904] Epoch[19] Batch [5]#011Speed: 257.12 samples/sec#011loss=3.449547\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:37 INFO 139984794219904] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314654.7073827, \"EndTime\": 1649314657.526857, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2819.007158279419, \"count\": 1, \"min\": 2819.007158279419, \"max\": 2819.007158279419}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:37 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.21605207438637 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:37 INFO 139984794219904] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=19, train loss <loss>=3.4269398927688597\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:37 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:37 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_7e6a27f8-411b-4ec7-928e-dfcb447acaed-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314657.5269458, \"EndTime\": 1649314657.6132226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 85.72912216186523, \"count\": 1, \"min\": 85.72912216186523, \"max\": 85.72912216186523}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:38 INFO 139984794219904] Epoch[20] Batch[0] avg_epoch_loss=3.688725\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=3.688724994659424\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:39 INFO 139984794219904] Epoch[20] Batch[5] avg_epoch_loss=3.498287\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=3.4982868432998657\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:39 INFO 139984794219904] Epoch[20] Batch [5]#011Speed: 268.98 samples/sec#011loss=3.498287\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314657.6133087, \"EndTime\": 1649314660.4066794, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2793.3003902435303, \"count\": 1, \"min\": 2793.3003902435303, \"max\": 2793.3003902435303}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=229.10914601713415 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 5.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=20, train loss <loss>=3.4806939363479614\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] Epoch[21] Batch[0] avg_epoch_loss=3.612838\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=3.612837791442871\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:42 INFO 139984794219904] Epoch[21] Batch[5] avg_epoch_loss=3.461246\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=3.4612457354863486\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:42 INFO 139984794219904] Epoch[21] Batch [5]#011Speed: 258.26 samples/sec#011loss=3.461246\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] Epoch[21] Batch[10] avg_epoch_loss=3.522867\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=3.5968114376068114\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] Epoch[21] Batch [10]#011Speed: 246.49 samples/sec#011loss=3.596811\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314660.4067705, \"EndTime\": 1649314663.5053785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3098.034381866455, \"count\": 1, \"min\": 3098.034381866455, \"max\": 3098.034381866455}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.25336219293357 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=21, train loss <loss>=3.5228665091774682\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:43 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:44 INFO 139984794219904] Epoch[22] Batch[0] avg_epoch_loss=3.332551\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=3.3325514793395996\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:45 INFO 139984794219904] Epoch[22] Batch[5] avg_epoch_loss=3.395688\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=3.3956881761550903\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:45 INFO 139984794219904] Epoch[22] Batch [5]#011Speed: 258.94 samples/sec#011loss=3.395688\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314663.5055184, \"EndTime\": 1649314666.3140275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2808.027982711792, \"count\": 1, \"min\": 2808.027982711792, \"max\": 2808.027982711792}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.78487277993048 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 5.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=22, train loss <loss>=3.4056610345840452\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_cdf00087-1089-49f9-ad0c-343b22e6d606-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314666.3141222, \"EndTime\": 1649314666.403542, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 88.86909484863281, \"count\": 1, \"min\": 88.86909484863281, \"max\": 88.86909484863281}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] Epoch[23] Batch[0] avg_epoch_loss=3.290050\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=3.2900495529174805\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:48 INFO 139984794219904] Epoch[23] Batch[5] avg_epoch_loss=3.398309\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=3.398309350013733\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:48 INFO 139984794219904] Epoch[23] Batch [5]#011Speed: 251.96 samples/sec#011loss=3.398309\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] Epoch[23] Batch[10] avg_epoch_loss=3.339493\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=3.2689140319824217\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] Epoch[23] Batch [10]#011Speed: 252.34 samples/sec#011loss=3.268914\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314666.4036293, \"EndTime\": 1649314669.5350354, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3131.3374042510986, \"count\": 1, \"min\": 3131.3374042510986, \"max\": 3131.3374042510986}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.25154121305465 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=23, train loss <loss>=3.339493296363137\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:49 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_4db0a89c-c63b-436a-a2f1-275db20e4052-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314669.5351253, \"EndTime\": 1649314669.62319, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.5709056854248, \"count\": 1, \"min\": 87.5709056854248, \"max\": 87.5709056854248}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:50 INFO 139984794219904] Epoch[24] Batch[0] avg_epoch_loss=3.718793\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=3.7187931537628174\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:51 INFO 139984794219904] Epoch[24] Batch[5] avg_epoch_loss=3.458712\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=3.4587120612462363\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:51 INFO 139984794219904] Epoch[24] Batch [5]#011Speed: 250.27 samples/sec#011loss=3.458712\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:52 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314669.623281, \"EndTime\": 1649314672.5565188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2933.1653118133545, \"count\": 1, \"min\": 2933.1653118133545, \"max\": 2933.1653118133545}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.18385283736063 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 6.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=24, train loss <loss>=3.4170703172683714\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:52 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:53 INFO 139984794219904] Epoch[25] Batch[0] avg_epoch_loss=3.443520\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=3.4435203075408936\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:54 INFO 139984794219904] Epoch[25] Batch[5] avg_epoch_loss=3.358721\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=3.358721137046814\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:54 INFO 139984794219904] Epoch[25] Batch [5]#011Speed: 246.73 samples/sec#011loss=3.358721\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:55 INFO 139984794219904] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314672.556615, \"EndTime\": 1649314675.47185, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2914.741039276123, \"count\": 1, \"min\": 2914.741039276123, \"max\": 2914.741039276123}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=204.8086100772073 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 6.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=25, train loss <loss>=3.3509109735488893\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:56 INFO 139984794219904] Epoch[26] Batch[0] avg_epoch_loss=3.426904\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=3.4269044399261475\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:57 INFO 139984794219904] Epoch[26] Batch[5] avg_epoch_loss=3.405070\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=3.4050700664520264\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:57 INFO 139984794219904] Epoch[26] Batch [5]#011Speed: 267.04 samples/sec#011loss=3.405070\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314675.4719815, \"EndTime\": 1649314678.2860472, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2813.4875297546387, \"count\": 1, \"min\": 2813.4875297546387, \"max\": 2813.4875297546387}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.8424695944257 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] #progress_metric: host=algo-1, completed 6.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=26, train loss <loss>=3.3690519094467164\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] Epoch[27] Batch[0] avg_epoch_loss=3.300478\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:57:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=3.3004775047302246\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:00 INFO 139984794219904] Epoch[27] Batch[5] avg_epoch_loss=3.331486\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=3.3314856688181558\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:00 INFO 139984794219904] Epoch[27] Batch [5]#011Speed: 245.43 samples/sec#011loss=3.331486\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] Epoch[27] Batch[10] avg_epoch_loss=3.265813\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=3.187004899978638\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] Epoch[27] Batch [10]#011Speed: 265.11 samples/sec#011loss=3.187005\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314678.286166, \"EndTime\": 1649314681.3771622, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3090.5086994171143, \"count\": 1, \"min\": 3090.5086994171143, \"max\": 3090.5086994171143}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.04784054140288 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=27, train loss <loss>=3.2658125920729204\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:01 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_3c9d9668-3dce-4ee2-8703-1daca881bffa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314681.3772519, \"EndTime\": 1649314681.4665954, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 88.85884284973145, \"count\": 1, \"min\": 88.85884284973145, \"max\": 88.85884284973145}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:02 INFO 139984794219904] Epoch[28] Batch[0] avg_epoch_loss=3.355785\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=3.355785369873047\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:03 INFO 139984794219904] Epoch[28] Batch[5] avg_epoch_loss=3.323442\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=3.3234423398971558\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:03 INFO 139984794219904] Epoch[28] Batch [5]#011Speed: 251.65 samples/sec#011loss=3.323442\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] Epoch[28] Batch[10] avg_epoch_loss=3.352849\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=3.388136863708496\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] Epoch[28] Batch [10]#011Speed: 252.89 samples/sec#011loss=3.388137\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314681.4666831, \"EndTime\": 1649314684.6351159, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3168.3642864227295, \"count\": 1, \"min\": 3168.3642864227295, \"max\": 3168.3642864227295}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.0385170502605 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 7.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=28, train loss <loss>=3.352848941629583\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:05 INFO 139984794219904] Epoch[29] Batch[0] avg_epoch_loss=3.408065\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=3.408064842224121\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:06 INFO 139984794219904] Epoch[29] Batch[5] avg_epoch_loss=3.333100\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=3.333099643389384\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:06 INFO 139984794219904] Epoch[29] Batch [5]#011Speed: 252.98 samples/sec#011loss=3.333100\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] Epoch[29] Batch[10] avg_epoch_loss=3.411268\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=3.505071020126343\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] Epoch[29] Batch [10]#011Speed: 239.85 samples/sec#011loss=3.505071\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314684.6352077, \"EndTime\": 1649314687.8623066, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3226.266622543335, \"count\": 1, \"min\": 3226.266622543335, \"max\": 3226.266622543335}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=202.0833009790526 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 7.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=29, train loss <loss>=3.4112684509970923\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:08 INFO 139984794219904] Epoch[30] Batch[0] avg_epoch_loss=3.120740\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=3.1207404136657715\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:09 INFO 139984794219904] Epoch[30] Batch[5] avg_epoch_loss=3.335894\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=3.3358936309814453\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:09 INFO 139984794219904] Epoch[30] Batch [5]#011Speed: 272.08 samples/sec#011loss=3.335894\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] Epoch[30] Batch[10] avg_epoch_loss=3.380190\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=3.433345413208008\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] Epoch[30] Batch [10]#011Speed: 254.99 samples/sec#011loss=3.433345\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314687.8623936, \"EndTime\": 1649314690.8431852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2980.255603790283, \"count\": 1, \"min\": 2980.255603790283, \"max\": 2980.255603790283}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.1237281754955 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 7.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=30, train loss <loss>=3.380189895629883\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:10 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:11 INFO 139984794219904] Epoch[31] Batch[0] avg_epoch_loss=3.380777\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=3.380776882171631\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:12 INFO 139984794219904] Epoch[31] Batch[5] avg_epoch_loss=3.349721\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=3.349721312522888\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:12 INFO 139984794219904] Epoch[31] Batch [5]#011Speed: 261.54 samples/sec#011loss=3.349721\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:13 INFO 139984794219904] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314690.8432972, \"EndTime\": 1649314693.6734385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2829.6384811401367, \"count\": 1, \"min\": 2829.6384811401367, \"max\": 2829.6384811401367}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.75248404324694 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=31, train loss <loss>=3.3242027521133424\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:14 INFO 139984794219904] Epoch[32] Batch[0] avg_epoch_loss=3.111763\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=3.111762762069702\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:15 INFO 139984794219904] Epoch[32] Batch[5] avg_epoch_loss=3.299445\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=3.299445390701294\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:15 INFO 139984794219904] Epoch[32] Batch [5]#011Speed: 248.10 samples/sec#011loss=3.299445\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:16 INFO 139984794219904] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314693.673533, \"EndTime\": 1649314696.5067165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2832.702159881592, \"count\": 1, \"min\": 2832.702159881592, \"max\": 2832.702159881592}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:16 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.09849762846343 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:16 INFO 139984794219904] #progress_metric: host=algo-1, completed 8.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=32, train loss <loss>=3.3021388053894043\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:16 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:17 INFO 139984794219904] Epoch[33] Batch[0] avg_epoch_loss=3.062536\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=3.0625357627868652\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:18 INFO 139984794219904] Epoch[33] Batch[5] avg_epoch_loss=3.221685\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=3.2216850916544595\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:18 INFO 139984794219904] Epoch[33] Batch [5]#011Speed: 252.47 samples/sec#011loss=3.221685\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:19 INFO 139984794219904] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314696.5068038, \"EndTime\": 1649314699.3474631, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2840.0614261627197, \"count\": 1, \"min\": 2840.0614261627197, \"max\": 2840.0614261627197}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:19 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.2797396890287 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:19 INFO 139984794219904] #progress_metric: host=algo-1, completed 8.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=33, train loss <loss>=3.2463881254196165\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:19 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:19 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_b6e0d2bb-5d3d-44f0-972b-bd933fcbc4cb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314699.347561, \"EndTime\": 1649314699.4338562, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 85.71386337280273, \"count\": 1, \"min\": 85.71386337280273, \"max\": 85.71386337280273}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:20 INFO 139984794219904] Epoch[34] Batch[0] avg_epoch_loss=3.184436\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=3.1844358444213867\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:21 INFO 139984794219904] Epoch[34] Batch[5] avg_epoch_loss=3.212682\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=3.2126821279525757\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:21 INFO 139984794219904] Epoch[34] Batch [5]#011Speed: 248.98 samples/sec#011loss=3.212682\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] Epoch[34] Batch[10] avg_epoch_loss=3.194692\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=3.173103952407837\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] Epoch[34] Batch [10]#011Speed: 248.02 samples/sec#011loss=3.173104\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314699.433949, \"EndTime\": 1649314702.5830088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3148.991107940674, \"count\": 1, \"min\": 3148.991107940674, \"max\": 3148.991107940674}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.6303855053828 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] #progress_metric: host=algo-1, completed 8.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=34, train loss <loss>=3.1946920481595127\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:22 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_a05954bf-edd0-4818-9adc-78f899875ea0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314702.5830877, \"EndTime\": 1649314702.667568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 83.9681625366211, \"count\": 1, \"min\": 83.9681625366211, \"max\": 83.9681625366211}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:23 INFO 139984794219904] Epoch[35] Batch[0] avg_epoch_loss=3.314510\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=3.314509868621826\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:24 INFO 139984794219904] Epoch[35] Batch[5] avg_epoch_loss=3.260765\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=3.2607646783192954\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:24 INFO 139984794219904] Epoch[35] Batch [5]#011Speed: 272.97 samples/sec#011loss=3.260765\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] Epoch[35] Batch[10] avg_epoch_loss=3.304491\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=3.3569628238677978\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] Epoch[35] Batch [10]#011Speed: 273.30 samples/sec#011loss=3.356963\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314702.6676428, \"EndTime\": 1649314705.5882998, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2920.588731765747, \"count\": 1, \"min\": 2920.588731765747, \"max\": 2920.588731765747}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.86320328623222 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=35, train loss <loss>=3.3044911081140693\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:25 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:26 INFO 139984794219904] Epoch[36] Batch[0] avg_epoch_loss=3.227343\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=3.2273430824279785\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:27 INFO 139984794219904] Epoch[36] Batch[5] avg_epoch_loss=3.204967\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=3.20496666431427\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:27 INFO 139984794219904] Epoch[36] Batch [5]#011Speed: 253.44 samples/sec#011loss=3.204967\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] Epoch[36] Batch[10] avg_epoch_loss=3.130554\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=3.0412582397460937\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] Epoch[36] Batch [10]#011Speed: 251.71 samples/sec#011loss=3.041258\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314705.588394, \"EndTime\": 1649314708.6879969, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3098.849058151245, \"count\": 1, \"min\": 3098.849058151245, \"max\": 3098.849058151245}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.4902622339195 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 9.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=36, train loss <loss>=3.1305537440560083\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:28 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_d92a2522-8008-4a65-a6f8-825fb52909a0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314708.688052, \"EndTime\": 1649314708.7426975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 54.16107177734375, \"count\": 1, \"min\": 54.16107177734375, \"max\": 54.16107177734375}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:29 INFO 139984794219904] Epoch[37] Batch[0] avg_epoch_loss=3.106869\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=3.1068689823150635\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:30 INFO 139984794219904] Epoch[37] Batch[5] avg_epoch_loss=3.206838\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=3.206838369369507\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:30 INFO 139984794219904] Epoch[37] Batch [5]#011Speed: 268.74 samples/sec#011loss=3.206838\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:31 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314708.7427795, \"EndTime\": 1649314711.5017753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2758.9333057403564, \"count\": 1, \"min\": 2758.9333057403564, \"max\": 2758.9333057403564}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:31 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=231.2378035412844 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:31 INFO 139984794219904] #progress_metric: host=algo-1, completed 9.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=37, train loss <loss>=3.2088709354400633\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:31 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:32 INFO 139984794219904] Epoch[38] Batch[0] avg_epoch_loss=3.217715\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=3.217714786529541\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:33 INFO 139984794219904] Epoch[38] Batch[5] avg_epoch_loss=3.261234\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=3.2612342834472656\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:33 INFO 139984794219904] Epoch[38] Batch [5]#011Speed: 247.62 samples/sec#011loss=3.261234\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] Epoch[38] Batch[10] avg_epoch_loss=3.285903\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=3.3155058860778808\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] Epoch[38] Batch [10]#011Speed: 244.08 samples/sec#011loss=3.315506\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314711.5018682, \"EndTime\": 1649314714.665609, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3163.1574630737305, \"count\": 1, \"min\": 3163.1574630737305, \"max\": 3163.1574630737305}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.11531074336725 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] #progress_metric: host=algo-1, completed 9.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=38, train loss <loss>=3.2859031937339087\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:34 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:35 INFO 139984794219904] Epoch[39] Batch[0] avg_epoch_loss=3.169374\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=3.1693735122680664\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:36 INFO 139984794219904] Epoch[39] Batch[5] avg_epoch_loss=3.215542\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=3.2155419190724692\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:36 INFO 139984794219904] Epoch[39] Batch [5]#011Speed: 255.71 samples/sec#011loss=3.215542\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] Epoch[39] Batch[10] avg_epoch_loss=3.277471\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=3.3517863273620607\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] Epoch[39] Batch [10]#011Speed: 243.17 samples/sec#011loss=3.351786\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314714.6656966, \"EndTime\": 1649314717.8134475, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3147.245407104492, \"count\": 1, \"min\": 3147.245407104492, \"max\": 3147.245407104492}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.06444719222378 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=39, train loss <loss>=3.277471195567738\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:37 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:38 INFO 139984794219904] Epoch[40] Batch[0] avg_epoch_loss=3.140012\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=3.14001202583313\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:39 INFO 139984794219904] Epoch[40] Batch[5] avg_epoch_loss=3.162706\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=3.162706216176351\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:39 INFO 139984794219904] Epoch[40] Batch [5]#011Speed: 272.70 samples/sec#011loss=3.162706\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:40 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314717.8135152, \"EndTime\": 1649314720.5818553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2767.834186553955, \"count\": 1, \"min\": 2767.834186553955, \"max\": 2767.834186553955}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=229.40714834263176 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 10.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=40, train loss <loss>=3.175392436981201\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:40 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:41 INFO 139984794219904] Epoch[41] Batch[0] avg_epoch_loss=3.098651\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=3.0986509323120117\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:42 INFO 139984794219904] Epoch[41] Batch[5] avg_epoch_loss=3.138210\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=3.1382097800572715\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:42 INFO 139984794219904] Epoch[41] Batch [5]#011Speed: 263.49 samples/sec#011loss=3.138210\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] Epoch[41] Batch[10] avg_epoch_loss=3.065130\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.977434253692627\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] Epoch[41] Batch [10]#011Speed: 254.96 samples/sec#011loss=2.977434\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314720.581937, \"EndTime\": 1649314723.5944371, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3011.8489265441895, \"count\": 1, \"min\": 3011.8489265441895, \"max\": 3011.8489265441895}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.47691962325172 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] #progress_metric: host=algo-1, completed 10.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=41, train loss <loss>=3.0651299953460693\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:43 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_3b718d62-89df-4817-9003-d605f7baad3a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314723.594512, \"EndTime\": 1649314723.681837, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.79080009460449, \"count\": 1, \"min\": 86.79080009460449, \"max\": 86.79080009460449}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:44 INFO 139984794219904] Epoch[42] Batch[0] avg_epoch_loss=3.213770\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=3.2137699127197266\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:45 INFO 139984794219904] Epoch[42] Batch[5] avg_epoch_loss=3.206952\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=3.2069520950317383\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:45 INFO 139984794219904] Epoch[42] Batch [5]#011Speed: 248.44 samples/sec#011loss=3.206952\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:46 INFO 139984794219904] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314723.6819272, \"EndTime\": 1649314726.6087084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2926.6953468322754, \"count\": 1, \"min\": 2926.6953468322754, \"max\": 2926.6953468322754}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.46379854839196 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 10.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=42, train loss <loss>=3.264574122428894\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:46 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:47 INFO 139984794219904] Epoch[43] Batch[0] avg_epoch_loss=3.148819\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=3.1488187313079834\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:48 INFO 139984794219904] Epoch[43] Batch[5] avg_epoch_loss=3.138472\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=3.1384724775950112\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:48 INFO 139984794219904] Epoch[43] Batch [5]#011Speed: 247.44 samples/sec#011loss=3.138472\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:49 INFO 139984794219904] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314726.6088269, \"EndTime\": 1649314729.4827855, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2873.443603515625, \"count\": 1, \"min\": 2873.443603515625, \"max\": 2873.443603515625}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:49 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.2834645094385 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:49 INFO 139984794219904] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=43, train loss <loss>=3.155887746810913\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:49 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:50 INFO 139984794219904] Epoch[44] Batch[0] avg_epoch_loss=3.282767\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=3.2827670574188232\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:51 INFO 139984794219904] Epoch[44] Batch[5] avg_epoch_loss=3.201443\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=3.201443076133728\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:51 INFO 139984794219904] Epoch[44] Batch [5]#011Speed: 247.19 samples/sec#011loss=3.201443\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:52 INFO 139984794219904] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314729.482869, \"EndTime\": 1649314732.3928807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2909.343957901001, \"count\": 1, \"min\": 2909.343957901001, \"max\": 2909.343957901001}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.93906500112348 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 11.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=44, train loss <loss>=3.2143173456192016\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:52 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:53 INFO 139984794219904] Epoch[45] Batch[0] avg_epoch_loss=3.115994\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=3.115994453430176\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:54 INFO 139984794219904] Epoch[45] Batch[5] avg_epoch_loss=3.149800\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=3.149800459543864\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:54 INFO 139984794219904] Epoch[45] Batch [5]#011Speed: 247.59 samples/sec#011loss=3.149800\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314732.392978, \"EndTime\": 1649314735.3422408, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2948.6825466156006, \"count\": 1, \"min\": 2948.6825466156006, \"max\": 2948.6825466156006}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.99768289534674 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 11.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=45, train loss <loss>=3.1619808435440064\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] Epoch[46] Batch[0] avg_epoch_loss=3.313564\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=3.3135643005371094\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:57 INFO 139984794219904] Epoch[46] Batch[5] avg_epoch_loss=3.167755\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=3.1677551666895547\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:57 INFO 139984794219904] Epoch[46] Batch [5]#011Speed: 252.36 samples/sec#011loss=3.167755\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] Epoch[46] Batch[10] avg_epoch_loss=3.124826\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=3.0733108043670656\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] Epoch[46] Batch [10]#011Speed: 248.58 samples/sec#011loss=3.073311\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314735.3423412, \"EndTime\": 1649314738.4847097, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3141.788959503174, \"count\": 1, \"min\": 3141.788959503174, \"max\": 3141.788959503174}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.97314365521927 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] #progress_metric: host=algo-1, completed 11.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=46, train loss <loss>=3.1248259110884233\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:58 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:59 INFO 139984794219904] Epoch[47] Batch[0] avg_epoch_loss=3.199342\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:58:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=3.1993415355682373\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:00 INFO 139984794219904] Epoch[47] Batch[5] avg_epoch_loss=3.123316\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=3.1233155727386475\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:00 INFO 139984794219904] Epoch[47] Batch [5]#011Speed: 258.09 samples/sec#011loss=3.123316\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] Epoch[47] Batch[10] avg_epoch_loss=3.190676\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=3.2715078353881837\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] Epoch[47] Batch [10]#011Speed: 254.84 samples/sec#011loss=3.271508\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314738.4847867, \"EndTime\": 1649314741.5749536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3089.712142944336, \"count\": 1, \"min\": 3089.712142944336, \"max\": 3089.712142944336}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.01237592630403 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=47, train loss <loss>=3.1906756921248003\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:01 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:02 INFO 139984794219904] Epoch[48] Batch[0] avg_epoch_loss=3.017298\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=3.0172979831695557\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:03 INFO 139984794219904] Epoch[48] Batch[5] avg_epoch_loss=3.079495\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=3.0794946750005088\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:03 INFO 139984794219904] Epoch[48] Batch [5]#011Speed: 258.60 samples/sec#011loss=3.079495\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:04 INFO 139984794219904] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314741.5750628, \"EndTime\": 1649314744.4200232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2844.325065612793, \"count\": 1, \"min\": 2844.325065612793, \"max\": 2844.325065612793}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=217.96805046694175 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 12.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=48, train loss <loss>=3.128597092628479\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:05 INFO 139984794219904] Epoch[49] Batch[0] avg_epoch_loss=3.116117\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=3.116116762161255\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:06 INFO 139984794219904] Epoch[49] Batch[5] avg_epoch_loss=3.172967\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=3.1729665994644165\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:06 INFO 139984794219904] Epoch[49] Batch [5]#011Speed: 250.62 samples/sec#011loss=3.172967\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314744.4201088, \"EndTime\": 1649314747.3010032, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2880.234718322754, \"count\": 1, \"min\": 2880.234718322754, \"max\": 2880.234718322754}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.45369019346478 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=49, train loss <loss>=3.132624101638794\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] Epoch[50] Batch[0] avg_epoch_loss=3.167978\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=3.167977809906006\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:09 INFO 139984794219904] Epoch[50] Batch[5] avg_epoch_loss=3.129990\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=3.1299899419148765\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:09 INFO 139984794219904] Epoch[50] Batch [5]#011Speed: 248.10 samples/sec#011loss=3.129990\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314747.301155, \"EndTime\": 1649314750.199132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2897.4344730377197, \"count\": 1, \"min\": 2897.4344730377197, \"max\": 2897.4344730377197}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.8052285389645 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 12.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=50, train loss <loss>=3.11628258228302\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] Epoch[51] Batch[0] avg_epoch_loss=3.059335\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=3.0593347549438477\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:12 INFO 139984794219904] Epoch[51] Batch[5] avg_epoch_loss=3.108787\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=3.1087867418924966\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:12 INFO 139984794219904] Epoch[51] Batch [5]#011Speed: 247.24 samples/sec#011loss=3.108787\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314750.1992195, \"EndTime\": 1649314753.0632396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2863.5332584381104, \"count\": 1, \"min\": 2863.5332584381104, \"max\": 2863.5332584381104}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.41124272055308 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=51, train loss <loss>=3.188272500038147\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] Epoch[52] Batch[0] avg_epoch_loss=3.072484\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=3.0724844932556152\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:14 INFO 139984794219904] Epoch[52] Batch[5] avg_epoch_loss=3.116914\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=3.1169135570526123\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:14 INFO 139984794219904] Epoch[52] Batch [5]#011Speed: 271.45 samples/sec#011loss=3.116914\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:15 INFO 139984794219904] processed a total of 584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314753.0633276, \"EndTime\": 1649314755.835593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2771.7621326446533, \"count\": 1, \"min\": 2771.7621326446533, \"max\": 2771.7621326446533}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:15 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.68336944964386 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:15 INFO 139984794219904] #progress_metric: host=algo-1, completed 13.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=52, train loss <loss>=3.044014310836792\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:15 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:15 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_938f33c6-2f21-4a5a-8f79-8b69db6b1c45-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314755.8357284, \"EndTime\": 1649314755.9233613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.01610565185547, \"count\": 1, \"min\": 87.01610565185547, \"max\": 87.01610565185547}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:16 INFO 139984794219904] Epoch[53] Batch[0] avg_epoch_loss=3.087466\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=3.087466239929199\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:17 INFO 139984794219904] Epoch[53] Batch[5] avg_epoch_loss=3.091096\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=3.091095725695292\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:17 INFO 139984794219904] Epoch[53] Batch [5]#011Speed: 249.34 samples/sec#011loss=3.091096\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:18 INFO 139984794219904] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314755.9234514, \"EndTime\": 1649314758.8445013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2920.9842681884766, \"count\": 1, \"min\": 2920.9842681884766, \"max\": 2920.9842681884766}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:18 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.69785179745736 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:18 INFO 139984794219904] #progress_metric: host=algo-1, completed 13.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=53, train loss <loss>=3.125322937965393\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:18 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:19 INFO 139984794219904] Epoch[54] Batch[0] avg_epoch_loss=3.275657\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=3.2756567001342773\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:20 INFO 139984794219904] Epoch[54] Batch[5] avg_epoch_loss=3.109745\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=3.109744985898336\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:20 INFO 139984794219904] Epoch[54] Batch [5]#011Speed: 270.40 samples/sec#011loss=3.109745\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] Epoch[54] Batch[10] avg_epoch_loss=3.095018\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=3.0773467063903808\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] Epoch[54] Batch [10]#011Speed: 252.00 samples/sec#011loss=3.077347\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314758.8445952, \"EndTime\": 1649314761.916343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3071.160078048706, \"count\": 1, \"min\": 3071.160078048706, \"max\": 3071.160078048706}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.96290215140849 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] #progress_metric: host=algo-1, completed 13.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=54, train loss <loss>=3.095018495212902\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:21 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:22 INFO 139984794219904] Epoch[55] Batch[0] avg_epoch_loss=3.031427\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=3.0314269065856934\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:23 INFO 139984794219904] Epoch[55] Batch[5] avg_epoch_loss=3.154558\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=3.1545584201812744\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:23 INFO 139984794219904] Epoch[55] Batch [5]#011Speed: 247.16 samples/sec#011loss=3.154558\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] Epoch[55] Batch[10] avg_epoch_loss=3.072312\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.973616886138916\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] Epoch[55] Batch [10]#011Speed: 246.24 samples/sec#011loss=2.973617\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314761.9164288, \"EndTime\": 1649314765.1080499, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3191.0717487335205, \"count\": 1, \"min\": 3191.0717487335205, \"max\": 3191.0717487335205}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.0115799077588 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=55, train loss <loss>=3.072312268343839\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] Epoch[56] Batch[0] avg_epoch_loss=3.010155\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=3.010154962539673\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:26 INFO 139984794219904] Epoch[56] Batch[5] avg_epoch_loss=3.046212\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=3.0462122360865274\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:26 INFO 139984794219904] Epoch[56] Batch [5]#011Speed: 247.62 samples/sec#011loss=3.046212\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] Epoch[56] Batch[10] avg_epoch_loss=3.096262\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=3.1563207626342775\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] Epoch[56] Batch [10]#011Speed: 256.92 samples/sec#011loss=3.156321\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314765.1081476, \"EndTime\": 1649314768.2292507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3120.548963546753, \"count\": 1, \"min\": 3120.548963546753, \"max\": 3120.548963546753}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.4273953923461 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 14.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=56, train loss <loss>=3.096261566335505\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] Epoch[57] Batch[0] avg_epoch_loss=3.040503\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=3.0405025482177734\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:30 INFO 139984794219904] Epoch[57] Batch[5] avg_epoch_loss=3.112969\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=3.1129691998163858\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:30 INFO 139984794219904] Epoch[57] Batch [5]#011Speed: 255.66 samples/sec#011loss=3.112969\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] Epoch[57] Batch[10] avg_epoch_loss=3.069954\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=3.0183362007141112\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] Epoch[57] Batch [10]#011Speed: 239.10 samples/sec#011loss=3.018336\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314768.2293265, \"EndTime\": 1649314771.3850737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3155.268907546997, \"count\": 1, \"min\": 3155.268907546997, \"max\": 3155.268907546997}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.9898809900705 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] #progress_metric: host=algo-1, completed 14.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=57, train loss <loss>=3.069954200224443\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] Epoch[58] Batch[0] avg_epoch_loss=3.106481\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=3.106480836868286\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:33 INFO 139984794219904] Epoch[58] Batch[5] avg_epoch_loss=3.054797\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=3.054796655972799\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:33 INFO 139984794219904] Epoch[58] Batch [5]#011Speed: 266.55 samples/sec#011loss=3.054797\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314771.3851647, \"EndTime\": 1649314774.1973412, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2811.645269393921, \"count\": 1, \"min\": 2811.645269393921, \"max\": 2811.645269393921}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.07828957080537 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] #progress_metric: host=algo-1, completed 14.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=58, train loss <loss>=3.0576340675354006\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] Epoch[59] Batch[0] avg_epoch_loss=3.108831\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=3.1088311672210693\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:35 INFO 139984794219904] Epoch[59] Batch[5] avg_epoch_loss=3.032190\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=3.032190124193827\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:35 INFO 139984794219904] Epoch[59] Batch [5]#011Speed: 266.90 samples/sec#011loss=3.032190\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314774.1974347, \"EndTime\": 1649314777.0083525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2810.4026317596436, \"count\": 1, \"min\": 2810.4026317596436, \"max\": 2810.4026317596436}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.37791436044506 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=59, train loss <loss>=3.0719857692718504\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] Epoch[60] Batch[0] avg_epoch_loss=2.986504\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.9865036010742188\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:38 INFO 139984794219904] Epoch[60] Batch[5] avg_epoch_loss=3.015737\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=3.015736738840739\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:38 INFO 139984794219904] Epoch[60] Batch [5]#011Speed: 247.38 samples/sec#011loss=3.015737\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] Epoch[60] Batch[10] avg_epoch_loss=3.006608\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.9956527233123778\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] Epoch[60] Batch [10]#011Speed: 241.10 samples/sec#011loss=2.995653\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314777.0084424, \"EndTime\": 1649314780.2244818, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3215.383529663086, \"count\": 1, \"min\": 3215.383529663086, \"max\": 3215.383529663086}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.78646227121234 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 15.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=60, train loss <loss>=3.0066076408733022\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_e59bd781-de02-487d-9a02-18eae0e287b3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314780.224559, \"EndTime\": 1649314780.3103101, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 85.2193832397461, \"count\": 1, \"min\": 85.2193832397461, \"max\": 85.2193832397461}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] Epoch[61] Batch[0] avg_epoch_loss=3.144421\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=3.144421339035034\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:42 INFO 139984794219904] Epoch[61] Batch[5] avg_epoch_loss=3.117391\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=3.117390751838684\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:42 INFO 139984794219904] Epoch[61] Batch [5]#011Speed: 257.77 samples/sec#011loss=3.117391\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] Epoch[61] Batch[10] avg_epoch_loss=3.011948\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.8854172229766846\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] Epoch[61] Batch [10]#011Speed: 243.75 samples/sec#011loss=2.885417\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314780.3103805, \"EndTime\": 1649314783.4428635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3132.416009902954, \"count\": 1, \"min\": 3132.416009902954, \"max\": 3132.416009902954}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.64823794516022 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] #progress_metric: host=algo-1, completed 15.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=61, train loss <loss>=3.0119482387195933\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:43 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:44 INFO 139984794219904] Epoch[62] Batch[0] avg_epoch_loss=2.917341\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.9173407554626465\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:45 INFO 139984794219904] Epoch[62] Batch[5] avg_epoch_loss=2.976166\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.9761656125386557\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:45 INFO 139984794219904] Epoch[62] Batch [5]#011Speed: 269.10 samples/sec#011loss=2.976166\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] Epoch[62] Batch[10] avg_epoch_loss=2.974161\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.9717546939849853\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] Epoch[62] Batch [10]#011Speed: 261.77 samples/sec#011loss=2.971755\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314783.442963, \"EndTime\": 1649314786.441899, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2998.3112812042236, \"count\": 1, \"min\": 2998.3112812042236, \"max\": 2998.3112812042236}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.7820618278811 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 15.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.9741606495597144\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:46 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_2dab3839-a3f2-4d06-8842-4398643291e4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314786.4419858, \"EndTime\": 1649314786.5098164, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 67.3670768737793, \"count\": 1, \"min\": 67.3670768737793, \"max\": 67.3670768737793}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:47 INFO 139984794219904] Epoch[63] Batch[0] avg_epoch_loss=3.020728\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=3.020728349685669\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:48 INFO 139984794219904] Epoch[63] Batch[5] avg_epoch_loss=3.031545\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=3.031545400619507\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:48 INFO 139984794219904] Epoch[63] Batch [5]#011Speed: 271.25 samples/sec#011loss=3.031545\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] Epoch[63] Batch[10] avg_epoch_loss=2.930086\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.8083351612091065\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] Epoch[63] Batch [10]#011Speed: 255.16 samples/sec#011loss=2.808335\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314786.5098894, \"EndTime\": 1649314789.4881334, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2978.184461593628, \"count\": 1, \"min\": 2978.184461593628, \"max\": 2978.184461593628}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.27359072374963 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.930086200887507\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:49 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_c6f1230e-28ad-40e7-a7b4-b0776b30e3dc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314789.488222, \"EndTime\": 1649314789.546148, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 57.35516548156738, \"count\": 1, \"min\": 57.35516548156738, \"max\": 57.35516548156738}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:50 INFO 139984794219904] Epoch[64] Batch[0] avg_epoch_loss=3.099394\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=3.099393606185913\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:51 INFO 139984794219904] Epoch[64] Batch[5] avg_epoch_loss=3.004399\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=3.0043991009394326\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:51 INFO 139984794219904] Epoch[64] Batch [5]#011Speed: 265.02 samples/sec#011loss=3.004399\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] Epoch[64] Batch[10] avg_epoch_loss=3.023735\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=3.0469377517700194\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] Epoch[64] Batch [10]#011Speed: 258.80 samples/sec#011loss=3.046938\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314789.546206, \"EndTime\": 1649314792.567664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3021.380662918091, \"count\": 1, \"min\": 3021.380662918091, \"max\": 3021.380662918091}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.38961917795768 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 16.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=64, train loss <loss>=3.023734851316972\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:52 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:53 INFO 139984794219904] Epoch[65] Batch[0] avg_epoch_loss=3.174706\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=3.174706220626831\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:54 INFO 139984794219904] Epoch[65] Batch[5] avg_epoch_loss=3.046348\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=3.0463479359944663\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:54 INFO 139984794219904] Epoch[65] Batch [5]#011Speed: 261.84 samples/sec#011loss=3.046348\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] Epoch[65] Batch[10] avg_epoch_loss=3.075079\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=3.109556865692139\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] Epoch[65] Batch [10]#011Speed: 261.22 samples/sec#011loss=3.109557\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314792.5677743, \"EndTime\": 1649314795.6087513, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3040.4584407806396, \"count\": 1, \"min\": 3040.4584407806396, \"max\": 3040.4584407806396}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.45941259864253 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 16.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=65, train loss <loss>=3.0750792676752265\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:56 INFO 139984794219904] Epoch[66] Batch[0] avg_epoch_loss=3.063117\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=3.063117027282715\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:57 INFO 139984794219904] Epoch[66] Batch[5] avg_epoch_loss=3.060005\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=3.0600051482518515\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:57 INFO 139984794219904] Epoch[66] Batch [5]#011Speed: 265.34 samples/sec#011loss=3.060005\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314795.608833, \"EndTime\": 1649314798.3847606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2775.3379344940186, \"count\": 1, \"min\": 2775.3379344940186, \"max\": 2775.3379344940186}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=225.5474801480265 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] #progress_metric: host=algo-1, completed 16.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=66, train loss <loss>=3.046658182144165\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] Epoch[67] Batch[0] avg_epoch_loss=3.051780\u001b[0m\n",
      "\u001b[34m[04/07/2022 06:59:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=3.0517799854278564\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:00 INFO 139984794219904] Epoch[67] Batch[5] avg_epoch_loss=3.117087\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=3.1170873641967773\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:00 INFO 139984794219904] Epoch[67] Batch [5]#011Speed: 260.83 samples/sec#011loss=3.117087\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314798.3848505, \"EndTime\": 1649314801.1403558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2755.004644393921, \"count\": 1, \"min\": 2755.004644393921, \"max\": 2755.004644393921}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=228.30023664945153 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=67, train loss <loss>=3.0784095764160155\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] Epoch[68] Batch[0] avg_epoch_loss=3.024233\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=3.024232864379883\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:03 INFO 139984794219904] Epoch[68] Batch[5] avg_epoch_loss=3.026066\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=3.0260661840438843\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:03 INFO 139984794219904] Epoch[68] Batch [5]#011Speed: 244.21 samples/sec#011loss=3.026066\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314801.1404443, \"EndTime\": 1649314804.0845983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2943.5458183288574, \"count\": 1, \"min\": 2943.5458183288574, \"max\": 2943.5458183288574}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.5626126462138 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 17.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=68, train loss <loss>=3.055865526199341\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] Epoch[69] Batch[0] avg_epoch_loss=2.990723\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.99072265625\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:06 INFO 139984794219904] Epoch[69] Batch[5] avg_epoch_loss=2.953898\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.9538979530334473\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:06 INFO 139984794219904] Epoch[69] Batch [5]#011Speed: 246.36 samples/sec#011loss=2.953898\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314804.0846968, \"EndTime\": 1649314807.0927918, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3007.538080215454, \"count\": 1, \"min\": 3007.538080215454, \"max\": 3007.538080215454}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.4693936858016 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 17.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.9473803281784057\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] Epoch[70] Batch[0] avg_epoch_loss=3.044743\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=3.0447425842285156\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:08 INFO 139984794219904] Epoch[70] Batch[5] avg_epoch_loss=3.011065\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=3.0110650857289634\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:08 INFO 139984794219904] Epoch[70] Batch [5]#011Speed: 249.67 samples/sec#011loss=3.011065\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314807.092886, \"EndTime\": 1649314810.0057328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2912.242650985718, \"count\": 1, \"min\": 2912.242650985718, \"max\": 2912.242650985718}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.31856453643528 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 17.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=70, train loss <loss>=3.0176101684570313\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] Epoch[71] Batch[0] avg_epoch_loss=3.020414\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=3.020414352416992\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:11 INFO 139984794219904] Epoch[71] Batch[5] avg_epoch_loss=3.060110\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=3.060109814008077\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:11 INFO 139984794219904] Epoch[71] Batch [5]#011Speed: 255.33 samples/sec#011loss=3.060110\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] Epoch[71] Batch[10] avg_epoch_loss=2.965906\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.852860927581787\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] Epoch[71] Batch [10]#011Speed: 244.36 samples/sec#011loss=2.852861\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314810.0058217, \"EndTime\": 1649314813.1622498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3155.94744682312, \"count\": 1, \"min\": 3155.94744682312, \"max\": 3155.94744682312}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.8533912696638 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.9659057747234\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] Epoch[72] Batch[0] avg_epoch_loss=3.073748\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=3.0737476348876953\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:14 INFO 139984794219904] Epoch[72] Batch[5] avg_epoch_loss=3.015394\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=3.0153938134511313\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:14 INFO 139984794219904] Epoch[72] Batch [5]#011Speed: 261.32 samples/sec#011loss=3.015394\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:15 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314813.1623375, \"EndTime\": 1649314815.918352, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2755.5220127105713, \"count\": 1, \"min\": 2755.5220127105713, \"max\": 2755.5220127105713}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:15 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=231.52317731362385 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:15 INFO 139984794219904] #progress_metric: host=algo-1, completed 18.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.9979758501052856\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:15 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:16 INFO 139984794219904] Epoch[73] Batch[0] avg_epoch_loss=2.878274\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.8782737255096436\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:17 INFO 139984794219904] Epoch[73] Batch[5] avg_epoch_loss=2.985402\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.9854016304016113\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:17 INFO 139984794219904] Epoch[73] Batch [5]#011Speed: 252.54 samples/sec#011loss=2.985402\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:18 INFO 139984794219904] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314815.9184504, \"EndTime\": 1649314818.72568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2806.6091537475586, \"count\": 1, \"min\": 2806.6091537475586, \"max\": 2806.6091537475586}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:18 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.6091256654584 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:18 INFO 139984794219904] #progress_metric: host=algo-1, completed 18.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=73, train loss <loss>=3.0127065658569334\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:18 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:19 INFO 139984794219904] Epoch[74] Batch[0] avg_epoch_loss=3.061362\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=3.061361789703369\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:20 INFO 139984794219904] Epoch[74] Batch[5] avg_epoch_loss=3.040059\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=3.0400594075520835\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:20 INFO 139984794219904] Epoch[74] Batch [5]#011Speed: 274.06 samples/sec#011loss=3.040059\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:21 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314818.7257771, \"EndTime\": 1649314821.4227953, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2696.49600982666, \"count\": 1, \"min\": 2696.49600982666, \"max\": 2696.49600982666}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:21 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=237.3342922116979 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:21 INFO 139984794219904] #progress_metric: host=algo-1, completed 18.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.9964523792266844\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:21 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:22 INFO 139984794219904] Epoch[75] Batch[0] avg_epoch_loss=3.012232\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=3.0122315883636475\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:23 INFO 139984794219904] Epoch[75] Batch[5] avg_epoch_loss=2.992265\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.9922646284103394\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:23 INFO 139984794219904] Epoch[75] Batch [5]#011Speed: 262.01 samples/sec#011loss=2.992265\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314821.4228761, \"EndTime\": 1649314824.2494726, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2825.9642124176025, \"count\": 1, \"min\": 2825.9642124176025, \"max\": 2825.9642124176025}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.69135660822383 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.987633228302002\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] Epoch[76] Batch[0] avg_epoch_loss=2.743995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.743994951248169\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:26 INFO 139984794219904] Epoch[76] Batch[5] avg_epoch_loss=2.892984\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.892984390258789\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:26 INFO 139984794219904] Epoch[76] Batch [5]#011Speed: 253.90 samples/sec#011loss=2.892984\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314824.2495654, \"EndTime\": 1649314827.1444113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2894.0606117248535, \"count\": 1, \"min\": 2894.0606117248535, \"max\": 2894.0606117248535}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.5306436275959 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] #progress_metric: host=algo-1, completed 19.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.9080379247665404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_b929500c-c723-4ac0-97e2-f9759ceb76cf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314827.1445084, \"EndTime\": 1649314827.2133443, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 68.15195083618164, \"count\": 1, \"min\": 68.15195083618164, \"max\": 68.15195083618164}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] Epoch[77] Batch[0] avg_epoch_loss=2.832981\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.8329806327819824\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:29 INFO 139984794219904] Epoch[77] Batch[5] avg_epoch_loss=2.905923\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.9059234460194907\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:29 INFO 139984794219904] Epoch[77] Batch [5]#011Speed: 246.94 samples/sec#011loss=2.905923\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] Epoch[77] Batch[10] avg_epoch_loss=2.898469\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=2.889522743225098\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] Epoch[77] Batch [10]#011Speed: 245.19 samples/sec#011loss=2.889523\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314827.2134612, \"EndTime\": 1649314830.3889992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3175.4627227783203, \"count\": 1, \"min\": 3175.4627227783203, \"max\": 3175.4627227783203}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.8359380015023 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] #progress_metric: host=algo-1, completed 19.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.8984685811129483\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:30 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_57ed602d-d1fa-4b20-9469-b32dd92f8743-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314830.3890798, \"EndTime\": 1649314830.476186, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.61913871765137, \"count\": 1, \"min\": 86.61913871765137, \"max\": 86.61913871765137}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:31 INFO 139984794219904] Epoch[78] Batch[0] avg_epoch_loss=2.882842\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.8828423023223877\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:32 INFO 139984794219904] Epoch[78] Batch[5] avg_epoch_loss=2.941303\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.9413032134373984\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:32 INFO 139984794219904] Epoch[78] Batch [5]#011Speed: 262.26 samples/sec#011loss=2.941303\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314830.4762692, \"EndTime\": 1649314833.325063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2848.724365234375, \"count\": 1, \"min\": 2848.724365234375, \"max\": 2848.724365234375}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.26066671626668 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] #progress_metric: host=algo-1, completed 19.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=78, train loss <loss>=3.0193668603897095\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] Epoch[79] Batch[0] avg_epoch_loss=2.845201\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.8452014923095703\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:35 INFO 139984794219904] Epoch[79] Batch[5] avg_epoch_loss=2.862364\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.8623640139897666\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:35 INFO 139984794219904] Epoch[79] Batch [5]#011Speed: 252.59 samples/sec#011loss=2.862364\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] Epoch[79] Batch[10] avg_epoch_loss=2.836861\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=2.806256914138794\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] Epoch[79] Batch [10]#011Speed: 252.17 samples/sec#011loss=2.806257\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314833.3251486, \"EndTime\": 1649314836.4335814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3107.9344749450684, \"count\": 1, \"min\": 3107.9344749450684, \"max\": 3107.9344749450684}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.77718400996858 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.836860786784779\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:36 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_6d2cdbe6-e77a-456d-82ed-300a467e7b39-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314836.4336674, \"EndTime\": 1649314836.5209148, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.72499656677246, \"count\": 1, \"min\": 86.72499656677246, \"max\": 86.72499656677246}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:37 INFO 139984794219904] Epoch[80] Batch[0] avg_epoch_loss=3.056448\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=3.056448221206665\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:38 INFO 139984794219904] Epoch[80] Batch[5] avg_epoch_loss=2.986851\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.9868505398432412\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:38 INFO 139984794219904] Epoch[80] Batch [5]#011Speed: 253.26 samples/sec#011loss=2.986851\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] Epoch[80] Batch[10] avg_epoch_loss=3.054599\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=3.1358960628509522\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] Epoch[80] Batch [10]#011Speed: 241.94 samples/sec#011loss=3.135896\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314836.521, \"EndTime\": 1649314839.67783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3156.754970550537, \"count\": 1, \"min\": 3156.754970550537, \"max\": 3156.754970550537}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=204.63275279091826 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] #progress_metric: host=algo-1, completed 20.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=80, train loss <loss>=3.054598504846746\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:39 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:40 INFO 139984794219904] Epoch[81] Batch[0] avg_epoch_loss=3.308016\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=3.308015823364258\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:41 INFO 139984794219904] Epoch[81] Batch[5] avg_epoch_loss=3.077592\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=3.077592055002848\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:41 INFO 139984794219904] Epoch[81] Batch [5]#011Speed: 249.79 samples/sec#011loss=3.077592\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] Epoch[81] Batch[10] avg_epoch_loss=3.015650\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.9413200855255126\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] Epoch[81] Batch [10]#011Speed: 240.80 samples/sec#011loss=2.941320\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314839.6779096, \"EndTime\": 1649314842.8699975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3191.6277408599854, \"count\": 1, \"min\": 3191.6277408599854, \"max\": 3191.6277408599854}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=204.9033854972398 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] #progress_metric: host=algo-1, completed 20.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=81, train loss <loss>=3.0156502506949683\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:42 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:43 INFO 139984794219904] Epoch[82] Batch[0] avg_epoch_loss=3.050184\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=3.0501835346221924\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:44 INFO 139984794219904] Epoch[82] Batch[5] avg_epoch_loss=3.001963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=3.0019627809524536\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:44 INFO 139984794219904] Epoch[82] Batch [5]#011Speed: 247.00 samples/sec#011loss=3.001963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] Epoch[82] Batch[10] avg_epoch_loss=2.932637\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=2.8494455337524416\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] Epoch[82] Batch [10]#011Speed: 243.95 samples/sec#011loss=2.849446\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314842.8700807, \"EndTime\": 1649314846.079306, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3208.648443222046, \"count\": 1, \"min\": 3208.648443222046, \"max\": 3208.648443222046}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=204.43821644882047 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 20.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.932636759497903\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] Epoch[83] Batch[0] avg_epoch_loss=3.075018\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=3.0750184059143066\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:47 INFO 139984794219904] Epoch[83] Batch[5] avg_epoch_loss=3.017078\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=3.017078081766764\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:47 INFO 139984794219904] Epoch[83] Batch [5]#011Speed: 269.11 samples/sec#011loss=3.017078\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:48 INFO 139984794219904] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314846.079402, \"EndTime\": 1649314848.7755065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2695.4236030578613, \"count\": 1, \"min\": 2695.4236030578613, \"max\": 2695.4236030578613}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:48 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=229.26594631733462 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:48 INFO 139984794219904] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=83, train loss <loss>=3.033814811706543\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:48 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:49 INFO 139984794219904] Epoch[84] Batch[0] avg_epoch_loss=3.001823\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=3.0018227100372314\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:50 INFO 139984794219904] Epoch[84] Batch[5] avg_epoch_loss=2.963604\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.963604211807251\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:50 INFO 139984794219904] Epoch[84] Batch [5]#011Speed: 246.64 samples/sec#011loss=2.963604\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:51 INFO 139984794219904] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314848.775599, \"EndTime\": 1649314851.682364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2906.2094688415527, \"count\": 1, \"min\": 2906.2094688415527, \"max\": 2906.2094688415527}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:51 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.19721324887252 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:51 INFO 139984794219904] #progress_metric: host=algo-1, completed 21.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.9174850940704347\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:51 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:52 INFO 139984794219904] Epoch[85] Batch[0] avg_epoch_loss=3.033102\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=3.0331015586853027\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:53 INFO 139984794219904] Epoch[85] Batch[5] avg_epoch_loss=3.016144\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=3.016143798828125\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:53 INFO 139984794219904] Epoch[85] Batch [5]#011Speed: 247.45 samples/sec#011loss=3.016144\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:54 INFO 139984794219904] Epoch[85] Batch[10] avg_epoch_loss=2.992801\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=2.964789628982544\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:54 INFO 139984794219904] Epoch[85] Batch [10]#011Speed: 239.02 samples/sec#011loss=2.964790\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314851.6824584, \"EndTime\": 1649314855.1554391, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3472.2683429718018, \"count\": 1, \"min\": 3472.2683429718018, \"max\": 3472.2683429718018}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=203.603914745661 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 21.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=85, train loss <loss>=3.0427187085151672\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] Epoch[86] Batch[0] avg_epoch_loss=2.992220\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.992220401763916\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:56 INFO 139984794219904] Epoch[86] Batch[5] avg_epoch_loss=2.932584\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.9325836102167764\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:56 INFO 139984794219904] Epoch[86] Batch [5]#011Speed: 263.69 samples/sec#011loss=2.932584\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:57 INFO 139984794219904] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314855.1555486, \"EndTime\": 1649314857.9013243, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2745.2268600463867, \"count\": 1, \"min\": 2745.2268600463867, \"max\": 2745.2268600463867}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:57 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=226.92805740463498 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:57 INFO 139984794219904] #progress_metric: host=algo-1, completed 21.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.9169386863708495\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:57 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:58 INFO 139984794219904] Epoch[87] Batch[0] avg_epoch_loss=2.862532\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.862532138824463\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:59 INFO 139984794219904] Epoch[87] Batch[5] avg_epoch_loss=2.962953\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.9629527727762857\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:00:59 INFO 139984794219904] Epoch[87] Batch [5]#011Speed: 270.33 samples/sec#011loss=2.962953\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] Epoch[87] Batch[10] avg_epoch_loss=2.892022\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.8069048881530763\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] Epoch[87] Batch [10]#011Speed: 272.32 samples/sec#011loss=2.806905\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314857.901421, \"EndTime\": 1649314860.8271122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2924.9579906463623, \"count\": 1, \"min\": 2924.9579906463623, \"max\": 2924.9579906463623}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.1631732988436 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.8920219161293725\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:00 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:01 INFO 139984794219904] Epoch[88] Batch[0] avg_epoch_loss=2.789564\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.7895641326904297\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:02 INFO 139984794219904] Epoch[88] Batch[5] avg_epoch_loss=2.903004\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.9030044873555503\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:02 INFO 139984794219904] Epoch[88] Batch [5]#011Speed: 258.86 samples/sec#011loss=2.903004\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:03 INFO 139984794219904] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314860.827207, \"EndTime\": 1649314863.589338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2761.502742767334, \"count\": 1, \"min\": 2761.502742767334, \"max\": 2761.502742767334}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:03 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=225.2302510207357 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:03 INFO 139984794219904] #progress_metric: host=algo-1, completed 22.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.8978888750076295\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:03 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:04 INFO 139984794219904] Epoch[89] Batch[0] avg_epoch_loss=2.991940\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.9919395446777344\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:05 INFO 139984794219904] Epoch[89] Batch[5] avg_epoch_loss=2.960435\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.960435072580973\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:05 INFO 139984794219904] Epoch[89] Batch [5]#011Speed: 247.50 samples/sec#011loss=2.960435\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:06 INFO 139984794219904] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314863.5894196, \"EndTime\": 1649314866.5164926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2926.5005588531494, \"count\": 1, \"min\": 2926.5005588531494, \"max\": 2926.5005588531494}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:06 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.81957681556634 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:06 INFO 139984794219904] #progress_metric: host=algo-1, completed 22.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.908742642402649\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:06 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:07 INFO 139984794219904] Epoch[90] Batch[0] avg_epoch_loss=3.094910\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=3.094910144805908\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:08 INFO 139984794219904] Epoch[90] Batch[5] avg_epoch_loss=2.957337\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.957337180773417\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:08 INFO 139984794219904] Epoch[90] Batch [5]#011Speed: 266.25 samples/sec#011loss=2.957337\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] Epoch[90] Batch[10] avg_epoch_loss=2.894836\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.8198339462280275\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] Epoch[90] Batch [10]#011Speed: 267.85 samples/sec#011loss=2.819834\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314866.5166225, \"EndTime\": 1649314869.5540905, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3036.9527339935303, \"count\": 1, \"min\": 3036.9527339935303, \"max\": 3036.9527339935303}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.9475174061314 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] #progress_metric: host=algo-1, completed 22.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.8948357105255127\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:09 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:10 INFO 139984794219904] Epoch[91] Batch[0] avg_epoch_loss=3.000525\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=3.0005249977111816\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:11 INFO 139984794219904] Epoch[91] Batch[5] avg_epoch_loss=2.947483\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.947482943534851\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:11 INFO 139984794219904] Epoch[91] Batch [5]#011Speed: 272.04 samples/sec#011loss=2.947483\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] Epoch[91] Batch[10] avg_epoch_loss=2.985409\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=3.0309197902679443\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] Epoch[91] Batch [10]#011Speed: 270.28 samples/sec#011loss=3.030920\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314869.5541797, \"EndTime\": 1649314872.4606154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2905.8780670166016, \"count\": 1, \"min\": 2905.8780670166016, \"max\": 2905.8780670166016}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.5777056889718 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.9854087829589844\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:12 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:13 INFO 139984794219904] Epoch[92] Batch[0] avg_epoch_loss=2.993203\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.9932029247283936\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:14 INFO 139984794219904] Epoch[92] Batch[5] avg_epoch_loss=2.973525\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.9735251665115356\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:14 INFO 139984794219904] Epoch[92] Batch [5]#011Speed: 266.79 samples/sec#011loss=2.973525\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314872.4607108, \"EndTime\": 1649314875.1841202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2722.809314727783, \"count\": 1, \"min\": 2722.809314727783, \"max\": 2722.809314727783}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=235.04004915926055 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] #progress_metric: host=algo-1, completed 23.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.9597188949584963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] Epoch[93] Batch[0] avg_epoch_loss=3.028702\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=3.0287024974823\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:16 INFO 139984794219904] Epoch[93] Batch[5] avg_epoch_loss=2.900674\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.9006736675898233\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:16 INFO 139984794219904] Epoch[93] Batch [5]#011Speed: 272.31 samples/sec#011loss=2.900674\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] Epoch[93] Batch[10] avg_epoch_loss=2.915842\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=2.9340444087982176\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] Epoch[93] Batch [10]#011Speed: 275.67 samples/sec#011loss=2.934044\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314875.184208, \"EndTime\": 1649314878.0713987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2886.594295501709, \"count\": 1, \"min\": 2886.594295501709, \"max\": 2886.594295501709}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=227.58876407668052 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] #progress_metric: host=algo-1, completed 23.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.9158421863209116\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] Epoch[94] Batch[0] avg_epoch_loss=2.891032\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.8910322189331055\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:19 INFO 139984794219904] Epoch[94] Batch[5] avg_epoch_loss=2.962536\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.962536017100016\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:19 INFO 139984794219904] Epoch[94] Batch [5]#011Speed: 246.87 samples/sec#011loss=2.962536\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:20 INFO 139984794219904] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314878.0715516, \"EndTime\": 1649314880.923073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2850.8641719818115, \"count\": 1, \"min\": 2850.8641719818115, \"max\": 2850.8641719818115}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:20 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.02724192164104 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:20 INFO 139984794219904] #progress_metric: host=algo-1, completed 23.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.9796302556991576\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:20 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:21 INFO 139984794219904] Epoch[95] Batch[0] avg_epoch_loss=2.995764\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.9957637786865234\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:22 INFO 139984794219904] Epoch[95] Batch[5] avg_epoch_loss=2.904982\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.9049822092056274\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:22 INFO 139984794219904] Epoch[95] Batch [5]#011Speed: 253.48 samples/sec#011loss=2.904982\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:23 INFO 139984794219904] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314880.9231644, \"EndTime\": 1649314883.8097088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2885.9684467315674, \"count\": 1, \"min\": 2885.9684467315674, \"max\": 2885.9684467315674}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:23 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.8616972475738 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:23 INFO 139984794219904] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.908424162864685\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:23 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:24 INFO 139984794219904] Epoch[96] Batch[0] avg_epoch_loss=2.882038\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.8820383548736572\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:25 INFO 139984794219904] Epoch[96] Batch[5] avg_epoch_loss=2.895517\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.8955169916152954\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:25 INFO 139984794219904] Epoch[96] Batch [5]#011Speed: 246.54 samples/sec#011loss=2.895517\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:26 INFO 139984794219904] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314883.8098066, \"EndTime\": 1649314886.6877425, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2877.307891845703, \"count\": 1, \"min\": 2877.307891845703, \"max\": 2877.307891845703}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:26 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.98682992844655 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:26 INFO 139984794219904] #progress_metric: host=algo-1, completed 24.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.913990688323975\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:26 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:27 INFO 139984794219904] Epoch[97] Batch[0] avg_epoch_loss=2.916659\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.916659355163574\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:28 INFO 139984794219904] Epoch[97] Batch[5] avg_epoch_loss=2.935199\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.9351987838745117\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:28 INFO 139984794219904] Epoch[97] Batch [5]#011Speed: 269.92 samples/sec#011loss=2.935199\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:29 INFO 139984794219904] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314886.6878362, \"EndTime\": 1649314889.4263625, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2737.9908561706543, \"count\": 1, \"min\": 2737.9908561706543, \"max\": 2737.9908561706543}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:29 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.49325949718965 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:29 INFO 139984794219904] #progress_metric: host=algo-1, completed 24.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.8719706535339355\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:29 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:30 INFO 139984794219904] Epoch[98] Batch[0] avg_epoch_loss=2.946474\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.946474075317383\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:31 INFO 139984794219904] Epoch[98] Batch[5] avg_epoch_loss=2.932018\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.932018438975016\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:31 INFO 139984794219904] Epoch[98] Batch [5]#011Speed: 246.67 samples/sec#011loss=2.932018\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] Epoch[98] Batch[10] avg_epoch_loss=2.863670\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=2.7816511154174806\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] Epoch[98] Batch [10]#011Speed: 245.70 samples/sec#011loss=2.781651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314889.426459, \"EndTime\": 1649314892.6132598, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3186.2988471984863, \"count\": 1, \"min\": 3186.2988471984863, \"max\": 3186.2988471984863}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.44170481950204 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] #progress_metric: host=algo-1, completed 24.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.863669655539773\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:32 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:33 INFO 139984794219904] Epoch[99] Batch[0] avg_epoch_loss=2.851046\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.851045608520508\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:34 INFO 139984794219904] Epoch[99] Batch[5] avg_epoch_loss=2.927533\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.9275328318277993\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:34 INFO 139984794219904] Epoch[99] Batch [5]#011Speed: 245.28 samples/sec#011loss=2.927533\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:35 INFO 139984794219904] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314892.613356, \"EndTime\": 1649314895.560195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2946.167469024658, \"count\": 1, \"min\": 2946.167469024658, \"max\": 2946.167469024658}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:35 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=200.24051460006547 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:35 INFO 139984794219904] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.853200578689575\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:35 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:36 INFO 139984794219904] Epoch[100] Batch[0] avg_epoch_loss=2.922853\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.9228525161743164\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:37 INFO 139984794219904] Epoch[100] Batch[5] avg_epoch_loss=2.890858\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.890858292579651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:37 INFO 139984794219904] Epoch[100] Batch [5]#011Speed: 246.84 samples/sec#011loss=2.890858\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] Epoch[100] Batch[10] avg_epoch_loss=2.854612\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=2.811115550994873\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] Epoch[100] Batch [10]#011Speed: 242.29 samples/sec#011loss=2.811116\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314895.5604382, \"EndTime\": 1649314898.803468, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3242.4912452697754, \"count\": 1, \"min\": 3242.4912452697754, \"max\": 3242.4912452697754}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=201.38067674359047 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] #progress_metric: host=algo-1, completed 25.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.8546115918592974\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:38 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:39 INFO 139984794219904] Epoch[101] Batch[0] avg_epoch_loss=2.854594\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.854593515396118\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:40 INFO 139984794219904] Epoch[101] Batch[5] avg_epoch_loss=2.876311\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.8763107458750405\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:40 INFO 139984794219904] Epoch[101] Batch [5]#011Speed: 246.79 samples/sec#011loss=2.876311\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] Epoch[101] Batch[10] avg_epoch_loss=2.909065\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.948370122909546\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] Epoch[101] Batch [10]#011Speed: 248.26 samples/sec#011loss=2.948370\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314898.8035517, \"EndTime\": 1649314901.9675333, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3163.459062576294, \"count\": 1, \"min\": 3163.459062576294, \"max\": 3163.459062576294}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.95228310894586 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] #progress_metric: host=algo-1, completed 25.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.909065008163452\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:41 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:42 INFO 139984794219904] Epoch[102] Batch[0] avg_epoch_loss=2.723273\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.7232728004455566\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:43 INFO 139984794219904] Epoch[102] Batch[5] avg_epoch_loss=2.874179\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.8741785685221353\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:43 INFO 139984794219904] Epoch[102] Batch [5]#011Speed: 245.47 samples/sec#011loss=2.874179\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] Epoch[102] Batch[10] avg_epoch_loss=2.931863\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=3.001084327697754\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] Epoch[102] Batch [10]#011Speed: 256.72 samples/sec#011loss=3.001084\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314901.9676178, \"EndTime\": 1649314905.106059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3137.805700302124, \"count\": 1, \"min\": 3137.805700302124, \"max\": 3137.805700302124}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.24180161523432 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] #progress_metric: host=algo-1, completed 25.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.9318630045110528\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] Epoch[103] Batch[0] avg_epoch_loss=3.006520\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=3.0065202713012695\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:46 INFO 139984794219904] Epoch[103] Batch[5] avg_epoch_loss=2.877196\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.877196113268534\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:46 INFO 139984794219904] Epoch[103] Batch [5]#011Speed: 259.98 samples/sec#011loss=2.877196\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:47 INFO 139984794219904] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314905.1061513, \"EndTime\": 1649314907.949117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2842.512607574463, \"count\": 1, \"min\": 2842.512607574463, \"max\": 2842.512607574463}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:47 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.08981366911772 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:47 INFO 139984794219904] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.8456891536712647\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:47 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:48 INFO 139984794219904] Epoch[104] Batch[0] avg_epoch_loss=3.009621\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=3.0096213817596436\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:49 INFO 139984794219904] Epoch[104] Batch[5] avg_epoch_loss=2.969654\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.969653765360514\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:49 INFO 139984794219904] Epoch[104] Batch [5]#011Speed: 274.74 samples/sec#011loss=2.969654\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] Epoch[104] Batch[10] avg_epoch_loss=2.982212\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=2.997281885147095\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] Epoch[104] Batch [10]#011Speed: 269.97 samples/sec#011loss=2.997282\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314907.949413, \"EndTime\": 1649314910.874925, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2924.9472618103027, \"count\": 1, \"min\": 2924.9472618103027, \"max\": 2924.9472618103027}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.48045642921855 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] #progress_metric: host=algo-1, completed 26.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.9822120016271416\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:50 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:51 INFO 139984794219904] Epoch[105] Batch[0] avg_epoch_loss=2.798719\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.7987194061279297\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:52 INFO 139984794219904] Epoch[105] Batch[5] avg_epoch_loss=2.850591\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.85059130191803\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:52 INFO 139984794219904] Epoch[105] Batch [5]#011Speed: 275.62 samples/sec#011loss=2.850591\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] Epoch[105] Batch[10] avg_epoch_loss=2.808780\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=2.7586068153381347\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] Epoch[105] Batch [10]#011Speed: 262.80 samples/sec#011loss=2.758607\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314910.87501, \"EndTime\": 1649314913.8432229, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2967.729330062866, \"count\": 1, \"min\": 2967.729330062866, \"max\": 2967.729330062866}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.67568028290194 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] #progress_metric: host=algo-1, completed 26.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.808780171654441\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:53 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_867d6f91-00d9-4d31-b99e-94cc11df73b2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314913.8433187, \"EndTime\": 1649314913.9151607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 71.09761238098145, \"count\": 1, \"min\": 71.09761238098145, \"max\": 71.09761238098145}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:54 INFO 139984794219904] Epoch[106] Batch[0] avg_epoch_loss=2.970018\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.9700183868408203\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:55 INFO 139984794219904] Epoch[106] Batch[5] avg_epoch_loss=2.931383\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.931382894515991\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:55 INFO 139984794219904] Epoch[106] Batch [5]#011Speed: 257.25 samples/sec#011loss=2.931383\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:56 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314913.9152477, \"EndTime\": 1649314916.7711723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2855.8316230773926, \"count\": 1, \"min\": 2855.8316230773926, \"max\": 2855.8316230773926}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:56 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.0913236855449 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:56 INFO 139984794219904] #progress_metric: host=algo-1, completed 26.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.9184966325759887\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:56 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:57 INFO 139984794219904] Epoch[107] Batch[0] avg_epoch_loss=2.950283\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.9502830505371094\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:58 INFO 139984794219904] Epoch[107] Batch[5] avg_epoch_loss=2.942404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.9424040714899697\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:58 INFO 139984794219904] Epoch[107] Batch [5]#011Speed: 248.20 samples/sec#011loss=2.942404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:59 INFO 139984794219904] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314916.7712684, \"EndTime\": 1649314919.719618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2947.812795639038, \"count\": 1, \"min\": 2947.812795639038, \"max\": 2947.812795639038}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:59 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.33270934931915 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:59 INFO 139984794219904] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.9350985527038573\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:01:59 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:00 INFO 139984794219904] Epoch[108] Batch[0] avg_epoch_loss=2.969546\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.969545602798462\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:01 INFO 139984794219904] Epoch[108] Batch[5] avg_epoch_loss=2.885017\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.885017156600952\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:01 INFO 139984794219904] Epoch[108] Batch [5]#011Speed: 261.14 samples/sec#011loss=2.885017\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] Epoch[108] Batch[10] avg_epoch_loss=2.821037\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=2.7442614078521728\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] Epoch[108] Batch [10]#011Speed: 250.64 samples/sec#011loss=2.744261\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314919.7197223, \"EndTime\": 1649314922.8098054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3089.4594192504883, \"count\": 1, \"min\": 3089.4594192504883, \"max\": 3089.4594192504883}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.62134725167385 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] #progress_metric: host=algo-1, completed 27.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.8210372708060523\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:02 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:03 INFO 139984794219904] Epoch[109] Batch[0] avg_epoch_loss=2.848972\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.8489716053009033\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:04 INFO 139984794219904] Epoch[109] Batch[5] avg_epoch_loss=2.911995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.9119948148727417\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:04 INFO 139984794219904] Epoch[109] Batch [5]#011Speed: 252.81 samples/sec#011loss=2.911995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] Epoch[109] Batch[10] avg_epoch_loss=2.923315\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=2.9368995666503905\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] Epoch[109] Batch [10]#011Speed: 245.35 samples/sec#011loss=2.936900\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314922.8098893, \"EndTime\": 1649314925.9287264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3118.38436126709, \"count\": 1, \"min\": 3118.38436126709, \"max\": 3118.38436126709}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.52590329814566 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] #progress_metric: host=algo-1, completed 27.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.923315156589855\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:05 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:06 INFO 139984794219904] Epoch[110] Batch[0] avg_epoch_loss=2.865060\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.865060329437256\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:07 INFO 139984794219904] Epoch[110] Batch[5] avg_epoch_loss=2.889662\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.8896623055140176\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:07 INFO 139984794219904] Epoch[110] Batch [5]#011Speed: 254.08 samples/sec#011loss=2.889662\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:08 INFO 139984794219904] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314925.9287992, \"EndTime\": 1649314928.8658173, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2936.5575313568115, \"count\": 1, \"min\": 2936.5575313568115, \"max\": 2936.5575313568115}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:08 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=200.90707623151863 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:08 INFO 139984794219904] #progress_metric: host=algo-1, completed 27.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.9418580770492553\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:08 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:09 INFO 139984794219904] Epoch[111] Batch[0] avg_epoch_loss=3.006134\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=3.006134033203125\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:10 INFO 139984794219904] Epoch[111] Batch[5] avg_epoch_loss=2.958914\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.958914041519165\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:10 INFO 139984794219904] Epoch[111] Batch [5]#011Speed: 250.94 samples/sec#011loss=2.958914\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:11 INFO 139984794219904] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314928.8659067, \"EndTime\": 1649314931.7028039, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2836.399793624878, \"count\": 1, \"min\": 2836.399793624878, \"max\": 2836.399793624878}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:11 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.45482843001082 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:11 INFO 139984794219904] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.927366304397583\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:11 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:12 INFO 139984794219904] Epoch[112] Batch[0] avg_epoch_loss=2.936143\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.936143159866333\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:13 INFO 139984794219904] Epoch[112] Batch[5] avg_epoch_loss=2.922862\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.922862490018209\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:13 INFO 139984794219904] Epoch[112] Batch [5]#011Speed: 246.46 samples/sec#011loss=2.922862\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:14 INFO 139984794219904] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314931.7029023, \"EndTime\": 1649314934.619321, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2915.897846221924, \"count\": 1, \"min\": 2915.897846221924, \"max\": 2915.897846221924}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:14 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.5886338847854 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:14 INFO 139984794219904] #progress_metric: host=algo-1, completed 28.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.9339432954788207\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:14 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:15 INFO 139984794219904] Epoch[113] Batch[0] avg_epoch_loss=2.915257\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.915257215499878\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:16 INFO 139984794219904] Epoch[113] Batch[5] avg_epoch_loss=2.891505\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.8915048440297446\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:16 INFO 139984794219904] Epoch[113] Batch [5]#011Speed: 245.87 samples/sec#011loss=2.891505\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] Epoch[113] Batch[10] avg_epoch_loss=2.843701\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=2.7863362312316893\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] Epoch[113] Batch [10]#011Speed: 247.34 samples/sec#011loss=2.786336\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314934.6194184, \"EndTime\": 1649314937.7995245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3179.500102996826, \"count\": 1, \"min\": 3179.500102996826, \"max\": 3179.500102996826}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.17634224772155 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] #progress_metric: host=algo-1, completed 28.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.8437009291215376\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:17 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:18 INFO 139984794219904] Epoch[114] Batch[0] avg_epoch_loss=3.035314\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=3.0353143215179443\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:19 INFO 139984794219904] Epoch[114] Batch[5] avg_epoch_loss=2.899712\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.899712006251017\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:19 INFO 139984794219904] Epoch[114] Batch [5]#011Speed: 247.37 samples/sec#011loss=2.899712\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] Epoch[114] Batch[10] avg_epoch_loss=2.940183\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.988749122619629\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] Epoch[114] Batch [10]#011Speed: 259.26 samples/sec#011loss=2.988749\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314937.7996113, \"EndTime\": 1649314940.9418359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3141.6866779327393, \"count\": 1, \"min\": 3141.6866779327393, \"max\": 3141.6866779327393}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.56922079082048 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] #progress_metric: host=algo-1, completed 28.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.9401834227822046\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:20 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:21 INFO 139984794219904] Epoch[115] Batch[0] avg_epoch_loss=3.094273\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=3.094273090362549\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:22 INFO 139984794219904] Epoch[115] Batch[5] avg_epoch_loss=2.984659\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.984659194946289\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:22 INFO 139984794219904] Epoch[115] Batch [5]#011Speed: 249.66 samples/sec#011loss=2.984659\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] Epoch[115] Batch[10] avg_epoch_loss=3.042034\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=3.1108847141265867\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] Epoch[115] Batch [10]#011Speed: 255.24 samples/sec#011loss=3.110885\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314940.94192, \"EndTime\": 1649314944.0642934, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3121.8996047973633, \"count\": 1, \"min\": 3121.8996047973633, \"max\": 3121.8996047973633}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=205.31560057864576 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=115, train loss <loss>=3.0420344309373335\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] Epoch[116] Batch[0] avg_epoch_loss=2.910027\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.910027027130127\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:25 INFO 139984794219904] Epoch[116] Batch[5] avg_epoch_loss=2.913015\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.9130153258641562\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:25 INFO 139984794219904] Epoch[116] Batch [5]#011Speed: 260.60 samples/sec#011loss=2.913015\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:26 INFO 139984794219904] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314944.0643795, \"EndTime\": 1649314946.909187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2844.346523284912, \"count\": 1, \"min\": 2844.346523284912, \"max\": 2844.346523284912}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:26 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.6929362635469 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:26 INFO 139984794219904] #progress_metric: host=algo-1, completed 29.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.9528029680252077\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:26 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:27 INFO 139984794219904] Epoch[117] Batch[0] avg_epoch_loss=2.976645\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.9766454696655273\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:28 INFO 139984794219904] Epoch[117] Batch[5] avg_epoch_loss=2.933300\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.9332996606826782\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:28 INFO 139984794219904] Epoch[117] Batch [5]#011Speed: 245.24 samples/sec#011loss=2.933300\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] Epoch[117] Batch[10] avg_epoch_loss=2.950407\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=2.9709359645843505\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] Epoch[117] Batch [10]#011Speed: 247.72 samples/sec#011loss=2.970936\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314946.9092808, \"EndTime\": 1649314950.090592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3180.8393001556396, \"count\": 1, \"min\": 3180.8393001556396, \"max\": 3180.8393001556396}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=204.96997223855965 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] #progress_metric: host=algo-1, completed 29.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.9504070715470747\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] Epoch[118] Batch[0] avg_epoch_loss=2.938962\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.938962459564209\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:31 INFO 139984794219904] Epoch[118] Batch[5] avg_epoch_loss=2.946804\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.9468039671579995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:31 INFO 139984794219904] Epoch[118] Batch [5]#011Speed: 265.43 samples/sec#011loss=2.946804\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] Epoch[118] Batch[10] avg_epoch_loss=2.951574\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=2.9572991371154784\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] Epoch[118] Batch [10]#011Speed: 257.56 samples/sec#011loss=2.957299\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314950.0906672, \"EndTime\": 1649314953.1441088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3052.988290786743, \"count\": 1, \"min\": 3052.988290786743, \"max\": 3052.988290786743}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.84579372875402 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] #progress_metric: host=algo-1, completed 29.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.9515744989568535\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] Epoch[119] Batch[0] avg_epoch_loss=2.853284\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.853283643722534\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:34 INFO 139984794219904] Epoch[119] Batch[5] avg_epoch_loss=2.896987\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.8969865640004477\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:34 INFO 139984794219904] Epoch[119] Batch [5]#011Speed: 256.27 samples/sec#011loss=2.896987\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] Epoch[119] Batch[10] avg_epoch_loss=2.944546\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=3.001617431640625\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] Epoch[119] Batch [10]#011Speed: 240.94 samples/sec#011loss=3.001617\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314953.1441808, \"EndTime\": 1649314956.27123, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3126.464366912842, \"count\": 1, \"min\": 3126.464366912842, \"max\": 3126.464366912842}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.73247960020302 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.9445460492914375\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] Epoch[120] Batch[0] avg_epoch_loss=2.734878\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.7348780632019043\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:38 INFO 139984794219904] Epoch[120] Batch[5] avg_epoch_loss=2.902007\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.9020069440205893\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:38 INFO 139984794219904] Epoch[120] Batch [5]#011Speed: 263.09 samples/sec#011loss=2.902007\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314956.2713041, \"EndTime\": 1649314959.0682335, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2796.40793800354, \"count\": 1, \"min\": 2796.40793800354, \"max\": 2796.40793800354}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=227.06620479022885 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] #progress_metric: host=algo-1, completed 30.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.891280102729797\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] Epoch[121] Batch[0] avg_epoch_loss=2.895227\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.8952274322509766\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:40 INFO 139984794219904] Epoch[121] Batch[5] avg_epoch_loss=2.882830\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.8828299840291343\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:40 INFO 139984794219904] Epoch[121] Batch [5]#011Speed: 263.06 samples/sec#011loss=2.882830\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] Epoch[121] Batch[10] avg_epoch_loss=2.921215\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=2.9672759532928468\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] Epoch[121] Batch [10]#011Speed: 250.31 samples/sec#011loss=2.967276\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314959.0683286, \"EndTime\": 1649314962.1562726, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3087.4240398406982, \"count\": 1, \"min\": 3087.4240398406982, \"max\": 3087.4240398406982}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.49522543563816 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] #progress_metric: host=algo-1, completed 30.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.9212145155126397\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] Epoch[122] Batch[0] avg_epoch_loss=2.758314\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.7583141326904297\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:44 INFO 139984794219904] Epoch[122] Batch[5] avg_epoch_loss=2.848835\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.848835031191508\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:44 INFO 139984794219904] Epoch[122] Batch [5]#011Speed: 246.79 samples/sec#011loss=2.848835\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] Epoch[122] Batch[10] avg_epoch_loss=2.788376\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.715825986862183\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] Epoch[122] Batch [10]#011Speed: 247.25 samples/sec#011loss=2.715826\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314962.1563494, \"EndTime\": 1649314965.3467042, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3189.899682998657, \"count\": 1, \"min\": 3189.899682998657, \"max\": 3189.899682998657}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.46268409408702 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] #progress_metric: host=algo-1, completed 30.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.7883763746781782\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_fa70eaf6-8685-4696-8bf5-1eeb45d1dd94-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314965.3467877, \"EndTime\": 1649314965.4320183, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 84.73467826843262, \"count\": 1, \"min\": 84.73467826843262, \"max\": 84.73467826843262}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] Epoch[123] Batch[0] avg_epoch_loss=2.843693\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.843693256378174\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:47 INFO 139984794219904] Epoch[123] Batch[5] avg_epoch_loss=2.862736\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.862736384073893\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:47 INFO 139984794219904] Epoch[123] Batch [5]#011Speed: 250.53 samples/sec#011loss=2.862736\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] processed a total of 576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314965.432106, \"EndTime\": 1649314968.0474422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2615.267038345337, \"count\": 1, \"min\": 2615.267038345337, \"max\": 2615.267038345337}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.23423314853153 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.869502994749281\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] Epoch[124] Batch[0] avg_epoch_loss=2.884378\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.8843777179718018\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:49 INFO 139984794219904] Epoch[124] Batch[5] avg_epoch_loss=2.806672\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.806671977043152\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:49 INFO 139984794219904] Epoch[124] Batch [5]#011Speed: 257.17 samples/sec#011loss=2.806672\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:50 INFO 139984794219904] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314968.0475333, \"EndTime\": 1649314970.889645, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2841.0024642944336, \"count\": 1, \"min\": 2841.0024642944336, \"max\": 2841.0024642944336}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:50 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.8452745765545 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:50 INFO 139984794219904] #progress_metric: host=algo-1, completed 31.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.814155673980713\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:50 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:51 INFO 139984794219904] Epoch[125] Batch[0] avg_epoch_loss=2.838880\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.8388795852661133\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:52 INFO 139984794219904] Epoch[125] Batch[5] avg_epoch_loss=2.861936\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.861936370531718\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:52 INFO 139984794219904] Epoch[125] Batch [5]#011Speed: 251.58 samples/sec#011loss=2.861936\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] Epoch[125] Batch[10] avg_epoch_loss=2.942390\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=3.0389343738555907\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] Epoch[125] Batch [10]#011Speed: 255.09 samples/sec#011loss=3.038934\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314970.8897324, \"EndTime\": 1649314974.007362, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3117.1224117279053, \"count\": 1, \"min\": 3117.1224117279053, \"max\": 3117.1224117279053}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.23378395411476 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] #progress_metric: host=algo-1, completed 31.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.9423900084062056\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] Epoch[126] Batch[0] avg_epoch_loss=2.907752\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.9077517986297607\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:55 INFO 139984794219904] Epoch[126] Batch[5] avg_epoch_loss=2.916903\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.9169031778971353\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:55 INFO 139984794219904] Epoch[126] Batch [5]#011Speed: 247.33 samples/sec#011loss=2.916903\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] Epoch[126] Batch[10] avg_epoch_loss=2.934152\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.9548502922058106\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] Epoch[126] Batch [10]#011Speed: 252.95 samples/sec#011loss=2.954850\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314974.0074492, \"EndTime\": 1649314977.1335626, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3125.5741119384766, \"count\": 1, \"min\": 3125.5741119384766, \"max\": 3125.5741119384766}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.3536825154144 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] #progress_metric: host=algo-1, completed 31.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.9341518662192603\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] Epoch[127] Batch[0] avg_epoch_loss=2.961625\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.96162486076355\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:58 INFO 139984794219904] Epoch[127] Batch[5] avg_epoch_loss=2.863877\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.8638773361841836\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:02:58 INFO 139984794219904] Epoch[127] Batch [5]#011Speed: 253.00 samples/sec#011loss=2.863877\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314977.1336455, \"EndTime\": 1649314980.0464506, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2912.320137023926, \"count\": 1, \"min\": 2912.320137023926, \"max\": 2912.320137023926}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.5579381926688 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.864777946472168\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] Epoch[128] Batch[0] avg_epoch_loss=2.886809\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.8868093490600586\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:01 INFO 139984794219904] Epoch[128] Batch[5] avg_epoch_loss=2.896852\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.896851897239685\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:01 INFO 139984794219904] Epoch[128] Batch [5]#011Speed: 242.38 samples/sec#011loss=2.896852\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:02 INFO 139984794219904] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314980.0466468, \"EndTime\": 1649314982.9975457, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2950.4010677337646, \"count\": 1, \"min\": 2950.4010677337646, \"max\": 2950.4010677337646}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:02 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.84306096042133 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:02 INFO 139984794219904] #progress_metric: host=algo-1, completed 32.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.837530255317688\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:02 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:03 INFO 139984794219904] Epoch[129] Batch[0] avg_epoch_loss=2.742227\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.74222731590271\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:04 INFO 139984794219904] Epoch[129] Batch[5] avg_epoch_loss=2.811494\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.8114942709604898\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:04 INFO 139984794219904] Epoch[129] Batch [5]#011Speed: 242.67 samples/sec#011loss=2.811494\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:05 INFO 139984794219904] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314982.997643, \"EndTime\": 1649314985.977491, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2979.3145656585693, \"count\": 1, \"min\": 2979.3145656585693, \"max\": 2979.3145656585693}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:05 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.07869968819756 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:05 INFO 139984794219904] #progress_metric: host=algo-1, completed 32.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.875887870788574\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:05 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:06 INFO 139984794219904] Epoch[130] Batch[0] avg_epoch_loss=2.764931\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.7649307250976562\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:07 INFO 139984794219904] Epoch[130] Batch[5] avg_epoch_loss=2.790249\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.7902485132217407\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:07 INFO 139984794219904] Epoch[130] Batch [5]#011Speed: 249.51 samples/sec#011loss=2.790249\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:08 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314985.977574, \"EndTime\": 1649314988.9517062, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2973.649501800537, \"count\": 1, \"min\": 2973.649501800537, \"max\": 2973.649501800537}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:08 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.52855090684872 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:08 INFO 139984794219904] #progress_metric: host=algo-1, completed 32.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.835889530181885\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:08 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:09 INFO 139984794219904] Epoch[131] Batch[0] avg_epoch_loss=2.773389\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.7733888626098633\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:10 INFO 139984794219904] Epoch[131] Batch[5] avg_epoch_loss=2.830668\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.830668012301127\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:10 INFO 139984794219904] Epoch[131] Batch [5]#011Speed: 267.79 samples/sec#011loss=2.830668\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] Epoch[131] Batch[10] avg_epoch_loss=2.883965\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=2.9479214191436767\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] Epoch[131] Batch [10]#011Speed: 243.82 samples/sec#011loss=2.947921\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314988.951855, \"EndTime\": 1649314992.030397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3077.9688358306885, \"count\": 1, \"min\": 3077.9688358306885, \"max\": 3077.9688358306885}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.74314598926298 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.883965015411377\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] Epoch[132] Batch[0] avg_epoch_loss=2.770812\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.7708122730255127\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:13 INFO 139984794219904] Epoch[132] Batch[5] avg_epoch_loss=2.854077\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.8540769815444946\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:13 INFO 139984794219904] Epoch[132] Batch [5]#011Speed: 274.68 samples/sec#011loss=2.854077\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:14 INFO 139984794219904] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314992.0304782, \"EndTime\": 1649314994.704074, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2673.1061935424805, \"count\": 1, \"min\": 2673.1061935424805, \"max\": 2673.1061935424805}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:14 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=233.42569558920363 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:14 INFO 139984794219904] #progress_metric: host=algo-1, completed 33.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.840773177146912\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:14 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:15 INFO 139984794219904] Epoch[133] Batch[0] avg_epoch_loss=2.811409\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.8114092350006104\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:16 INFO 139984794219904] Epoch[133] Batch[5] avg_epoch_loss=2.881877\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.8818766276041665\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:16 INFO 139984794219904] Epoch[133] Batch [5]#011Speed: 246.30 samples/sec#011loss=2.881877\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] Epoch[133] Batch[10] avg_epoch_loss=2.818592\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=2.7426513671875\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] Epoch[133] Batch [10]#011Speed: 241.04 samples/sec#011loss=2.742651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314994.7041473, \"EndTime\": 1649314997.9219646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3217.2482013702393, \"count\": 1, \"min\": 3217.2482013702393, \"max\": 3217.2482013702393}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.00092369891283 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] #progress_metric: host=algo-1, completed 33.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.8185924183238638\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:17 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:18 INFO 139984794219904] Epoch[134] Batch[0] avg_epoch_loss=2.877179\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.8771793842315674\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:19 INFO 139984794219904] Epoch[134] Batch[5] avg_epoch_loss=2.776002\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.7760016918182373\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:19 INFO 139984794219904] Epoch[134] Batch [5]#011Speed: 272.26 samples/sec#011loss=2.776002\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] Epoch[134] Batch[10] avg_epoch_loss=2.852925\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.9452335834503174\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] Epoch[134] Batch [10]#011Speed: 256.86 samples/sec#011loss=2.945234\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649314997.9220524, \"EndTime\": 1649315000.9665675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3043.956995010376, \"count\": 1, \"min\": 3043.956995010376, \"max\": 3043.956995010376}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.18585335522064 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] #progress_metric: host=algo-1, completed 33.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.852925278923728\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:20 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:21 INFO 139984794219904] Epoch[135] Batch[0] avg_epoch_loss=2.885326\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.885326385498047\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:22 INFO 139984794219904] Epoch[135] Batch[5] avg_epoch_loss=2.842687\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.842686891555786\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:22 INFO 139984794219904] Epoch[135] Batch [5]#011Speed: 273.71 samples/sec#011loss=2.842687\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:23 INFO 139984794219904] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315000.9666595, \"EndTime\": 1649315003.6530085, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2685.802698135376, \"count\": 1, \"min\": 2685.802698135376, \"max\": 2685.802698135376}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:23 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=233.06673720595194 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:23 INFO 139984794219904] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.87345712184906\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:23 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:24 INFO 139984794219904] Epoch[136] Batch[0] avg_epoch_loss=2.824915\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.8249154090881348\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:25 INFO 139984794219904] Epoch[136] Batch[5] avg_epoch_loss=2.810562\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.8105616172154746\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:25 INFO 139984794219904] Epoch[136] Batch [5]#011Speed: 266.02 samples/sec#011loss=2.810562\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] Epoch[136] Batch[10] avg_epoch_loss=2.820904\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=2.833315134048462\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] Epoch[136] Batch [10]#011Speed: 260.24 samples/sec#011loss=2.833315\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315003.6530907, \"EndTime\": 1649315006.6188066, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2965.0914669036865, \"count\": 1, \"min\": 2965.0914669036865, \"max\": 2965.0914669036865}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=225.27812441681303 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] #progress_metric: host=algo-1, completed 34.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.8209041248668325\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:26 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:27 INFO 139984794219904] Epoch[137] Batch[0] avg_epoch_loss=2.920346\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.92034649848938\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:28 INFO 139984794219904] Epoch[137] Batch[5] avg_epoch_loss=2.851690\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.851689577102661\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:28 INFO 139984794219904] Epoch[137] Batch [5]#011Speed: 245.38 samples/sec#011loss=2.851690\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] Epoch[137] Batch[10] avg_epoch_loss=2.891486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=2.9392418384552004\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] Epoch[137] Batch [10]#011Speed: 245.53 samples/sec#011loss=2.939242\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315006.6188965, \"EndTime\": 1649315009.8025894, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3183.06565284729, \"count\": 1, \"min\": 3183.06565284729, \"max\": 3183.06565284729}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=202.94146319432028 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] #progress_metric: host=algo-1, completed 34.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.8914860595356333\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:29 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:30 INFO 139984794219904] Epoch[138] Batch[0] avg_epoch_loss=2.988149\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.9881486892700195\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:31 INFO 139984794219904] Epoch[138] Batch[5] avg_epoch_loss=2.902569\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.902569055557251\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:31 INFO 139984794219904] Epoch[138] Batch [5]#011Speed: 252.62 samples/sec#011loss=2.902569\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] Epoch[138] Batch[10] avg_epoch_loss=2.930386\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.9637656211853027\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] Epoch[138] Batch [10]#011Speed: 252.49 samples/sec#011loss=2.963766\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315009.8026712, \"EndTime\": 1649315012.902657, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3099.407196044922, \"count\": 1, \"min\": 3099.407196044922, \"max\": 3099.407196044922}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.1274299026385 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] #progress_metric: host=algo-1, completed 34.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.9303856762972744\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:32 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:33 INFO 139984794219904] Epoch[139] Batch[0] avg_epoch_loss=2.917554\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.9175539016723633\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:34 INFO 139984794219904] Epoch[139] Batch[5] avg_epoch_loss=2.875257\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.875257054964701\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:34 INFO 139984794219904] Epoch[139] Batch [5]#011Speed: 270.66 samples/sec#011loss=2.875257\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:35 INFO 139984794219904] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315012.9027464, \"EndTime\": 1649315015.6328828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2729.684591293335, \"count\": 1, \"min\": 2729.684591293335, \"max\": 2729.684591293335}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:35 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=231.51788385607392 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:35 INFO 139984794219904] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.8643696784973143\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:35 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:36 INFO 139984794219904] Epoch[140] Batch[0] avg_epoch_loss=2.905573\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.9055728912353516\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:37 INFO 139984794219904] Epoch[140] Batch[5] avg_epoch_loss=2.877248\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.8772480487823486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:37 INFO 139984794219904] Epoch[140] Batch [5]#011Speed: 257.02 samples/sec#011loss=2.877248\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:38 INFO 139984794219904] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315015.632971, \"EndTime\": 1649315018.501545, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2867.943525314331, \"count\": 1, \"min\": 2867.943525314331, \"max\": 2867.943525314331}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:38 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.65895153708226 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:38 INFO 139984794219904] #progress_metric: host=algo-1, completed 35.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.880436873435974\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:38 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:39 INFO 139984794219904] Epoch[141] Batch[0] avg_epoch_loss=2.823946\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.8239457607269287\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:40 INFO 139984794219904] Epoch[141] Batch[5] avg_epoch_loss=2.872816\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.8728155295054116\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:40 INFO 139984794219904] Epoch[141] Batch [5]#011Speed: 255.50 samples/sec#011loss=2.872816\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315018.5016382, \"EndTime\": 1649315021.3257754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2823.5816955566406, \"count\": 1, \"min\": 2823.5816955566406, \"max\": 2823.5816955566406}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.56819897941133 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] #progress_metric: host=algo-1, completed 35.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.836474633216858\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] Epoch[142] Batch[0] avg_epoch_loss=2.903458\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.9034583568573\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:43 INFO 139984794219904] Epoch[142] Batch[5] avg_epoch_loss=2.848064\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.848064422607422\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:43 INFO 139984794219904] Epoch[142] Batch [5]#011Speed: 258.00 samples/sec#011loss=2.848064\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] Epoch[142] Batch[10] avg_epoch_loss=2.821026\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.7885793685913085\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] Epoch[142] Batch [10]#011Speed: 274.27 samples/sec#011loss=2.788579\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315021.3258731, \"EndTime\": 1649315024.3416255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3015.2761936187744, \"count\": 1, \"min\": 3015.2761936187744, \"max\": 3015.2761936187744}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.2272562562774 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] #progress_metric: host=algo-1, completed 35.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.821025761691007\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] Epoch[143] Batch[0] avg_epoch_loss=2.831415\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.8314149379730225\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:46 INFO 139984794219904] Epoch[143] Batch[5] avg_epoch_loss=2.879377\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.8793769677480063\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:46 INFO 139984794219904] Epoch[143] Batch [5]#011Speed: 265.33 samples/sec#011loss=2.879377\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315024.3417242, \"EndTime\": 1649315027.1167498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2774.4662761688232, \"count\": 1, \"min\": 2774.4662761688232, \"max\": 2774.4662761688232}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.88161135196887 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.8086288213729858\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] Epoch[144] Batch[0] avg_epoch_loss=2.889211\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.8892109394073486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:48 INFO 139984794219904] Epoch[144] Batch[5] avg_epoch_loss=2.835156\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.835155963897705\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:48 INFO 139984794219904] Epoch[144] Batch [5]#011Speed: 252.37 samples/sec#011loss=2.835156\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315027.1169164, \"EndTime\": 1649315030.0185497, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2901.102066040039, \"count\": 1, \"min\": 2901.102066040039, \"max\": 2901.102066040039}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.87158055148365 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] #progress_metric: host=algo-1, completed 36.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.8321057319641114\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] Epoch[145] Batch[0] avg_epoch_loss=2.834953\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.8349530696868896\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:51 INFO 139984794219904] Epoch[145] Batch[5] avg_epoch_loss=2.866463\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.8664631446202598\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:51 INFO 139984794219904] Epoch[145] Batch [5]#011Speed: 261.68 samples/sec#011loss=2.866463\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:52 INFO 139984794219904] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315030.0186453, \"EndTime\": 1649315032.8024194, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2783.243417739868, \"count\": 1, \"min\": 2783.243417739868, \"max\": 2783.243417739868}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=228.5000019273106 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 36.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.8547258377075195\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:52 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:53 INFO 139984794219904] Epoch[146] Batch[0] avg_epoch_loss=2.804735\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.804734945297241\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:54 INFO 139984794219904] Epoch[146] Batch[5] avg_epoch_loss=2.817217\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.817216634750366\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:54 INFO 139984794219904] Epoch[146] Batch [5]#011Speed: 265.32 samples/sec#011loss=2.817217\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:55 INFO 139984794219904] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315032.8025086, \"EndTime\": 1649315035.6172094, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2814.187526702881, \"count\": 1, \"min\": 2814.187526702881, \"max\": 2814.187526702881}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.14463390959045 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 36.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.8045878648757934\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:56 INFO 139984794219904] Epoch[147] Batch[0] avg_epoch_loss=2.871909\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.8719093799591064\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:57 INFO 139984794219904] Epoch[147] Batch[5] avg_epoch_loss=2.879599\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.87959877649943\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:57 INFO 139984794219904] Epoch[147] Batch [5]#011Speed: 271.51 samples/sec#011loss=2.879599\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] Epoch[147] Batch[10] avg_epoch_loss=2.919651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=2.9677145004272463\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] Epoch[147] Batch [10]#011Speed: 272.32 samples/sec#011loss=2.967715\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315035.6173058, \"EndTime\": 1649315038.5537782, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2935.9476566314697, \"count\": 1, \"min\": 2935.9476566314697, \"max\": 2935.9476566314697}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.0017423912995 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.9196513782848013\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:58 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:59 INFO 139984794219904] Epoch[148] Batch[0] avg_epoch_loss=2.797051\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:03:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.797050714492798\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:00 INFO 139984794219904] Epoch[148] Batch[5] avg_epoch_loss=2.858126\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.858125607172648\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:00 INFO 139984794219904] Epoch[148] Batch [5]#011Speed: 249.14 samples/sec#011loss=2.858126\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:01 INFO 139984794219904] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315038.5538526, \"EndTime\": 1649315041.4440978, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2889.7690773010254, \"count\": 1, \"min\": 2889.7690773010254, \"max\": 2889.7690773010254}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:01 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.88402589535121 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:01 INFO 139984794219904] #progress_metric: host=algo-1, completed 37.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.853088355064392\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:01 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:02 INFO 139984794219904] Epoch[149] Batch[0] avg_epoch_loss=2.928607\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.9286065101623535\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:03 INFO 139984794219904] Epoch[149] Batch[5] avg_epoch_loss=2.871161\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.8711605866750083\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:03 INFO 139984794219904] Epoch[149] Batch [5]#011Speed: 252.56 samples/sec#011loss=2.871161\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:04 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315041.4442058, \"EndTime\": 1649315044.4217331, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2976.9489765167236, \"count\": 1, \"min\": 2976.9489765167236, \"max\": 2976.9489765167236}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.30378669038026 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.8526368618011473\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:05 INFO 139984794219904] Epoch[150] Batch[0] avg_epoch_loss=2.800179\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.8001792430877686\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:06 INFO 139984794219904] Epoch[150] Batch[5] avg_epoch_loss=2.871193\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.871192971865336\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:06 INFO 139984794219904] Epoch[150] Batch [5]#011Speed: 239.46 samples/sec#011loss=2.871193\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315044.4218192, \"EndTime\": 1649315047.3818603, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2959.449529647827, \"count\": 1, \"min\": 2959.449529647827, \"max\": 2959.449529647827}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.2194856777169 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 37.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.8224935054779055\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] Epoch[151] Batch[0] avg_epoch_loss=2.709479\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.7094790935516357\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:09 INFO 139984794219904] Epoch[151] Batch[5] avg_epoch_loss=2.780356\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.7803561290105185\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:09 INFO 139984794219904] Epoch[151] Batch [5]#011Speed: 249.19 samples/sec#011loss=2.780356\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315047.381952, \"EndTime\": 1649315050.2728748, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2890.3980255126953, \"count\": 1, \"min\": 2890.3980255126953, \"max\": 2890.3980255126953}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.57152240004044 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.763289976119995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_4e5ef5c1-f552-4a36-b5c3-791cf6761adc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315050.2730074, \"EndTime\": 1649315050.3598104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 86.26270294189453, \"count\": 1, \"min\": 86.26270294189453, \"max\": 86.26270294189453}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] Epoch[152] Batch[0] avg_epoch_loss=2.936500\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.93649959564209\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:12 INFO 139984794219904] Epoch[152] Batch[5] avg_epoch_loss=2.831966\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.8319655656814575\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:12 INFO 139984794219904] Epoch[152] Batch [5]#011Speed: 251.66 samples/sec#011loss=2.831966\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] Epoch[152] Batch[10] avg_epoch_loss=2.818526\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=2.8023983955383303\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] Epoch[152] Batch [10]#011Speed: 240.73 samples/sec#011loss=2.802398\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315050.3599143, \"EndTime\": 1649315053.5290341, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3169.048070907593, \"count\": 1, \"min\": 3169.048070907593, \"max\": 3169.048070907593}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.30424909119893 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 38.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.818525942889127\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:14 INFO 139984794219904] Epoch[153] Batch[0] avg_epoch_loss=2.844773\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.8447728157043457\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:15 INFO 139984794219904] Epoch[153] Batch[5] avg_epoch_loss=2.794825\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.7948246399561563\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:15 INFO 139984794219904] Epoch[153] Batch [5]#011Speed: 268.03 samples/sec#011loss=2.794825\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315053.529131, \"EndTime\": 1649315056.2563488, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2726.611614227295, \"count\": 1, \"min\": 2726.611614227295, \"max\": 2726.611614227295}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=229.21028669297814 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] #progress_metric: host=algo-1, completed 38.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.8010928630828857\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] Epoch[154] Batch[0] avg_epoch_loss=2.838351\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.8383514881134033\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:18 INFO 139984794219904] Epoch[154] Batch[5] avg_epoch_loss=2.818597\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.818597197532654\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:18 INFO 139984794219904] Epoch[154] Batch [5]#011Speed: 247.07 samples/sec#011loss=2.818597\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] Epoch[154] Batch[10] avg_epoch_loss=2.895844\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=2.988540601730347\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] Epoch[154] Batch [10]#011Speed: 251.91 samples/sec#011loss=2.988541\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315056.256447, \"EndTime\": 1649315059.420478, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3163.398027420044, \"count\": 1, \"min\": 3163.398027420044, \"max\": 3163.398027420044}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=203.57114468175416 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] #progress_metric: host=algo-1, completed 38.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.895844199440696\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:19 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:20 INFO 139984794219904] Epoch[155] Batch[0] avg_epoch_loss=2.800242\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.8002421855926514\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:21 INFO 139984794219904] Epoch[155] Batch[5] avg_epoch_loss=2.829031\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.829031149546305\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:21 INFO 139984794219904] Epoch[155] Batch [5]#011Speed: 246.86 samples/sec#011loss=2.829031\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] Epoch[155] Batch[10] avg_epoch_loss=2.760578\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.67843337059021\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] Epoch[155] Batch [10]#011Speed: 259.74 samples/sec#011loss=2.678433\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315059.4205568, \"EndTime\": 1649315062.5583274, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3137.296199798584, \"count\": 1, \"min\": 3137.296199798584, \"max\": 3137.296199798584}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=205.26424875506203 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.760577613657171\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:22 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_32e2e78b-e243-44b3-b415-3473700b7cb8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315062.558414, \"EndTime\": 1649315062.645999, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.08596229553223, \"count\": 1, \"min\": 87.08596229553223, \"max\": 87.08596229553223}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:23 INFO 139984794219904] Epoch[156] Batch[0] avg_epoch_loss=2.759790\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.7597899436950684\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:24 INFO 139984794219904] Epoch[156] Batch[5] avg_epoch_loss=2.832849\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.832849462827047\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:24 INFO 139984794219904] Epoch[156] Batch [5]#011Speed: 251.28 samples/sec#011loss=2.832849\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:25 INFO 139984794219904] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315062.6460783, \"EndTime\": 1649315065.5368116, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2890.666961669922, \"count\": 1, \"min\": 2890.666961669922, \"max\": 2890.666961669922}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.1275418774726 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 39.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.821711707115173\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:25 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:26 INFO 139984794219904] Epoch[157] Batch[0] avg_epoch_loss=2.834299\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.834299087524414\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:27 INFO 139984794219904] Epoch[157] Batch[5] avg_epoch_loss=2.857011\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.85701056321462\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:27 INFO 139984794219904] Epoch[157] Batch [5]#011Speed: 248.10 samples/sec#011loss=2.857011\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] Epoch[157] Batch[10] avg_epoch_loss=2.822279\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=2.780600166320801\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] Epoch[157] Batch [10]#011Speed: 250.66 samples/sec#011loss=2.780600\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315065.5369084, \"EndTime\": 1649315068.7037787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3166.36061668396, \"count\": 1, \"min\": 3166.36061668396, \"max\": 3166.36061668396}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.00655646465307 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 39.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.8222785646265205\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:28 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:29 INFO 139984794219904] Epoch[158] Batch[0] avg_epoch_loss=2.789654\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.789654493331909\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:30 INFO 139984794219904] Epoch[158] Batch[5] avg_epoch_loss=2.830239\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.8302388191223145\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:30 INFO 139984794219904] Epoch[158] Batch [5]#011Speed: 270.76 samples/sec#011loss=2.830239\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:31 INFO 139984794219904] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315068.7039444, \"EndTime\": 1649315071.4546564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2750.2048015594482, \"count\": 1, \"min\": 2750.2048015594482, \"max\": 2750.2048015594482}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:31 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=231.2441784503145 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:31 INFO 139984794219904] #progress_metric: host=algo-1, completed 39.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.8042396783828734\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:31 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:32 INFO 139984794219904] Epoch[159] Batch[0] avg_epoch_loss=2.879850\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.879850387573242\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:33 INFO 139984794219904] Epoch[159] Batch[5] avg_epoch_loss=2.835772\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.835772395133972\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:33 INFO 139984794219904] Epoch[159] Batch [5]#011Speed: 276.05 samples/sec#011loss=2.835772\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] processed a total of 588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315071.4547484, \"EndTime\": 1649315074.1140916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2658.7393283843994, \"count\": 1, \"min\": 2658.7393283843994, \"max\": 2658.7393283843994}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.1483040474633 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.8763152599334716\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] Epoch[160] Batch[0] avg_epoch_loss=2.748724\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.7487239837646484\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:35 INFO 139984794219904] Epoch[160] Batch[5] avg_epoch_loss=2.796427\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.796426852544149\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:35 INFO 139984794219904] Epoch[160] Batch [5]#011Speed: 251.37 samples/sec#011loss=2.796427\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:36 INFO 139984794219904] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315074.1141653, \"EndTime\": 1649315076.9471612, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2832.561492919922, \"count\": 1, \"min\": 2832.561492919922, \"max\": 2832.561492919922}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:36 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.16654111815998 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:36 INFO 139984794219904] #progress_metric: host=algo-1, completed 40.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.783007502555847\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:36 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:37 INFO 139984794219904] Epoch[161] Batch[0] avg_epoch_loss=2.832872\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.832872152328491\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:38 INFO 139984794219904] Epoch[161] Batch[5] avg_epoch_loss=2.807404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.8074039220809937\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:38 INFO 139984794219904] Epoch[161] Batch [5]#011Speed: 247.63 samples/sec#011loss=2.807404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] Epoch[161] Batch[10] avg_epoch_loss=2.826445\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=2.8492948532104494\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] Epoch[161] Batch [10]#011Speed: 247.79 samples/sec#011loss=2.849295\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315076.9472563, \"EndTime\": 1649315080.1220648, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3174.238920211792, \"count\": 1, \"min\": 3174.238920211792, \"max\": 3174.238920211792}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.545283013908 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 40.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.8264452544125644\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] Epoch[162] Batch[0] avg_epoch_loss=2.918692\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.918692111968994\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:41 INFO 139984794219904] Epoch[162] Batch[5] avg_epoch_loss=2.831515\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.831514596939087\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:41 INFO 139984794219904] Epoch[162] Batch [5]#011Speed: 270.25 samples/sec#011loss=2.831515\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] Epoch[162] Batch[10] avg_epoch_loss=2.812408\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=2.7894800662994386\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] Epoch[162] Batch [10]#011Speed: 262.03 samples/sec#011loss=2.789480\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315080.1221528, \"EndTime\": 1649315083.0880418, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2965.3022289276123, \"count\": 1, \"min\": 2965.3022289276123, \"max\": 2965.3022289276123}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=229.643741186824 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] #progress_metric: host=algo-1, completed 40.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.8124079921028833\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] Epoch[163] Batch[0] avg_epoch_loss=2.791206\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.791205644607544\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:44 INFO 139984794219904] Epoch[163] Batch[5] avg_epoch_loss=2.792871\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.7928707599639893\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:44 INFO 139984794219904] Epoch[163] Batch [5]#011Speed: 268.67 samples/sec#011loss=2.792871\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] Epoch[163] Batch[10] avg_epoch_loss=2.762941\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=2.7270243167877197\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] Epoch[163] Batch [10]#011Speed: 261.84 samples/sec#011loss=2.727024\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315083.0881655, \"EndTime\": 1649315086.0712636, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2982.6483726501465, \"count\": 1, \"min\": 2982.6483726501465, \"max\": 2982.6483726501465}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=217.91709663160603 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.7629405585202305\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] Epoch[164] Batch[0] avg_epoch_loss=2.871537\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.87153697013855\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:47 INFO 139984794219904] Epoch[164] Batch[5] avg_epoch_loss=2.808945\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.8089447816212973\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:47 INFO 139984794219904] Epoch[164] Batch [5]#011Speed: 245.78 samples/sec#011loss=2.808945\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] Epoch[164] Batch[10] avg_epoch_loss=2.852678\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.9051580905914305\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] Epoch[164] Batch [10]#011Speed: 242.49 samples/sec#011loss=2.905158\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315086.0713627, \"EndTime\": 1649315089.2944329, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3222.419023513794, \"count\": 1, \"min\": 3222.419023513794, \"max\": 3222.419023513794}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=202.63359045025166 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] #progress_metric: host=algo-1, completed 41.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.8526781038804487\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] Epoch[165] Batch[0] avg_epoch_loss=2.934841\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.934840679168701\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:51 INFO 139984794219904] Epoch[165] Batch[5] avg_epoch_loss=2.876327\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.87632683912913\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:51 INFO 139984794219904] Epoch[165] Batch [5]#011Speed: 263.57 samples/sec#011loss=2.876327\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] Epoch[165] Batch[10] avg_epoch_loss=2.820311\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=2.7530922412872316\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] Epoch[165] Batch [10]#011Speed: 245.88 samples/sec#011loss=2.753092\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315089.2945397, \"EndTime\": 1649315092.379156, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3084.0961933135986, \"count\": 1, \"min\": 3084.0961933135986, \"max\": 3084.0961933135986}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.69566282152527 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 41.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.820311112837358\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] Epoch[166] Batch[0] avg_epoch_loss=2.873398\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.8733983039855957\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:54 INFO 139984794219904] Epoch[166] Batch[5] avg_epoch_loss=2.776181\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.776181221008301\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:54 INFO 139984794219904] Epoch[166] Batch [5]#011Speed: 252.44 samples/sec#011loss=2.776181\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] Epoch[166] Batch[10] avg_epoch_loss=2.872391\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=2.9878427982330322\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] Epoch[166] Batch [10]#011Speed: 273.45 samples/sec#011loss=2.987843\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315092.3792322, \"EndTime\": 1649315095.413533, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3033.797264099121, \"count\": 1, \"min\": 3033.797264099121, \"max\": 3033.797264099121}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.91357527963305 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 41.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.872391028837724\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] Epoch[167] Batch[0] avg_epoch_loss=3.044432\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=3.044431686401367\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:57 INFO 139984794219904] Epoch[167] Batch[5] avg_epoch_loss=2.920248\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.920247793197632\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:57 INFO 139984794219904] Epoch[167] Batch [5]#011Speed: 247.16 samples/sec#011loss=2.920248\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315095.4136214, \"EndTime\": 1649315098.305996, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2891.768455505371, \"count\": 1, \"min\": 2891.768455505371, \"max\": 2891.768455505371}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.5413124927089 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.9246856451034544\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] Epoch[168] Batch[0] avg_epoch_loss=2.836918\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:04:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.8369181156158447\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:00 INFO 139984794219904] Epoch[168] Batch[5] avg_epoch_loss=2.868150\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.8681499560674033\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:00 INFO 139984794219904] Epoch[168] Batch [5]#011Speed: 262.51 samples/sec#011loss=2.868150\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315098.3060963, \"EndTime\": 1649315101.1356378, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2829.033136367798, \"count\": 1, \"min\": 2829.033136367798, \"max\": 2829.033136367798}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.44542985104462 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] #progress_metric: host=algo-1, completed 42.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.8520124435424803\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] Epoch[169] Batch[0] avg_epoch_loss=2.743995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.743995428085327\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:02 INFO 139984794219904] Epoch[169] Batch[5] avg_epoch_loss=2.824112\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.8241122166315713\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:02 INFO 139984794219904] Epoch[169] Batch [5]#011Speed: 262.95 samples/sec#011loss=2.824112\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] Epoch[169] Batch[10] avg_epoch_loss=2.766752\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.6979187965393066\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] Epoch[169] Batch [10]#011Speed: 249.26 samples/sec#011loss=2.697919\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315101.1357486, \"EndTime\": 1649315104.2810347, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3144.6518898010254, \"count\": 1, \"min\": 3144.6518898010254, \"max\": 3144.6518898010254}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=203.83260995616067 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 42.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.7667515711350874\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] Epoch[170] Batch[0] avg_epoch_loss=2.895704\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.8957035541534424\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:06 INFO 139984794219904] Epoch[170] Batch[5] avg_epoch_loss=2.829092\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.8290919065475464\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:06 INFO 139984794219904] Epoch[170] Batch [5]#011Speed: 256.90 samples/sec#011loss=2.829092\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] Epoch[170] Batch[10] avg_epoch_loss=2.768594\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.6959958553314207\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] Epoch[170] Batch [10]#011Speed: 264.08 samples/sec#011loss=2.695996\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315104.281089, \"EndTime\": 1649315107.4020715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3120.5782890319824, \"count\": 1, \"min\": 3120.5782890319824, \"max\": 3120.5782890319824}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.0156563701446 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 42.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.7685937014493076\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:08 INFO 139984794219904] Epoch[171] Batch[0] avg_epoch_loss=3.084776\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=3.084775924682617\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] Epoch[171] Batch[5] avg_epoch_loss=2.974810\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.9748095273971558\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] Epoch[171] Batch [5]#011Speed: 253.64 samples/sec#011loss=2.974810\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] processed a total of 576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315107.402164, \"EndTime\": 1649315109.9993842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2596.5776443481445, \"count\": 1, \"min\": 2596.5776443481445, \"max\": 2596.5776443481445}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.81823443667116 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.9036186271243625\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:09 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:10 INFO 139984794219904] Epoch[172] Batch[0] avg_epoch_loss=2.886333\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.886333465576172\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:11 INFO 139984794219904] Epoch[172] Batch[5] avg_epoch_loss=2.818838\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.8188379208246865\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:11 INFO 139984794219904] Epoch[172] Batch [5]#011Speed: 259.00 samples/sec#011loss=2.818838\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] Epoch[172] Batch[10] avg_epoch_loss=2.869182\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=2.9295953273773194\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] Epoch[172] Batch [10]#011Speed: 250.86 samples/sec#011loss=2.929595\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315109.9994888, \"EndTime\": 1649315113.0963805, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3096.256732940674, \"count\": 1, \"min\": 3096.256732940674, \"max\": 3096.256732940674}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.33750388650526 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 43.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.8691821965304287\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] Epoch[173] Batch[0] avg_epoch_loss=2.749887\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.749887228012085\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:14 INFO 139984794219904] Epoch[173] Batch[5] avg_epoch_loss=2.798402\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.798402031262716\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:14 INFO 139984794219904] Epoch[173] Batch [5]#011Speed: 246.91 samples/sec#011loss=2.798402\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] Epoch[173] Batch[10] avg_epoch_loss=2.735336\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.659656810760498\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] Epoch[173] Batch [10]#011Speed: 243.06 samples/sec#011loss=2.659657\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315113.0964844, \"EndTime\": 1649315116.3028579, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3205.8074474334717, \"count\": 1, \"min\": 3205.8074474334717, \"max\": 3205.8074474334717}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=200.87801766197575 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] #progress_metric: host=algo-1, completed 43.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.735336021943526\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_1d6a1960-f2ec-463e-b1c1-a14c34911b37-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315116.3029444, \"EndTime\": 1649315116.3918772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 88.32931518554688, \"count\": 1, \"min\": 88.32931518554688, \"max\": 88.32931518554688}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] Epoch[174] Batch[0] avg_epoch_loss=2.808949\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.8089492321014404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:18 INFO 139984794219904] Epoch[174] Batch[5] avg_epoch_loss=2.777303\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.7773026625315347\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:18 INFO 139984794219904] Epoch[174] Batch [5]#011Speed: 247.08 samples/sec#011loss=2.777303\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315116.3919928, \"EndTime\": 1649315119.3233585, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2931.291341781616, \"count\": 1, \"min\": 2931.291341781616, \"max\": 2931.291341781616}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.84275279955332 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] #progress_metric: host=algo-1, completed 43.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.769833874702454\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] Epoch[175] Batch[0] avg_epoch_loss=2.773432\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.7734320163726807\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:21 INFO 139984794219904] Epoch[175] Batch[5] avg_epoch_loss=2.809651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.8096514542897544\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:21 INFO 139984794219904] Epoch[175] Batch [5]#011Speed: 247.34 samples/sec#011loss=2.809651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315119.3234477, \"EndTime\": 1649315122.269582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2945.544958114624, \"count\": 1, \"min\": 2945.544958114624, \"max\": 2945.544958114624}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.08340752702864 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.7839585304260255\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] Epoch[176] Batch[0] avg_epoch_loss=2.754824\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.754824161529541\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:24 INFO 139984794219904] Epoch[176] Batch[5] avg_epoch_loss=2.747710\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.7477097511291504\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:24 INFO 139984794219904] Epoch[176] Batch [5]#011Speed: 257.60 samples/sec#011loss=2.747710\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] Epoch[176] Batch[10] avg_epoch_loss=2.791174\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.843332052230835\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] Epoch[176] Batch [10]#011Speed: 259.97 samples/sec#011loss=2.843332\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315122.2696712, \"EndTime\": 1649315125.313262, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3043.040990829468, \"count\": 1, \"min\": 3043.040990829468, \"max\": 3043.040990829468}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.15092068048037 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 44.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.791174433448098\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] Epoch[177] Batch[0] avg_epoch_loss=2.740537\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.740536689758301\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:27 INFO 139984794219904] Epoch[177] Batch[5] avg_epoch_loss=2.786954\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.786953926086426\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:27 INFO 139984794219904] Epoch[177] Batch [5]#011Speed: 253.40 samples/sec#011loss=2.786954\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315125.3133483, \"EndTime\": 1649315128.1960816, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2882.272481918335, \"count\": 1, \"min\": 2882.272481918335, \"max\": 2882.272481918335}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.93433453664224 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 44.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.8102235555648805\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] Epoch[178] Batch[0] avg_epoch_loss=2.761255\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.7612550258636475\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:30 INFO 139984794219904] Epoch[178] Batch[5] avg_epoch_loss=2.860088\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.8600878715515137\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:30 INFO 139984794219904] Epoch[178] Batch [5]#011Speed: 254.29 samples/sec#011loss=2.860088\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315128.1961813, \"EndTime\": 1649315131.0432558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2846.426010131836, \"count\": 1, \"min\": 2846.426010131836, \"max\": 2846.426010131836}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.26531119570149 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] #progress_metric: host=algo-1, completed 44.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.797767686843872\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] Epoch[179] Batch[0] avg_epoch_loss=2.812954\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.8129541873931885\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:32 INFO 139984794219904] Epoch[179] Batch[5] avg_epoch_loss=2.798557\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.79855744043986\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:32 INFO 139984794219904] Epoch[179] Batch [5]#011Speed: 250.49 samples/sec#011loss=2.798557\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:33 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315131.0433521, \"EndTime\": 1649315133.9323883, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2888.5138034820557, \"count\": 1, \"min\": 2888.5138034820557, \"max\": 2888.5138034820557}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:33 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.8650966722156 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:33 INFO 139984794219904] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.761091637611389\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:33 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:34 INFO 139984794219904] Epoch[180] Batch[0] avg_epoch_loss=2.757387\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.757387161254883\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:35 INFO 139984794219904] Epoch[180] Batch[5] avg_epoch_loss=2.779148\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.779147823651632\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:35 INFO 139984794219904] Epoch[180] Batch [5]#011Speed: 251.79 samples/sec#011loss=2.779148\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] Epoch[180] Batch[10] avg_epoch_loss=2.881699\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=3.0047601222991944\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] Epoch[180] Batch [10]#011Speed: 262.90 samples/sec#011loss=3.004760\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315133.9324715, \"EndTime\": 1649315136.9841359, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3051.104784011841, \"count\": 1, \"min\": 3051.104784011841, \"max\": 3051.104784011841}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.35630060878418 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] #progress_metric: host=algo-1, completed 45.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.881698868491433\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:36 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:37 INFO 139984794219904] Epoch[181] Batch[0] avg_epoch_loss=2.876057\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.8760571479797363\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:38 INFO 139984794219904] Epoch[181] Batch[5] avg_epoch_loss=2.789660\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.789659937222799\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:38 INFO 139984794219904] Epoch[181] Batch [5]#011Speed: 257.26 samples/sec#011loss=2.789660\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] Epoch[181] Batch[10] avg_epoch_loss=2.817644\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.851224422454834\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] Epoch[181] Batch [10]#011Speed: 243.18 samples/sec#011loss=2.851224\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315136.9842248, \"EndTime\": 1649315140.375259, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3390.491485595703, \"count\": 1, \"min\": 3390.491485595703, \"max\": 3390.491485595703}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.8749680849635 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 45.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.8530637621879578\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] Epoch[182] Batch[0] avg_epoch_loss=2.667459\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.667459011077881\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:42 INFO 139984794219904] Epoch[182] Batch[5] avg_epoch_loss=2.773051\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.773050546646118\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:42 INFO 139984794219904] Epoch[182] Batch [5]#011Speed: 245.39 samples/sec#011loss=2.773051\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] Epoch[182] Batch[10] avg_epoch_loss=2.739022\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.698187065124512\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] Epoch[182] Batch [10]#011Speed: 244.30 samples/sec#011loss=2.698187\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315140.3753552, \"EndTime\": 1649315143.5971694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3221.280097961426, \"count\": 1, \"min\": 3221.280097961426, \"max\": 3221.280097961426}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=200.22399292809723 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] #progress_metric: host=algo-1, completed 45.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.7390216914090244\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:43 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:44 INFO 139984794219904] Epoch[183] Batch[0] avg_epoch_loss=2.838554\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.8385539054870605\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:45 INFO 139984794219904] Epoch[183] Batch[5] avg_epoch_loss=2.794920\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.794920285542806\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:45 INFO 139984794219904] Epoch[183] Batch [5]#011Speed: 264.68 samples/sec#011loss=2.794920\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] Epoch[183] Batch[10] avg_epoch_loss=2.809901\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=2.827876901626587\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] Epoch[183] Batch [10]#011Speed: 255.33 samples/sec#011loss=2.827877\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315143.5972476, \"EndTime\": 1649315146.6179397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3020.2059745788574, \"count\": 1, \"min\": 3020.2059745788574, \"max\": 3020.2059745788574}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.16862238655398 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.809900565580888\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:46 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:47 INFO 139984794219904] Epoch[184] Batch[0] avg_epoch_loss=2.783273\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.7832725048065186\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:48 INFO 139984794219904] Epoch[184] Batch[5] avg_epoch_loss=2.812455\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.812454660733541\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:48 INFO 139984794219904] Epoch[184] Batch [5]#011Speed: 256.09 samples/sec#011loss=2.812455\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:49 INFO 139984794219904] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315146.61802, \"EndTime\": 1649315149.4570923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2838.589668273926, \"count\": 1, \"min\": 2838.589668273926, \"max\": 2838.589668273926}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:49 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.1667073443382 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:49 INFO 139984794219904] #progress_metric: host=algo-1, completed 46.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.820889115333557\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:49 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:50 INFO 139984794219904] Epoch[185] Batch[0] avg_epoch_loss=2.823421\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.8234212398529053\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:51 INFO 139984794219904] Epoch[185] Batch[5] avg_epoch_loss=2.741444\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.7414438327153525\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:51 INFO 139984794219904] Epoch[185] Batch [5]#011Speed: 253.53 samples/sec#011loss=2.741444\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315149.4571867, \"EndTime\": 1649315152.3337388, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2876.049518585205, \"count\": 1, \"min\": 2876.049518585205, \"max\": 2876.049518585205}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.04345255651012 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 46.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.7110255002975463\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_c6727daf-c6b2-41bf-b710-16299350bbf5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315152.3338337, \"EndTime\": 1649315152.417909, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 83.56976509094238, \"count\": 1, \"min\": 83.56976509094238, \"max\": 83.56976509094238}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] Epoch[186] Batch[0] avg_epoch_loss=2.661412\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.661412000656128\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:54 INFO 139984794219904] Epoch[186] Batch[5] avg_epoch_loss=2.728438\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.7284377018610635\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:54 INFO 139984794219904] Epoch[186] Batch [5]#011Speed: 247.51 samples/sec#011loss=2.728438\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] Epoch[186] Batch[10] avg_epoch_loss=2.699622\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=2.66504225730896\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] Epoch[186] Batch [10]#011Speed: 248.88 samples/sec#011loss=2.665042\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315152.417999, \"EndTime\": 1649315155.5787234, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3160.6509685516357, \"count\": 1, \"min\": 3160.6509685516357, \"max\": 3160.6509685516357}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.59339349016108 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 46.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.6996215907010166\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:55 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_bbfe4b34-78e4-4620-b6a6-61d95e9e1711-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315155.5788252, \"EndTime\": 1649315155.6475172, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 68.03011894226074, \"count\": 1, \"min\": 68.03011894226074, \"max\": 68.03011894226074}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:56 INFO 139984794219904] Epoch[187] Batch[0] avg_epoch_loss=2.712227\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.7122268676757812\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:57 INFO 139984794219904] Epoch[187] Batch[5] avg_epoch_loss=2.750674\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.7506741682688394\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:57 INFO 139984794219904] Epoch[187] Batch [5]#011Speed: 273.86 samples/sec#011loss=2.750674\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315155.6476014, \"EndTime\": 1649315158.321386, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2673.696756362915, \"count\": 1, \"min\": 2673.696756362915, \"max\": 2673.696756362915}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=237.4752742030342 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.768136477470398\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] Epoch[188] Batch[0] avg_epoch_loss=2.705003\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:05:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.705003499984741\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:00 INFO 139984794219904] Epoch[188] Batch[5] avg_epoch_loss=2.739930\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.7399301131566367\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:00 INFO 139984794219904] Epoch[188] Batch [5]#011Speed: 250.58 samples/sec#011loss=2.739930\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] Epoch[188] Batch[10] avg_epoch_loss=2.700386\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.652934122085571\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] Epoch[188] Batch [10]#011Speed: 265.69 samples/sec#011loss=2.652934\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315158.3216026, \"EndTime\": 1649315161.3351877, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3012.930154800415, \"count\": 1, \"min\": 3012.930154800415, \"max\": 3012.930154800415}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=217.71880548134854 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] #progress_metric: host=algo-1, completed 47.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.700386480851607\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] Epoch[189] Batch[0] avg_epoch_loss=2.840983\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.8409829139709473\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:03 INFO 139984794219904] Epoch[189] Batch[5] avg_epoch_loss=2.786415\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.786414543787638\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:03 INFO 139984794219904] Epoch[189] Batch [5]#011Speed: 257.65 samples/sec#011loss=2.786415\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315161.3352706, \"EndTime\": 1649315164.191119, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2855.118989944458, \"count\": 1, \"min\": 2855.118989944458, \"max\": 2855.118989944458}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.7929871646531 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 47.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.754069209098816\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] Epoch[190] Batch[0] avg_epoch_loss=2.795815\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.7958152294158936\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:06 INFO 139984794219904] Epoch[190] Batch[5] avg_epoch_loss=2.787419\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.7874189615249634\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:06 INFO 139984794219904] Epoch[190] Batch [5]#011Speed: 246.62 samples/sec#011loss=2.787419\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] Epoch[190] Batch[10] avg_epoch_loss=2.761849\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=2.731164741516113\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] Epoch[190] Batch [10]#011Speed: 239.49 samples/sec#011loss=2.731165\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315164.191274, \"EndTime\": 1649315167.4179592, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3226.1364459991455, \"count\": 1, \"min\": 3226.1364459991455, \"max\": 3226.1364459991455}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.7992947356356 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 47.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.7618488615209404\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:08 INFO 139984794219904] Epoch[191] Batch[0] avg_epoch_loss=2.709265\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.7092654705047607\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:09 INFO 139984794219904] Epoch[191] Batch[5] avg_epoch_loss=2.710385\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.710384805997213\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:09 INFO 139984794219904] Epoch[191] Batch [5]#011Speed: 246.52 samples/sec#011loss=2.710385\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] Epoch[191] Batch[10] avg_epoch_loss=2.792530\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.8911032676696777\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] Epoch[191] Batch [10]#011Speed: 242.58 samples/sec#011loss=2.891103\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315167.4180458, \"EndTime\": 1649315170.6354253, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3216.8920040130615, \"count\": 1, \"min\": 3216.8920040130615, \"max\": 3216.8920040130615}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=202.98366484578645 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.7925295613028784\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:10 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:11 INFO 139984794219904] Epoch[192] Batch[0] avg_epoch_loss=2.733181\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.7331807613372803\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:12 INFO 139984794219904] Epoch[192] Batch[5] avg_epoch_loss=2.723775\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.7237754265467324\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:12 INFO 139984794219904] Epoch[192] Batch [5]#011Speed: 251.64 samples/sec#011loss=2.723775\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] Epoch[192] Batch[10] avg_epoch_loss=2.691022\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=2.651718187332153\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] Epoch[192] Batch [10]#011Speed: 243.75 samples/sec#011loss=2.651718\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315170.6355045, \"EndTime\": 1649315173.8251262, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3189.085006713867, \"count\": 1, \"min\": 3189.085006713867, \"max\": 3189.085006713867}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=200.98773858777076 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 48.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.691022135994651\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:13 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_686325b8-0ee9-42a4-810a-5d3df5205b2f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315173.825251, \"EndTime\": 1649315173.9137437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 87.95738220214844, \"count\": 1, \"min\": 87.95738220214844, \"max\": 87.95738220214844}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:14 INFO 139984794219904] Epoch[193] Batch[0] avg_epoch_loss=2.726186\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.7261862754821777\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:15 INFO 139984794219904] Epoch[193] Batch[5] avg_epoch_loss=2.771286\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.771285971005758\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:15 INFO 139984794219904] Epoch[193] Batch [5]#011Speed: 253.98 samples/sec#011loss=2.771286\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:16 INFO 139984794219904] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315173.9138389, \"EndTime\": 1649315176.8184037, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2904.491186141968, \"count\": 1, \"min\": 2904.491186141968, \"max\": 2904.491186141968}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:16 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.96044322382838 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:16 INFO 139984794219904] #progress_metric: host=algo-1, completed 48.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.730574131011963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:16 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:17 INFO 139984794219904] Epoch[194] Batch[0] avg_epoch_loss=2.765401\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.7654006481170654\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:18 INFO 139984794219904] Epoch[194] Batch[5] avg_epoch_loss=2.755215\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.7552152077356973\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:18 INFO 139984794219904] Epoch[194] Batch [5]#011Speed: 245.95 samples/sec#011loss=2.755215\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:19 INFO 139984794219904] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315176.8185081, \"EndTime\": 1649315179.7319992, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2912.947177886963, \"count\": 1, \"min\": 2912.947177886963, \"max\": 2912.947177886963}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:19 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.2669913385546 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:19 INFO 139984794219904] #progress_metric: host=algo-1, completed 48.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.7614943265914915\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:19 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:20 INFO 139984794219904] Epoch[195] Batch[0] avg_epoch_loss=2.785520\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.785519599914551\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:21 INFO 139984794219904] Epoch[195] Batch[5] avg_epoch_loss=2.764512\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.7645124991734824\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:21 INFO 139984794219904] Epoch[195] Batch [5]#011Speed: 261.10 samples/sec#011loss=2.764512\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] Epoch[195] Batch[10] avg_epoch_loss=2.774825\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.7872010707855224\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] Epoch[195] Batch [10]#011Speed: 248.38 samples/sec#011loss=2.787201\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315179.7320817, \"EndTime\": 1649315182.803933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3071.2616443634033, \"count\": 1, \"min\": 3071.2616443634033, \"max\": 3071.2616443634033}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.83714437925096 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.7748254862698642\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:22 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:23 INFO 139984794219904] Epoch[196] Batch[0] avg_epoch_loss=2.589594\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.5895936489105225\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:24 INFO 139984794219904] Epoch[196] Batch[5] avg_epoch_loss=2.740516\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.7405157883961997\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:24 INFO 139984794219904] Epoch[196] Batch [5]#011Speed: 247.24 samples/sec#011loss=2.740516\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:25 INFO 139984794219904] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315182.8040261, \"EndTime\": 1649315185.7365062, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2931.6000938415527, \"count\": 1, \"min\": 2931.6000938415527, \"max\": 2931.6000938415527}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=201.24585352794327 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 49.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.8173104524612427\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:25 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:26 INFO 139984794219904] Epoch[197] Batch[0] avg_epoch_loss=2.837685\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.8376846313476562\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:27 INFO 139984794219904] Epoch[197] Batch[5] avg_epoch_loss=2.843328\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.843328356742859\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:27 INFO 139984794219904] Epoch[197] Batch [5]#011Speed: 244.95 samples/sec#011loss=2.843328\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] Epoch[197] Batch[10] avg_epoch_loss=2.845981\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.8491641998291017\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] Epoch[197] Batch [10]#011Speed: 245.28 samples/sec#011loss=2.849164\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315185.7365992, \"EndTime\": 1649315188.9364898, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3199.3768215179443, \"count\": 1, \"min\": 3199.3768215179443, \"max\": 3199.3768215179443}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.3437464953782 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 49.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.845981012691151\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:28 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:29 INFO 139984794219904] Epoch[198] Batch[0] avg_epoch_loss=2.798137\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.7981374263763428\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:30 INFO 139984794219904] Epoch[198] Batch[5] avg_epoch_loss=2.808819\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.808818737665812\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:30 INFO 139984794219904] Epoch[198] Batch [5]#011Speed: 264.59 samples/sec#011loss=2.808819\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] Epoch[198] Batch[10] avg_epoch_loss=2.748608\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.6763550281524657\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] Epoch[198] Batch [10]#011Speed: 249.48 samples/sec#011loss=2.676355\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315188.936597, \"EndTime\": 1649315192.0505366, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3113.3856773376465, \"count\": 1, \"min\": 3113.3856773376465, \"max\": 3113.3856773376465}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.5199382891559 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] #progress_metric: host=algo-1, completed 49.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.748607960614291\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] Epoch[199] Batch[0] avg_epoch_loss=2.991458\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.9914581775665283\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:33 INFO 139984794219904] Epoch[199] Batch[5] avg_epoch_loss=2.826713\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.8267133235931396\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:33 INFO 139984794219904] Epoch[199] Batch [5]#011Speed: 276.39 samples/sec#011loss=2.826713\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] Epoch[199] Batch[10] avg_epoch_loss=2.849088\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.875937986373901\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] Epoch[199] Batch [10]#011Speed: 248.73 samples/sec#011loss=2.875938\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315192.050617, \"EndTime\": 1649315195.0763803, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3025.2718925476074, \"count\": 1, \"min\": 3025.2718925476074, \"max\": 3025.2718925476074}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.1443915098659 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.8490881703116675\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] Epoch[200] Batch[0] avg_epoch_loss=2.692277\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.6922767162323\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:36 INFO 139984794219904] Epoch[200] Batch[5] avg_epoch_loss=2.783305\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.783305366834005\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:36 INFO 139984794219904] Epoch[200] Batch [5]#011Speed: 251.52 samples/sec#011loss=2.783305\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] Epoch[200] Batch[10] avg_epoch_loss=2.828710\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.8831944942474363\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] Epoch[200] Batch [10]#011Speed: 269.35 samples/sec#011loss=2.883194\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315195.0764754, \"EndTime\": 1649315198.1256528, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3048.7051010131836, \"count\": 1, \"min\": 3048.7051010131836, \"max\": 3048.7051010131836}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.49177350252737 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] #progress_metric: host=algo-1, completed 50.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.828709515658292\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] Epoch[201] Batch[0] avg_epoch_loss=3.035904\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=3.0359041690826416\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] Epoch[201] Batch[5] avg_epoch_loss=2.856389\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.856388966242472\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] Epoch[201] Batch [5]#011Speed: 246.54 samples/sec#011loss=2.856389\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315198.1257439, \"EndTime\": 1649315200.9938517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2867.623805999756, \"count\": 1, \"min\": 2867.623805999756, \"max\": 2867.623805999756}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.4532035455529 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 50.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.848442220687866\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:40 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:41 INFO 139984794219904] Epoch[202] Batch[0] avg_epoch_loss=2.585358\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.585357904434204\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:42 INFO 139984794219904] Epoch[202] Batch[5] avg_epoch_loss=2.699810\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.6998104651769004\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:42 INFO 139984794219904] Epoch[202] Batch [5]#011Speed: 246.71 samples/sec#011loss=2.699810\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] Epoch[202] Batch[10] avg_epoch_loss=2.686997\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.6716217517852785\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] Epoch[202] Batch [10]#011Speed: 264.30 samples/sec#011loss=2.671622\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315200.9939477, \"EndTime\": 1649315204.071774, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3077.302932739258, \"count\": 1, \"min\": 3077.302932739258, \"max\": 3077.302932739258}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.51597533456408 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] #progress_metric: host=algo-1, completed 50.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.686997413635254\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_84549f7f-60ec-4c27-9f03-3483b5ea957a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315204.071847, \"EndTime\": 1649315204.1563342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 83.98604393005371, \"count\": 1, \"min\": 83.98604393005371, \"max\": 83.98604393005371}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] Epoch[203] Batch[0] avg_epoch_loss=2.813969\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.8139686584472656\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:46 INFO 139984794219904] Epoch[203] Batch[5] avg_epoch_loss=2.772501\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.772500912348429\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:46 INFO 139984794219904] Epoch[203] Batch [5]#011Speed: 246.05 samples/sec#011loss=2.772501\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] Epoch[203] Batch[10] avg_epoch_loss=2.822997\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.883592700958252\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] Epoch[203] Batch [10]#011Speed: 240.79 samples/sec#011loss=2.883593\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315204.1564085, \"EndTime\": 1649315207.376179, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3219.701051712036, \"count\": 1, \"min\": 3219.701051712036, \"max\": 3219.701051712036}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.15145998940548 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.8229971798983486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] Epoch[204] Batch[0] avg_epoch_loss=2.780813\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.7808125019073486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:49 INFO 139984794219904] Epoch[204] Batch[5] avg_epoch_loss=2.785117\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.7851169109344482\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:49 INFO 139984794219904] Epoch[204] Batch [5]#011Speed: 275.72 samples/sec#011loss=2.785117\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315207.376302, \"EndTime\": 1649315210.063221, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2686.4407062530518, \"count\": 1, \"min\": 2686.4407062530518, \"max\": 2686.4407062530518}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.82921528543702 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] #progress_metric: host=algo-1, completed 51.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.7530033588409424\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] Epoch[205] Batch[0] avg_epoch_loss=2.830421\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.830421209335327\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:51 INFO 139984794219904] Epoch[205] Batch[5] avg_epoch_loss=2.742723\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.7427227099736533\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:51 INFO 139984794219904] Epoch[205] Batch [5]#011Speed: 270.66 samples/sec#011loss=2.742723\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] Epoch[205] Batch[10] avg_epoch_loss=2.723688\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=2.700845718383789\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] Epoch[205] Batch [10]#011Speed: 266.82 samples/sec#011loss=2.700846\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315210.063485, \"EndTime\": 1649315212.9815652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2917.4411296844482, \"count\": 1, \"min\": 2917.4411296844482, \"max\": 2917.4411296844482}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=226.21885981550056 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] #progress_metric: host=algo-1, completed 51.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.7236877137964424\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:52 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:53 INFO 139984794219904] Epoch[206] Batch[0] avg_epoch_loss=2.771634\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.771634340286255\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:54 INFO 139984794219904] Epoch[206] Batch[5] avg_epoch_loss=2.799510\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.7995096842447915\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:54 INFO 139984794219904] Epoch[206] Batch [5]#011Speed: 261.42 samples/sec#011loss=2.799510\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:55 INFO 139984794219904] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315212.9816194, \"EndTime\": 1649315215.8883517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2906.209707260132, \"count\": 1, \"min\": 2906.209707260132, \"max\": 2906.209707260132}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.8323545842716 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 51.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.787394642829895\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:56 INFO 139984794219904] Epoch[207] Batch[0] avg_epoch_loss=2.760662\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.7606618404388428\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:57 INFO 139984794219904] Epoch[207] Batch[5] avg_epoch_loss=2.750665\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.750665307044983\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:57 INFO 139984794219904] Epoch[207] Batch [5]#011Speed: 246.99 samples/sec#011loss=2.750665\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] Epoch[207] Batch[10] avg_epoch_loss=2.681996\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=2.5995938777923584\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] Epoch[207] Batch [10]#011Speed: 242.31 samples/sec#011loss=2.599594\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315215.8884335, \"EndTime\": 1649315219.069715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3180.696964263916, \"count\": 1, \"min\": 3180.696964263916, \"max\": 3180.696964263916}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.7521264659496 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.681996475566517\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_3e4c6a99-61e8-4691-8270-252242594d65-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315219.0697932, \"EndTime\": 1649315219.1286976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 58.32791328430176, \"count\": 1, \"min\": 58.32791328430176, \"max\": 58.32791328430176}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] Epoch[208] Batch[0] avg_epoch_loss=2.667284\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:06:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.6672840118408203\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:00 INFO 139984794219904] Epoch[208] Batch[5] avg_epoch_loss=2.747530\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.7475303411483765\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:00 INFO 139984794219904] Epoch[208] Batch [5]#011Speed: 262.35 samples/sec#011loss=2.747530\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] Epoch[208] Batch[10] avg_epoch_loss=2.697598\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.6376790523529055\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] Epoch[208] Batch [10]#011Speed: 262.92 samples/sec#011loss=2.637679\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315219.1287951, \"EndTime\": 1649315222.1662035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3037.3432636260986, \"count\": 1, \"min\": 3037.3432636260986, \"max\": 3037.3432636260986}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.6523522514121 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] #progress_metric: host=algo-1, completed 52.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.697597937150435\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] Epoch[209] Batch[0] avg_epoch_loss=2.782246\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.7822458744049072\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:04 INFO 139984794219904] Epoch[209] Batch[5] avg_epoch_loss=2.742559\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.7425593932469687\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:04 INFO 139984794219904] Epoch[209] Batch [5]#011Speed: 255.98 samples/sec#011loss=2.742559\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315222.1662922, \"EndTime\": 1649315225.0826054, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2915.837526321411, \"count\": 1, \"min\": 2915.837526321411, \"max\": 2915.837526321411}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.47731072786692 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] #progress_metric: host=algo-1, completed 52.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.7483201742172243\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] Epoch[210] Batch[0] avg_epoch_loss=2.778518\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.7785181999206543\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:07 INFO 139984794219904] Epoch[210] Batch[5] avg_epoch_loss=2.778318\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.778318246205648\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:07 INFO 139984794219904] Epoch[210] Batch [5]#011Speed: 229.72 samples/sec#011loss=2.778318\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315225.0827386, \"EndTime\": 1649315228.1129398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3029.3898582458496, \"count\": 1, \"min\": 3029.3898582458496, \"max\": 3029.3898582458496}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=198.04956877131679 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] #progress_metric: host=algo-1, completed 52.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.761699914932251\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] Epoch[211] Batch[0] avg_epoch_loss=2.638519\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.638519048690796\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:09 INFO 139984794219904] Epoch[211] Batch[5] avg_epoch_loss=2.738374\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.738373796145121\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:09 INFO 139984794219904] Epoch[211] Batch [5]#011Speed: 274.95 samples/sec#011loss=2.738374\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:10 INFO 139984794219904] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315228.1130488, \"EndTime\": 1649315230.7630887, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2649.327039718628, \"count\": 1, \"min\": 2649.327039718628, \"max\": 2649.327039718628}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.9494687224331 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.6835654735565186\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:10 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:11 INFO 139984794219904] Epoch[212] Batch[0] avg_epoch_loss=2.746038\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=2.746037721633911\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:12 INFO 139984794219904] Epoch[212] Batch[5] avg_epoch_loss=2.698722\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=2.6987216075261435\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:12 INFO 139984794219904] Epoch[212] Batch [5]#011Speed: 267.77 samples/sec#011loss=2.698722\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] Epoch[212] Batch[10] avg_epoch_loss=2.683575\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=2.665399408340454\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] Epoch[212] Batch [10]#011Speed: 244.86 samples/sec#011loss=2.665399\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315230.7632015, \"EndTime\": 1649315233.8528967, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3089.200496673584, \"count\": 1, \"min\": 3089.200496673584, \"max\": 3089.200496673584}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.69691292888004 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 53.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=212, train loss <loss>=2.68357515335083\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:14 INFO 139984794219904] Epoch[213] Batch[0] avg_epoch_loss=2.725026\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=2.7250263690948486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:15 INFO 139984794219904] Epoch[213] Batch[5] avg_epoch_loss=2.766706\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=2.766705592473348\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:15 INFO 139984794219904] Epoch[213] Batch [5]#011Speed: 248.34 samples/sec#011loss=2.766706\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] Epoch[213] Batch[10] avg_epoch_loss=2.714283\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=2.651375246047974\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] Epoch[213] Batch [10]#011Speed: 242.22 samples/sec#011loss=2.651375\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315233.8529804, \"EndTime\": 1649315237.0593555, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3205.8897018432617, \"count\": 1, \"min\": 3205.8897018432617, \"max\": 3205.8897018432617}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=205.2372384860384 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] #progress_metric: host=algo-1, completed 53.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=213, train loss <loss>=2.7142827077345415\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] Epoch[214] Batch[0] avg_epoch_loss=2.717995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=2.7179954051971436\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:18 INFO 139984794219904] Epoch[214] Batch[5] avg_epoch_loss=2.716275\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=2.716275175412496\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:18 INFO 139984794219904] Epoch[214] Batch [5]#011Speed: 250.76 samples/sec#011loss=2.716275\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315237.059467, \"EndTime\": 1649315240.00078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2940.8328533172607, \"count\": 1, \"min\": 2940.8328533172607, \"max\": 2940.8328533172607}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.81526465317611 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] #progress_metric: host=algo-1, completed 53.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=214, train loss <loss>=2.701929521560669\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] Epoch[215] Batch[0] avg_epoch_loss=2.591706\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=2.591705560684204\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:21 INFO 139984794219904] Epoch[215] Batch[5] avg_epoch_loss=2.687576\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=2.6875760157903037\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:21 INFO 139984794219904] Epoch[215] Batch [5]#011Speed: 250.43 samples/sec#011loss=2.687576\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:22 INFO 139984794219904] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315240.000872, \"EndTime\": 1649315242.8446064, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2843.1832790374756, \"count\": 1, \"min\": 2843.1832790374756, \"max\": 2843.1832790374756}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:22 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=218.75742564502386 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:22 INFO 139984794219904] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=215, train loss <loss>=2.698664832115173\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:22 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:23 INFO 139984794219904] Epoch[216] Batch[0] avg_epoch_loss=2.725472\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=2.7254722118377686\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:24 INFO 139984794219904] Epoch[216] Batch[5] avg_epoch_loss=2.738446\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=2.738445599873861\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:24 INFO 139984794219904] Epoch[216] Batch [5]#011Speed: 254.57 samples/sec#011loss=2.738446\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:25 INFO 139984794219904] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315242.8447094, \"EndTime\": 1649315245.6958485, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2850.50630569458, \"count\": 1, \"min\": 2850.50630569458, \"max\": 2850.50630569458}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:25 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.4566808678053 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:25 INFO 139984794219904] #progress_metric: host=algo-1, completed 54.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=216, train loss <loss>=2.73063542842865\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:25 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:26 INFO 139984794219904] Epoch[217] Batch[0] avg_epoch_loss=2.760668\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=2.760667562484741\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:27 INFO 139984794219904] Epoch[217] Batch[5] avg_epoch_loss=2.742946\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=2.7429461081822715\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:27 INFO 139984794219904] Epoch[217] Batch [5]#011Speed: 247.42 samples/sec#011loss=2.742946\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:28 INFO 139984794219904] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315245.6959708, \"EndTime\": 1649315248.60128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2904.7293663024902, \"count\": 1, \"min\": 2904.7293663024902, \"max\": 2904.7293663024902}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:28 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.52336232603434 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:28 INFO 139984794219904] #progress_metric: host=algo-1, completed 54.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=217, train loss <loss>=2.749947261810303\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:28 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:29 INFO 139984794219904] Epoch[218] Batch[0] avg_epoch_loss=2.972284\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=2.9722840785980225\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:30 INFO 139984794219904] Epoch[218] Batch[5] avg_epoch_loss=2.749353\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=2.749352773030599\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:30 INFO 139984794219904] Epoch[218] Batch [5]#011Speed: 255.29 samples/sec#011loss=2.749353\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315248.6015012, \"EndTime\": 1649315251.4045873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2802.5712966918945, \"count\": 1, \"min\": 2802.5712966918945, \"max\": 2802.5712966918945}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.71196950649667 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] #progress_metric: host=algo-1, completed 54.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=218, train loss <loss>=2.722499680519104\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] Epoch[219] Batch[0] avg_epoch_loss=2.653926\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:31 INFO 139984794219904] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=2.653926372528076\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:33 INFO 139984794219904] Epoch[219] Batch[5] avg_epoch_loss=2.681173\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=2.681172768274943\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:33 INFO 139984794219904] Epoch[219] Batch [5]#011Speed: 260.18 samples/sec#011loss=2.681173\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315251.404685, \"EndTime\": 1649315254.2503788, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2845.1647758483887, \"count\": 1, \"min\": 2845.1647758483887, \"max\": 2845.1647758483887}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.84820557716685 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=219, train loss <loss>=2.708343195915222\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] Epoch[220] Batch[0] avg_epoch_loss=2.722805\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=2.7228052616119385\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:36 INFO 139984794219904] Epoch[220] Batch[5] avg_epoch_loss=2.739642\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=2.7396422227223716\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:36 INFO 139984794219904] Epoch[220] Batch [5]#011Speed: 254.26 samples/sec#011loss=2.739642\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] Epoch[220] Batch[10] avg_epoch_loss=2.705961\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=2.66554274559021\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] Epoch[220] Batch [10]#011Speed: 241.00 samples/sec#011loss=2.665543\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315254.250477, \"EndTime\": 1649315257.455665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3204.6337127685547, \"count\": 1, \"min\": 3204.6337127685547, \"max\": 3204.6337127685547}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.3760015164702 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] #progress_metric: host=algo-1, completed 55.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] #quality_metric: host=algo-1, epoch=220, train loss <loss>=2.7059606422077525\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:37 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:38 INFO 139984794219904] Epoch[221] Batch[0] avg_epoch_loss=2.839980\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=2.839980363845825\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:39 INFO 139984794219904] Epoch[221] Batch[5] avg_epoch_loss=2.743843\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=2.7438428004582724\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:39 INFO 139984794219904] Epoch[221] Batch [5]#011Speed: 250.33 samples/sec#011loss=2.743843\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315257.455751, \"EndTime\": 1649315260.3256621, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2869.2901134490967, \"count\": 1, \"min\": 2869.2901134490967, \"max\": 2869.2901134490967}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.34343590785824 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] #progress_metric: host=algo-1, completed 55.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=221, train loss <loss>=2.7221686840057373\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] Epoch[222] Batch[0] avg_epoch_loss=2.801333\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=2.801333427429199\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:42 INFO 139984794219904] Epoch[222] Batch[5] avg_epoch_loss=2.778514\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=2.778513749440511\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:42 INFO 139984794219904] Epoch[222] Batch [5]#011Speed: 244.82 samples/sec#011loss=2.778514\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315260.3257647, \"EndTime\": 1649315263.227481, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2900.9411334991455, \"count\": 1, \"min\": 2900.9411334991455, \"max\": 2900.9411334991455}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.81248250562655 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] #progress_metric: host=algo-1, completed 55.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=222, train loss <loss>=2.7728349447250364\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] Epoch[223] Batch[0] avg_epoch_loss=2.710213\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=2.7102131843566895\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:45 INFO 139984794219904] Epoch[223] Batch[5] avg_epoch_loss=2.725896\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=2.7258960803349814\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:45 INFO 139984794219904] Epoch[223] Batch [5]#011Speed: 267.22 samples/sec#011loss=2.725896\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] Epoch[223] Batch[10] avg_epoch_loss=2.733896\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=2.743496322631836\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] Epoch[223] Batch [10]#011Speed: 266.96 samples/sec#011loss=2.743496\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315263.2276208, \"EndTime\": 1649315266.212806, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2984.4648838043213, \"count\": 1, \"min\": 2984.4648838043213, \"max\": 2984.4648838043213}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=226.8284699167941 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=223, train loss <loss>=2.733896190469915\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] Epoch[224] Batch[0] avg_epoch_loss=2.806164\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=2.806164026260376\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:48 INFO 139984794219904] Epoch[224] Batch[5] avg_epoch_loss=2.723939\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=2.7239386240641275\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:48 INFO 139984794219904] Epoch[224] Batch [5]#011Speed: 253.17 samples/sec#011loss=2.723939\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315266.2129285, \"EndTime\": 1649315269.0754304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2861.9720935821533, \"count\": 1, \"min\": 2861.9720935821533, \"max\": 2861.9720935821533}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.26188569375066 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] #progress_metric: host=algo-1, completed 56.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=224, train loss <loss>=2.727420687675476\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] Epoch[225] Batch[0] avg_epoch_loss=2.682880\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=2.682879686355591\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:50 INFO 139984794219904] Epoch[225] Batch[5] avg_epoch_loss=2.746964\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=2.74696413675944\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:50 INFO 139984794219904] Epoch[225] Batch [5]#011Speed: 257.56 samples/sec#011loss=2.746964\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:51 INFO 139984794219904] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315269.0755217, \"EndTime\": 1649315271.857798, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2781.7323207855225, \"count\": 1, \"min\": 2781.7323207855225, \"max\": 2781.7323207855225}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:51 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.6694117271975 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:51 INFO 139984794219904] #progress_metric: host=algo-1, completed 56.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=225, train loss <loss>=2.7598788738250732\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:51 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:52 INFO 139984794219904] Epoch[226] Batch[0] avg_epoch_loss=2.798787\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=2.7987868785858154\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:53 INFO 139984794219904] Epoch[226] Batch[5] avg_epoch_loss=2.736783\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=2.7367825508117676\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:53 INFO 139984794219904] Epoch[226] Batch [5]#011Speed: 247.47 samples/sec#011loss=2.736783\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:54 INFO 139984794219904] Epoch[226] Batch[10] avg_epoch_loss=2.687533\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=2.6284337997436524\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:54 INFO 139984794219904] Epoch[226] Batch [10]#011Speed: 244.62 samples/sec#011loss=2.628434\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315271.8578856, \"EndTime\": 1649315275.0001423, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3141.6542530059814, \"count\": 1, \"min\": 3141.6542530059814, \"max\": 3141.6542530059814}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.79899890495744 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] #progress_metric: host=algo-1, completed 56.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=226, train loss <loss>=2.6875331185080786\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] Epoch[227] Batch[0] avg_epoch_loss=2.950984\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=2.950983762741089\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:56 INFO 139984794219904] Epoch[227] Batch[5] avg_epoch_loss=2.784742\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=2.7847424348195395\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:56 INFO 139984794219904] Epoch[227] Batch [5]#011Speed: 255.37 samples/sec#011loss=2.784742\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:57 INFO 139984794219904] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315275.0002284, \"EndTime\": 1649315277.8909945, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2890.291690826416, \"count\": 1, \"min\": 2890.291690826416, \"max\": 2890.291690826416}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:57 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.50124165596142 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:57 INFO 139984794219904] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=227, train loss <loss>=2.823831486701965\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:57 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:58 INFO 139984794219904] Epoch[228] Batch[0] avg_epoch_loss=2.660939\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=2.6609394550323486\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:59 INFO 139984794219904] Epoch[228] Batch[5] avg_epoch_loss=2.664113\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=2.6641127665837607\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:07:59 INFO 139984794219904] Epoch[228] Batch [5]#011Speed: 248.20 samples/sec#011loss=2.664113\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:00 INFO 139984794219904] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315277.8910923, \"EndTime\": 1649315280.7867053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2895.118474960327, \"count\": 1, \"min\": 2895.118474960327, \"max\": 2895.118474960327}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:00 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.45216718916367 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 57.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=228, train loss <loss>=2.6559647798538206\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:00 INFO 139984794219904] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:00 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/state_14b17af6-171c-4def-ab03-b1d311adf02c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315280.7868032, \"EndTime\": 1649315280.8754504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 88.0880355834961, \"count\": 1, \"min\": 88.0880355834961, \"max\": 88.0880355834961}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:01 INFO 139984794219904] Epoch[229] Batch[0] avg_epoch_loss=2.561319\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=2.561318874359131\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:02 INFO 139984794219904] Epoch[229] Batch[5] avg_epoch_loss=2.686203\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=2.686203042666117\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:02 INFO 139984794219904] Epoch[229] Batch [5]#011Speed: 245.57 samples/sec#011loss=2.686203\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] Epoch[229] Batch[10] avg_epoch_loss=2.700574\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=229, batch=10 train loss <loss>=2.71781964302063\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] Epoch[229] Batch [10]#011Speed: 246.34 samples/sec#011loss=2.717820\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315280.8755388, \"EndTime\": 1649315284.068568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3192.952871322632, \"count\": 1, \"min\": 3192.952871322632, \"max\": 3192.952871322632}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.273150472161 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] #progress_metric: host=algo-1, completed 57.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=229, train loss <loss>=2.7005742246454414\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] Epoch[230] Batch[0] avg_epoch_loss=2.747665\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=2.7476654052734375\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:06 INFO 139984794219904] Epoch[230] Batch[5] avg_epoch_loss=2.755963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=2.755962530771891\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:06 INFO 139984794219904] Epoch[230] Batch [5]#011Speed: 237.51 samples/sec#011loss=2.755963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315284.0686622, \"EndTime\": 1649315287.0373294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2968.088150024414, \"count\": 1, \"min\": 2968.088150024414, \"max\": 2968.088150024414}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.26888455860188 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] #progress_metric: host=algo-1, completed 57.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=230, train loss <loss>=2.7698561191558837\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] Epoch[231] Batch[0] avg_epoch_loss=2.826844\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=2.8268444538116455\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:08 INFO 139984794219904] Epoch[231] Batch[5] avg_epoch_loss=2.721647\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=2.721647302309672\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:08 INFO 139984794219904] Epoch[231] Batch [5]#011Speed: 252.15 samples/sec#011loss=2.721647\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] Epoch[231] Batch[10] avg_epoch_loss=2.745984\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=2.7751880168914793\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] Epoch[231] Batch [10]#011Speed: 246.85 samples/sec#011loss=2.775188\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315287.0375772, \"EndTime\": 1649315290.1713428, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3133.1393718719482, \"count\": 1, \"min\": 3133.1393718719482, \"max\": 3133.1393718719482}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.64250575830417 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=231, train loss <loss>=2.7459839907559482\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] Epoch[232] Batch[0] avg_epoch_loss=2.738047\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=2.7380473613739014\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:11 INFO 139984794219904] Epoch[232] Batch[5] avg_epoch_loss=2.750580\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=2.750580072402954\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:11 INFO 139984794219904] Epoch[232] Batch [5]#011Speed: 273.77 samples/sec#011loss=2.750580\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] Epoch[232] Batch[10] avg_epoch_loss=2.787118\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=2.830962562561035\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] Epoch[232] Batch [10]#011Speed: 251.31 samples/sec#011loss=2.830963\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315290.1714237, \"EndTime\": 1649315293.1741893, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3002.3279190063477, \"count\": 1, \"min\": 3002.3279190063477, \"max\": 3002.3279190063477}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=226.14801754880384 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] #progress_metric: host=algo-1, completed 58.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=232, train loss <loss>=2.7871175679293545\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] Epoch[233] Batch[0] avg_epoch_loss=2.633640\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=2.6336400508880615\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] Epoch[233] Batch[5] avg_epoch_loss=2.750524\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=2.750524123509725\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] Epoch[233] Batch [5]#011Speed: 256.37 samples/sec#011loss=2.750524\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] processed a total of 586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315293.17428, \"EndTime\": 1649315295.9524255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2777.6403427124023, \"count\": 1, \"min\": 2777.6403427124023, \"max\": 2777.6403427124023}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.96017100920236 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] #progress_metric: host=algo-1, completed 58.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=233, train loss <loss>=2.785216236114502\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:15 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:16 INFO 139984794219904] Epoch[234] Batch[0] avg_epoch_loss=2.652866\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=2.6528663635253906\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:17 INFO 139984794219904] Epoch[234] Batch[5] avg_epoch_loss=2.763218\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=2.763218363126119\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:17 INFO 139984794219904] Epoch[234] Batch [5]#011Speed: 254.75 samples/sec#011loss=2.763218\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:18 INFO 139984794219904] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315295.9525263, \"EndTime\": 1649315298.78028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2827.265977859497, \"count\": 1, \"min\": 2827.265977859497, \"max\": 2827.265977859497}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:18 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=217.51405136525116 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:18 INFO 139984794219904] #progress_metric: host=algo-1, completed 58.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=234, train loss <loss>=2.772331476211548\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:18 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:19 INFO 139984794219904] Epoch[235] Batch[0] avg_epoch_loss=2.854621\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=2.854620933532715\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:20 INFO 139984794219904] Epoch[235] Batch[5] avg_epoch_loss=2.713400\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=2.713399648666382\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:20 INFO 139984794219904] Epoch[235] Batch [5]#011Speed: 249.69 samples/sec#011loss=2.713400\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:21 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315298.7803786, \"EndTime\": 1649315301.6464622, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2865.569591522217, \"count\": 1, \"min\": 2865.569591522217, \"max\": 2865.569591522217}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:21 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=222.63247212462053 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:21 INFO 139984794219904] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=235, train loss <loss>=2.7405244588851927\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:21 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:22 INFO 139984794219904] Epoch[236] Batch[0] avg_epoch_loss=2.696869\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=2.696868896484375\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:23 INFO 139984794219904] Epoch[236] Batch[5] avg_epoch_loss=2.723384\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=2.723384420077006\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:23 INFO 139984794219904] Epoch[236] Batch [5]#011Speed: 246.48 samples/sec#011loss=2.723384\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] Epoch[236] Batch[10] avg_epoch_loss=2.752516\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=2.787474203109741\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] Epoch[236] Batch [10]#011Speed: 271.18 samples/sec#011loss=2.787474\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315301.6465614, \"EndTime\": 1649315304.7326808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3085.616111755371, \"count\": 1, \"min\": 3085.616111755371, \"max\": 3085.616111755371}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.18232169187695 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] #progress_metric: host=algo-1, completed 59.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=236, train loss <loss>=2.7525161396373403\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:24 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:25 INFO 139984794219904] Epoch[237] Batch[0] avg_epoch_loss=2.872328\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=2.872328281402588\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:26 INFO 139984794219904] Epoch[237] Batch[5] avg_epoch_loss=2.752356\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=2.7523561318715415\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:26 INFO 139984794219904] Epoch[237] Batch [5]#011Speed: 266.09 samples/sec#011loss=2.752356\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:27 INFO 139984794219904] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315304.732771, \"EndTime\": 1649315307.474341, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2740.9257888793945, \"count\": 1, \"min\": 2740.9257888793945, \"max\": 2740.9257888793945}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:27 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=229.47230985222347 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:27 INFO 139984794219904] #progress_metric: host=algo-1, completed 59.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=237, train loss <loss>=2.720527505874634\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:27 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:28 INFO 139984794219904] Epoch[238] Batch[0] avg_epoch_loss=2.731613\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=2.7316129207611084\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:29 INFO 139984794219904] Epoch[238] Batch[5] avg_epoch_loss=2.727642\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=2.7276421387990317\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:29 INFO 139984794219904] Epoch[238] Batch [5]#011Speed: 257.69 samples/sec#011loss=2.727642\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315307.4744391, \"EndTime\": 1649315310.299583, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2824.4881629943848, \"count\": 1, \"min\": 2824.4881629943848, \"max\": 2824.4881629943848}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.9583250578971 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] #progress_metric: host=algo-1, completed 59.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=238, train loss <loss>=2.7518059253692626\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] Epoch[239] Batch[0] avg_epoch_loss=2.756827\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=2.756826877593994\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:32 INFO 139984794219904] Epoch[239] Batch[5] avg_epoch_loss=2.693110\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=2.6931103467941284\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:32 INFO 139984794219904] Epoch[239] Batch [5]#011Speed: 259.78 samples/sec#011loss=2.693110\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] Epoch[239] Batch[10] avg_epoch_loss=2.740653\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=2.7977034568786623\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] Epoch[239] Batch [10]#011Speed: 243.16 samples/sec#011loss=2.797703\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315310.299671, \"EndTime\": 1649315313.4271698, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3126.8694400787354, \"count\": 1, \"min\": 3126.8694400787354, \"max\": 3126.8694400787354}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=211.70545513601053 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=239, train loss <loss>=2.7406526695598257\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:33 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:34 INFO 139984794219904] Epoch[240] Batch[0] avg_epoch_loss=2.853033\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:34 INFO 139984794219904] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=2.8530330657958984\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:35 INFO 139984794219904] Epoch[240] Batch[5] avg_epoch_loss=2.790500\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=2.790499965349833\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:35 INFO 139984794219904] Epoch[240] Batch [5]#011Speed: 260.33 samples/sec#011loss=2.790500\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315313.4272463, \"EndTime\": 1649315316.265104, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2837.3734951019287, \"count\": 1, \"min\": 2837.3734951019287, \"max\": 2837.3734951019287}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=225.55006571092787 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] #progress_metric: host=algo-1, completed 60.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=240, train loss <loss>=2.769952344894409\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] Epoch[241] Batch[0] avg_epoch_loss=2.665426\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=2.66542649269104\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:38 INFO 139984794219904] Epoch[241] Batch[5] avg_epoch_loss=2.794907\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=2.7949065367380777\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:38 INFO 139984794219904] Epoch[241] Batch [5]#011Speed: 258.28 samples/sec#011loss=2.794907\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] Epoch[241] Batch[10] avg_epoch_loss=2.778495\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=2.758800220489502\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] Epoch[241] Batch [10]#011Speed: 260.35 samples/sec#011loss=2.758800\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315316.265199, \"EndTime\": 1649315319.3276384, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3061.9585514068604, \"count\": 1, \"min\": 3061.9585514068604, \"max\": 3061.9585514068604}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.25279609659503 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] #progress_metric: host=algo-1, completed 60.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=241, train loss <loss>=2.7784945748069068\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] Epoch[242] Batch[0] avg_epoch_loss=2.828765\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=2.8287646770477295\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:41 INFO 139984794219904] Epoch[242] Batch[5] avg_epoch_loss=2.778820\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=2.778819759686788\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:41 INFO 139984794219904] Epoch[242] Batch [5]#011Speed: 254.67 samples/sec#011loss=2.778820\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] Epoch[242] Batch[10] avg_epoch_loss=2.848529\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=242, batch=10 train loss <loss>=2.9321806907653807\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] Epoch[242] Batch [10]#011Speed: 247.38 samples/sec#011loss=2.932181\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315319.327727, \"EndTime\": 1649315322.4703512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3142.1070098876953, \"count\": 1, \"min\": 3142.1070098876953, \"max\": 3142.1070098876953}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.7221854354633 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] #progress_metric: host=algo-1, completed 60.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=242, train loss <loss>=2.848529273813421\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:42 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:43 INFO 139984794219904] Epoch[243] Batch[0] avg_epoch_loss=3.319472\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:43 INFO 139984794219904] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=3.319472074508667\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:44 INFO 139984794219904] Epoch[243] Batch[5] avg_epoch_loss=2.906728\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=2.9067278703053794\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:44 INFO 139984794219904] Epoch[243] Batch [5]#011Speed: 267.37 samples/sec#011loss=2.906728\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] Epoch[243] Batch[10] avg_epoch_loss=2.782152\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=2.6326611995697022\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] Epoch[243] Batch [10]#011Speed: 262.43 samples/sec#011loss=2.632661\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315322.4704463, \"EndTime\": 1649315325.4922357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3021.256446838379, \"count\": 1, \"min\": 3021.256446838379, \"max\": 3021.256446838379}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=212.1551664505961 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=243, train loss <loss>=2.7821521108800713\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:45 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:46 INFO 139984794219904] Epoch[244] Batch[0] avg_epoch_loss=2.768565\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=2.7685654163360596\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:47 INFO 139984794219904] Epoch[244] Batch[5] avg_epoch_loss=2.791302\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:47 INFO 139984794219904] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=2.7913021643956504\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:47 INFO 139984794219904] Epoch[244] Batch [5]#011Speed: 267.93 samples/sec#011loss=2.791302\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] Epoch[244] Batch[10] avg_epoch_loss=2.834272\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=244, batch=10 train loss <loss>=2.8858362197875977\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] Epoch[244] Batch [10]#011Speed: 241.75 samples/sec#011loss=2.885836\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315325.4923162, \"EndTime\": 1649315328.561617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3068.8772201538086, \"count\": 1, \"min\": 3068.8772201538086, \"max\": 3068.8772201538086}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.032186410084 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] #progress_metric: host=algo-1, completed 61.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=244, train loss <loss>=2.834272189573808\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:48 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:49 INFO 139984794219904] Epoch[245] Batch[0] avg_epoch_loss=2.757615\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=2.7576146125793457\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:50 INFO 139984794219904] Epoch[245] Batch[5] avg_epoch_loss=2.726362\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=2.726361552874247\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:50 INFO 139984794219904] Epoch[245] Batch [5]#011Speed: 248.43 samples/sec#011loss=2.726362\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:51 INFO 139984794219904] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315328.5616963, \"EndTime\": 1649315331.521714, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2959.59210395813, \"count\": 1, \"min\": 2959.59210395813, \"max\": 2959.59210395813}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:51 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=210.8256158156083 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:51 INFO 139984794219904] #progress_metric: host=algo-1, completed 61.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=245, train loss <loss>=2.7388235092163087\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:51 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:52 INFO 139984794219904] Epoch[246] Batch[0] avg_epoch_loss=2.760906\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=2.7609059810638428\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:53 INFO 139984794219904] Epoch[246] Batch[5] avg_epoch_loss=2.739336\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:53 INFO 139984794219904] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=2.739335616429647\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:53 INFO 139984794219904] Epoch[246] Batch [5]#011Speed: 254.74 samples/sec#011loss=2.739336\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315331.521872, \"EndTime\": 1649315334.3482225, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2825.791358947754, \"count\": 1, \"min\": 2825.791358947754, \"max\": 2825.791358947754}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=223.63597316233466 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] #progress_metric: host=algo-1, completed 61.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=246, train loss <loss>=2.7531253814697267\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] Epoch[247] Batch[0] avg_epoch_loss=2.676142\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=2.6761419773101807\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:56 INFO 139984794219904] Epoch[247] Batch[5] avg_epoch_loss=2.672997\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:56 INFO 139984794219904] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=2.6729968388875327\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:56 INFO 139984794219904] Epoch[247] Batch [5]#011Speed: 258.77 samples/sec#011loss=2.672997\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] Epoch[247] Batch[10] avg_epoch_loss=2.713246\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=2.76154465675354\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] Epoch[247] Batch [10]#011Speed: 250.26 samples/sec#011loss=2.761545\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315334.348407, \"EndTime\": 1649315337.4614322, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3112.3015880584717, \"count\": 1, \"min\": 3112.3015880584717, \"max\": 3112.3015880584717}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.912309310615 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=247, train loss <loss>=2.713245847008445\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:57 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:58 INFO 139984794219904] Epoch[248] Batch[0] avg_epoch_loss=2.829621\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=2.829620599746704\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:59 INFO 139984794219904] Epoch[248] Batch[5] avg_epoch_loss=2.723829\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:59 INFO 139984794219904] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=2.723828593889872\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:08:59 INFO 139984794219904] Epoch[248] Batch [5]#011Speed: 260.59 samples/sec#011loss=2.723829\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] Epoch[248] Batch[10] avg_epoch_loss=2.698862\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=2.6689016819000244\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] Epoch[248] Batch [10]#011Speed: 243.47 samples/sec#011loss=2.668902\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315337.4615068, \"EndTime\": 1649315340.5957355, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3133.7738037109375, \"count\": 1, \"min\": 3133.7738037109375, \"max\": 3133.7738037109375}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.32423274973078 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 62.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=248, train loss <loss>=2.6988618157126685\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:00 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:01 INFO 139984794219904] Epoch[249] Batch[0] avg_epoch_loss=2.766145\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:01 INFO 139984794219904] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=2.7661449909210205\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:02 INFO 139984794219904] Epoch[249] Batch[5] avg_epoch_loss=2.746070\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:02 INFO 139984794219904] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=2.7460699876149497\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:02 INFO 139984794219904] Epoch[249] Batch [5]#011Speed: 246.59 samples/sec#011loss=2.746070\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:03 INFO 139984794219904] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315340.5958238, \"EndTime\": 1649315343.5292459, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2932.9419136047363, \"count\": 1, \"min\": 2932.9419136047363, \"max\": 2932.9419136047363}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:03 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.49653635037708 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:03 INFO 139984794219904] #progress_metric: host=algo-1, completed 62.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:03 INFO 139984794219904] #quality_metric: host=algo-1, epoch=249, train loss <loss>=2.772625780105591\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:03 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:04 INFO 139984794219904] Epoch[250] Batch[0] avg_epoch_loss=2.736323\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:04 INFO 139984794219904] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=2.7363228797912598\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:05 INFO 139984794219904] Epoch[250] Batch[5] avg_epoch_loss=2.719140\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:05 INFO 139984794219904] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=2.7191398541132608\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:05 INFO 139984794219904] Epoch[250] Batch [5]#011Speed: 244.85 samples/sec#011loss=2.719140\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:06 INFO 139984794219904] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315343.5293455, \"EndTime\": 1649315346.5098379, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2979.9883365631104, \"count\": 1, \"min\": 2979.9883365631104, \"max\": 2979.9883365631104}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:06 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=209.72390773664924 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:06 INFO 139984794219904] #progress_metric: host=algo-1, completed 62.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:06 INFO 139984794219904] #quality_metric: host=algo-1, epoch=250, train loss <loss>=2.7309895753860474\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:06 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:07 INFO 139984794219904] Epoch[251] Batch[0] avg_epoch_loss=2.747917\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:07 INFO 139984794219904] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=2.747917413711548\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:08 INFO 139984794219904] Epoch[251] Batch[5] avg_epoch_loss=2.711787\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:08 INFO 139984794219904] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=2.711786945660909\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:08 INFO 139984794219904] Epoch[251] Batch [5]#011Speed: 258.14 samples/sec#011loss=2.711787\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] Epoch[251] Batch[10] avg_epoch_loss=2.792290\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=2.8888939380645753\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] Epoch[251] Batch [10]#011Speed: 245.59 samples/sec#011loss=2.888894\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315346.50992, \"EndTime\": 1649315349.6189606, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3108.556032180786, \"count\": 1, \"min\": 3108.556032180786, \"max\": 3108.556032180786}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=206.1966519671616 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] #quality_metric: host=algo-1, epoch=251, train loss <loss>=2.792290124026212\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:09 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:10 INFO 139984794219904] Epoch[252] Batch[0] avg_epoch_loss=2.750760\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:10 INFO 139984794219904] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=2.7507596015930176\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:11 INFO 139984794219904] Epoch[252] Batch[5] avg_epoch_loss=2.731059\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:11 INFO 139984794219904] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=2.731058677037557\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:11 INFO 139984794219904] Epoch[252] Batch [5]#011Speed: 240.24 samples/sec#011loss=2.731059\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:12 INFO 139984794219904] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315349.6190414, \"EndTime\": 1649315352.5963614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2976.7141342163086, \"count\": 1, \"min\": 2976.7141342163086, \"max\": 2976.7141342163086}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:12 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=203.90854311185237 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:12 INFO 139984794219904] #progress_metric: host=algo-1, completed 63.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:12 INFO 139984794219904] #quality_metric: host=algo-1, epoch=252, train loss <loss>=2.6841175317764283\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:12 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:13 INFO 139984794219904] Epoch[253] Batch[0] avg_epoch_loss=2.807683\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:13 INFO 139984794219904] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=2.807682752609253\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:14 INFO 139984794219904] Epoch[253] Batch[5] avg_epoch_loss=2.738322\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:14 INFO 139984794219904] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=2.7383217811584473\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:14 INFO 139984794219904] Epoch[253] Batch [5]#011Speed: 246.34 samples/sec#011loss=2.738322\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] Epoch[253] Batch[10] avg_epoch_loss=2.796471\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=253, batch=10 train loss <loss>=2.8662498950958253\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] Epoch[253] Batch [10]#011Speed: 258.62 samples/sec#011loss=2.866250\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315352.5964358, \"EndTime\": 1649315355.7405195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3143.5184478759766, \"count\": 1, \"min\": 3143.5184478759766, \"max\": 3143.5184478759766}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=203.9043089199176 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] #progress_metric: host=algo-1, completed 63.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] #quality_metric: host=algo-1, epoch=253, train loss <loss>=2.7964709238572554\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:15 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:16 INFO 139984794219904] Epoch[254] Batch[0] avg_epoch_loss=2.631430\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:16 INFO 139984794219904] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=2.63142991065979\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:17 INFO 139984794219904] Epoch[254] Batch[5] avg_epoch_loss=2.734011\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:17 INFO 139984794219904] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=2.734010696411133\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:17 INFO 139984794219904] Epoch[254] Batch [5]#011Speed: 246.21 samples/sec#011loss=2.734011\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] Epoch[254] Batch[10] avg_epoch_loss=2.746251\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=254, batch=10 train loss <loss>=2.760939931869507\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] Epoch[254] Batch [10]#011Speed: 249.28 samples/sec#011loss=2.760940\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315355.7405977, \"EndTime\": 1649315358.9124997, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3171.438694000244, \"count\": 1, \"min\": 3171.438694000244, \"max\": 3171.438694000244}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.15239070846724 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] #progress_metric: host=algo-1, completed 63.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] #quality_metric: host=algo-1, epoch=254, train loss <loss>=2.746251257983121\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:18 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:19 INFO 139984794219904] Epoch[255] Batch[0] avg_epoch_loss=2.987003\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:19 INFO 139984794219904] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=2.9870028495788574\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:20 INFO 139984794219904] Epoch[255] Batch[5] avg_epoch_loss=2.828476\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:20 INFO 139984794219904] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=2.828475991884867\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:20 INFO 139984794219904] Epoch[255] Batch [5]#011Speed: 246.15 samples/sec#011loss=2.828476\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:21 INFO 139984794219904] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315358.9125967, \"EndTime\": 1649315361.8352165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2922.05548286438, \"count\": 1, \"min\": 2922.05548286438, \"max\": 2922.05548286438}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:21 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.22235624542694 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:21 INFO 139984794219904] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:21 INFO 139984794219904] #quality_metric: host=algo-1, epoch=255, train loss <loss>=2.7986806631088257\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:21 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:22 INFO 139984794219904] Epoch[256] Batch[0] avg_epoch_loss=2.868652\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:22 INFO 139984794219904] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=2.86865234375\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:23 INFO 139984794219904] Epoch[256] Batch[5] avg_epoch_loss=2.733322\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:23 INFO 139984794219904] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=2.73332150777181\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:23 INFO 139984794219904] Epoch[256] Batch [5]#011Speed: 270.53 samples/sec#011loss=2.733322\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:24 INFO 139984794219904] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315361.83531, \"EndTime\": 1649315364.6424165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2806.5974712371826, \"count\": 1, \"min\": 2806.5974712371826, \"max\": 2806.5974712371826}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:24 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=224.81778926092653 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:24 INFO 139984794219904] #progress_metric: host=algo-1, completed 64.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:24 INFO 139984794219904] #quality_metric: host=algo-1, epoch=256, train loss <loss>=2.735584020614624\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:24 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:25 INFO 139984794219904] Epoch[257] Batch[0] avg_epoch_loss=2.598438\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:25 INFO 139984794219904] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=2.598437547683716\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:26 INFO 139984794219904] Epoch[257] Batch[5] avg_epoch_loss=2.700414\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:26 INFO 139984794219904] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=2.7004138628641763\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:26 INFO 139984794219904] Epoch[257] Batch [5]#011Speed: 252.16 samples/sec#011loss=2.700414\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:27 INFO 139984794219904] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315364.6425018, \"EndTime\": 1649315367.5410361, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2897.9649543762207, \"count\": 1, \"min\": 2897.9649543762207, \"max\": 2897.9649543762207}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:27 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=208.74706217889624 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:27 INFO 139984794219904] #progress_metric: host=algo-1, completed 64.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:27 INFO 139984794219904] #quality_metric: host=algo-1, epoch=257, train loss <loss>=2.7333224534988405\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:27 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:28 INFO 139984794219904] Epoch[258] Batch[0] avg_epoch_loss=2.847300\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:28 INFO 139984794219904] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=2.8473000526428223\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:29 INFO 139984794219904] Epoch[258] Batch[5] avg_epoch_loss=2.738972\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:29 INFO 139984794219904] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=2.7389720678329468\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:29 INFO 139984794219904] Epoch[258] Batch [5]#011Speed: 253.76 samples/sec#011loss=2.738972\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315367.541272, \"EndTime\": 1649315370.3740892, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2832.2417736053467, \"count\": 1, \"min\": 2832.2417736053467, \"max\": 2832.2417736053467}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=225.25252231741328 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] #progress_metric: host=algo-1, completed 64.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=258, train loss <loss>=2.721740221977234\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] Epoch[259] Batch[0] avg_epoch_loss=2.743541\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:30 INFO 139984794219904] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=2.7435410022735596\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:32 INFO 139984794219904] Epoch[259] Batch[5] avg_epoch_loss=2.778104\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:32 INFO 139984794219904] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=2.7781037092208862\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:32 INFO 139984794219904] Epoch[259] Batch [5]#011Speed: 245.80 samples/sec#011loss=2.778104\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315370.374187, \"EndTime\": 1649315373.262159, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2887.2835636138916, \"count\": 1, \"min\": 2887.2835636138916, \"max\": 2887.2835636138916}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=215.07064965772918 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=259, train loss <loss>=2.7522983074188234\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] Epoch[260] Batch[0] avg_epoch_loss=2.712783\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:33 INFO 139984794219904] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=2.712782621383667\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:35 INFO 139984794219904] Epoch[260] Batch[5] avg_epoch_loss=2.774994\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:35 INFO 139984794219904] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=2.7749942938486734\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:35 INFO 139984794219904] Epoch[260] Batch [5]#011Speed: 247.57 samples/sec#011loss=2.774994\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] Epoch[260] Batch[10] avg_epoch_loss=2.690880\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=2.5899434089660645\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] Epoch[260] Batch [10]#011Speed: 265.33 samples/sec#011loss=2.589943\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315373.262256, \"EndTime\": 1649315376.3508236, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3088.067054748535, \"count\": 1, \"min\": 3088.067054748535, \"max\": 3088.067054748535}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=207.56479953356865 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] #progress_metric: host=algo-1, completed 65.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=260, train loss <loss>=2.6908802552656694\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] Epoch[261] Batch[0] avg_epoch_loss=2.807979\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:36 INFO 139984794219904] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=2.807978630065918\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:38 INFO 139984794219904] Epoch[261] Batch[5] avg_epoch_loss=2.700521\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:38 INFO 139984794219904] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=2.7005207935969033\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:38 INFO 139984794219904] Epoch[261] Batch [5]#011Speed: 260.63 samples/sec#011loss=2.700521\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] Epoch[261] Batch[10] avg_epoch_loss=2.694549\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=261, batch=10 train loss <loss>=2.6873827934265138\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] Epoch[261] Batch [10]#011Speed: 239.04 samples/sec#011loss=2.687383\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315376.3509092, \"EndTime\": 1649315379.5055616, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3154.094457626343, \"count\": 1, \"min\": 3154.094457626343, \"max\": 3154.094457626343}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=220.02349076434783 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] #progress_metric: host=algo-1, completed 65.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] #quality_metric: host=algo-1, epoch=261, train loss <loss>=2.6945489753376353\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:39 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:40 INFO 139984794219904] Epoch[262] Batch[0] avg_epoch_loss=2.734063\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:40 INFO 139984794219904] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=2.734062910079956\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:41 INFO 139984794219904] Epoch[262] Batch[5] avg_epoch_loss=2.682795\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:41 INFO 139984794219904] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=2.6827951272328696\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:41 INFO 139984794219904] Epoch[262] Batch [5]#011Speed: 267.34 samples/sec#011loss=2.682795\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315379.5056398, \"EndTime\": 1649315382.3036327, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2797.5497245788574, \"count\": 1, \"min\": 2797.5497245788574, \"max\": 2797.5497245788574}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=219.8244248872392 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] #progress_metric: host=algo-1, completed 65.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=262, train loss <loss>=2.6908303260803224\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] Epoch[263] Batch[0] avg_epoch_loss=2.705806\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:42 INFO 139984794219904] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=2.705806255340576\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:44 INFO 139984794219904] Epoch[263] Batch[5] avg_epoch_loss=2.709928\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:44 INFO 139984794219904] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=2.709928115208944\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:44 INFO 139984794219904] Epoch[263] Batch [5]#011Speed: 268.42 samples/sec#011loss=2.709928\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315382.3037293, \"EndTime\": 1649315385.0042083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2699.798583984375, \"count\": 1, \"min\": 2699.798583984375, \"max\": 2699.798583984375}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=234.82055437383391 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=263, train loss <loss>=2.6930708408355715\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] Epoch[264] Batch[0] avg_epoch_loss=2.745826\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:45 INFO 139984794219904] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=2.745826244354248\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:46 INFO 139984794219904] Epoch[264] Batch[5] avg_epoch_loss=2.708080\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:46 INFO 139984794219904] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=2.708080252011617\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:46 INFO 139984794219904] Epoch[264] Batch [5]#011Speed: 262.01 samples/sec#011loss=2.708080\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] Epoch[264] Batch[10] avg_epoch_loss=2.736972\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=264, batch=10 train loss <loss>=2.771642303466797\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] Epoch[264] Batch [10]#011Speed: 242.96 samples/sec#011loss=2.771642\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315385.0043063, \"EndTime\": 1649315388.0925279, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3087.5277519226074, \"count\": 1, \"min\": 3087.5277519226074, \"max\": 3087.5277519226074}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=213.75398437384175 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] #progress_metric: host=algo-1, completed 66.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=264, train loss <loss>=2.7369720935821533\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] Epoch[265] Batch[0] avg_epoch_loss=2.850406\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:48 INFO 139984794219904] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=2.850405693054199\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:49 INFO 139984794219904] Epoch[265] Batch[5] avg_epoch_loss=2.750618\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:49 INFO 139984794219904] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=2.750618497530619\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:49 INFO 139984794219904] Epoch[265] Batch [5]#011Speed: 269.18 samples/sec#011loss=2.750618\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:50 INFO 139984794219904] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315388.092614, \"EndTime\": 1649315390.873, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2779.909610748291, \"count\": 1, \"min\": 2779.909610748291, \"max\": 2779.909610748291}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:50 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=221.57868844389094 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:50 INFO 139984794219904] #progress_metric: host=algo-1, completed 66.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:50 INFO 139984794219904] #quality_metric: host=algo-1, epoch=265, train loss <loss>=2.7756451606750487\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:50 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:51 INFO 139984794219904] Epoch[266] Batch[0] avg_epoch_loss=2.704995\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:51 INFO 139984794219904] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=2.7049951553344727\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:52 INFO 139984794219904] Epoch[266] Batch[5] avg_epoch_loss=2.708989\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:52 INFO 139984794219904] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=2.708988904953003\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:52 INFO 139984794219904] Epoch[266] Batch [5]#011Speed: 249.29 samples/sec#011loss=2.708989\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] Epoch[266] Batch[10] avg_epoch_loss=2.725483\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=266, batch=10 train loss <loss>=2.7452768802642824\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] Epoch[266] Batch [10]#011Speed: 252.87 samples/sec#011loss=2.745277\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315390.8731027, \"EndTime\": 1649315394.0165, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3142.90189743042, \"count\": 1, \"min\": 3142.90189743042, \"max\": 3142.90189743042}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.0323977396467 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] #progress_metric: host=algo-1, completed 66.75 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=266, train loss <loss>=2.725483439185403\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] Epoch[267] Batch[0] avg_epoch_loss=2.666067\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:54 INFO 139984794219904] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=2.666067123413086\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:55 INFO 139984794219904] Epoch[267] Batch[5] avg_epoch_loss=2.702582\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:55 INFO 139984794219904] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=2.702582279841105\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:55 INFO 139984794219904] Epoch[267] Batch [5]#011Speed: 261.17 samples/sec#011loss=2.702582\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] Epoch[267] Batch[10] avg_epoch_loss=2.661806\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=267, batch=10 train loss <loss>=2.6128735065460207\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] Epoch[267] Batch [10]#011Speed: 252.99 samples/sec#011loss=2.612874\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315394.0166044, \"EndTime\": 1649315397.1202114, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3103.0118465423584, \"count\": 1, \"min\": 3103.0118465423584, \"max\": 3103.0118465423584}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=216.87654071523392 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=267, train loss <loss>=2.6618055647069756\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] Epoch[268] Batch[0] avg_epoch_loss=2.683268\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:57 INFO 139984794219904] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=2.6832683086395264\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:58 INFO 139984794219904] Epoch[268] Batch[5] avg_epoch_loss=2.739286\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:58 INFO 139984794219904] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=2.7392861445744834\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:09:58 INFO 139984794219904] Epoch[268] Batch [5]#011Speed: 247.26 samples/sec#011loss=2.739286\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] Epoch[268] Batch[10] avg_epoch_loss=2.672381\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=2.592093896865845\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] Epoch[268] Batch [10]#011Speed: 238.32 samples/sec#011loss=2.592094\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315397.120303, \"EndTime\": 1649315400.3030849, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3182.2280883789062, \"count\": 1, \"min\": 3182.2280883789062, \"max\": 3182.2280883789062}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] #throughput_metric: host=algo-1, train throughput=214.6187835717654 records/second\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 67.25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] #quality_metric: host=algo-1, epoch=268, train loss <loss>=2.672380577434193\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] Loading parameters from best epoch (228)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315400.303196, \"EndTime\": 1649315400.336454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 32.55462646484375, \"count\": 1, \"min\": 32.55462646484375, \"max\": 32.55462646484375}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] stopping training now\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] Final loss: 2.6559647798538206 (occurred at epoch 228)\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] #quality_metric: host=algo-1, train final_loss <loss>=2.6559647798538206\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 WARNING 139984794219904] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:00 INFO 139984794219904] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315400.3365664, \"EndTime\": 1649315401.1655445, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 827.9764652252197, \"count\": 1, \"min\": 827.9764652252197, \"max\": 827.9764652252197}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:01 INFO 139984794219904] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315401.1656349, \"EndTime\": 1649315401.4048593, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 1067.3389434814453, \"count\": 1, \"min\": 1067.3389434814453, \"max\": 1067.3389434814453}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:01 INFO 139984794219904] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:01 INFO 139984794219904] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315401.404959, \"EndTime\": 1649315401.442044, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 37.035465240478516, \"count\": 1, \"min\": 37.035465240478516, \"max\": 37.035465240478516}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:01 INFO 139984794219904] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:01 INFO 139984794219904] #memory_usage::<batchbuffer> = 20.827598571777344 mb\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:01 INFO 139984794219904] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315401.4421072, \"EndTime\": 1649315401.443056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.04482269287109375, \"count\": 1, \"min\": 0.04482269287109375, \"max\": 0.04482269287109375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315401.4431155, \"EndTime\": 1649315405.532, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 4088.9973640441895, \"count\": 1, \"min\": 4088.9973640441895, \"max\": 4088.9973640441895}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, RMSE): 5.8989878147238874\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, mean_absolute_QuantileLoss): 1832.4389066113367\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, mean_wQuantileLoss): 0.025094769727938105\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.1]): 0.014288400874851281\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.2]): 0.0225867036869799\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.3]): 0.027742677318998123\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.4]): 0.030750283284544076\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.5]): 0.03149062662526271\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.6]): 0.03079409803616571\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.7]): 0.028418682243083953\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.8]): 0.023746501104391464\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #test_score (algo-1, wQuantileLoss[0.9]): 0.016034954377165744\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #quality_metric: host=algo-1, test RMSE <loss>=5.8989878147238874\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.025094769727938105\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1649315405.532077, \"EndTime\": 1649315405.5867138, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 7.18235969543457, \"count\": 1, \"min\": 7.18235969543457, \"max\": 7.18235969543457}, \"totaltime\": {\"sum\": 810407.5071811676, \"count\": 1, \"min\": 810407.5071811676, \"max\": 810407.5071811676}}}\u001b[0m\n",
      "\u001b[34m[04/07/2022 07:10:05 INFO 139984794219904 integration.py:592] worker closed\u001b[0m\n",
      "\n",
      "2022-04-07 07:10:20 Uploading - Uploading generated training model\n",
      "2022-04-07 07:10:20 Completed - Training job completed\n",
      "Training seconds: 886\n",
      "Billable seconds: 886\n",
      "CPU times: user 2.43 s, sys: 165 ms, total: 2.6 s\n",
      "Wall time: 16min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/test/\".format(s3_data_path)\n",
    "}\n",
    "\n",
    "estimator.fit(\n",
    "    inputs=data_channels,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe05be5",
   "metadata": {},
   "source": [
    "### Create endpoint and predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e3f75",
   "metadata": {},
   "source": [
    "Now that we have a trained model, we can use it to perform predictions by deploying it to an endpoint.\n",
    "\n",
    "**Note: Remember to delete the endpoint after running this experiment. A cell at the very bottom of this notebook will do that: make sure you run it at the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40051975",
   "metadata": {},
   "source": [
    "To query the endpoint and perform predictions, we can define the following utility class: this allows making requests using `pandas.Series` objects rather than raw JSON strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229b58f",
   "metadata": {},
   "source": [
    "Create endpoint and predictor\n",
    "Now that we have a trained model, we can use it to perform predictions by deploying it to an endpoint.\n",
    "\n",
    "Note: Remember to delete the endpoint after running this experiment. A cell at the very bottom of this notebook will do that: make sure you run it at the end.\n",
    "\n",
    "To query the endpoint and perform predictions, we can define the following utility class: this allows making requests using pandas.Series objects rather than raw JSON strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "71bc1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + pd.Timedelta(freq)\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        #prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)\n",
    "        prediction_index = pd.date_range(prediction_time, periods = prediction_length, freq=freq)\n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3499fa",
   "metadata": {},
   "source": [
    "Now we can deploy the model and create and endpoint that can be queried using our custom DeepARPredictor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7ff53105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ea8e5d35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from primary with message \"Customer Error: Content-Type header value 'application/octet-stream' not supported (caused by KeyError)\n\nCaused by: 'application/octet-stream'\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/redshift-deepar-nyctaxi-demo-2022-04-07-08-20-28-192 in account 988889742134 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-793dfe0c76ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-229-0fa6f9626a46>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mquantiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__encode_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeepARPredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__decode_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    400\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (415) from primary with message \"Customer Error: Content-Type header value 'application/octet-stream' not supported (caused by KeyError)\n\nCaused by: 'application/octet-stream'\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/redshift-deepar-nyctaxi-demo-2022-04-07-08-20-28-192 in account 988889742134 for more information."
     ]
    }
   ],
   "source": [
    "predictor.predict(ts=timeseries[1], quantiles=[0.10, 0.5, 0.90]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd2dd5",
   "metadata": {},
   "source": [
    "### Delete endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f0dd77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bfb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
