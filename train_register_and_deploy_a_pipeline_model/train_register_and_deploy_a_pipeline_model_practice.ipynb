{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Builds and Trains a Pipeline Model consisting of a preprocessing SKLearn script followed by a Tensorflow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The pipeline model is then registered to the Model Registry and deployed from there into a real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role:  arn:aws:iam::988889742134:role/service-role/AmazonSageMaker-ExecutionRole-20220315T092490\n",
      "bucket name:  sagemaker-pipeline-practice\n",
      "region name:  ap-northeast-2\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "sagemaker_client = session.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "print(\"sagemaker role: \", sagemaker_role)\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "\n",
    "bucket_nm = \"sagemaker-pipeline-practice\"\n",
    "print(\"bucket name: \", bucket_nm)\n",
    "\n",
    "region_nm = session.region_name\n",
    "print(\"region name: \", region_nm)\n",
    "\n",
    "model_package_group_name = \"PipelineModelPackageGroup\"\n",
    "prefix = \"pipeline-model-example\"\n",
    "pipeline_name = \"TrainingPipelineForModel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"http://sagemaker-pipeline-practice.s3.amazonaws.com/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws s3api create-bucket --bucket $bucket_nm --create-bucket-configuration LocationConstraint=$region_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download California Housing dataset and upload to Amazon S3\n",
    "\n",
    "We use the California housing dataset.\n",
    "\n",
    "More info on the dataset:\n",
    "\n",
    "This dataset was obtained from the StatLib repository. http://lib.stat.cmu.edu/datasets/\n",
    "\n",
    "The target variable is the median house value for California districts.\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path:  /root/amazon-sagemaker-practices/train_register_and_deploy_a_pipeline_model\n",
      "data dir path:  /root/amazon-sagemaker-practices/train_register_and_deploy_a_pipeline_model/data\n",
      "raw data dir path:  /root/amazon-sagemaker-practices/train_register_and_deploy_a_pipeline_model/data/raw\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "print(\"current path: \", current_path)\n",
    "\n",
    "data_dir = os.path.join(current_path, \"data\")\n",
    "print(\"data dir path: \", data_dir)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "raw_dir = os.path.join(current_path, \"data/raw\")\n",
    "print(\"raw data dir path: \", raw_dir)\n",
    "os.makedirs(raw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-files/datasets/tabular/california_housing/cal_housing.tgz to ./cal_housing.tgz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/datasets/tabular/california_housing/cal_housing.tgz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: CaliforniaHousing/cal_housing.data: Cannot change ownership to uid 10017, gid 166: Operation not permitted\n",
      "tar: CaliforniaHousing/cal_housing.domain: Cannot change ownership to uid 10017, gid 166: Operation not permitted\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "!tar -zxf cal_housing.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "    \"medianHouseValue\",\n",
    "]\n",
    "\n",
    "cal_housing_df = pd.read_csv(\"CaliforniaHousing/cal_housing.data\", names=columns, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
       "0    -122.23     37.88              41.0       880.0          129.0   \n",
       "1    -122.22     37.86              21.0      7099.0         1106.0   \n",
       "2    -122.24     37.85              52.0      1467.0          190.0   \n",
       "3    -122.25     37.85              52.0      1274.0          235.0   \n",
       "4    -122.25     37.85              52.0      1627.0          280.0   \n",
       "\n",
       "   population  households  medianIncome  medianHouseValue  \n",
       "0       322.0       126.0        8.3252          452600.0  \n",
       "1      2401.0      1138.0        8.3014          358500.0  \n",
       "2       496.0       177.0        7.2574          352100.0  \n",
       "3       558.0       219.0        5.6431          341300.0  \n",
       "4       565.0       259.0        3.8462          342200.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing_df[\n",
    "    \"medianHouseValue\"\n",
    "] /= 500000  # Scaling target down to avoid overcomplicating the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>0.9052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>0.7170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>0.7042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>0.6826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>0.6844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
       "0    -122.23     37.88              41.0       880.0          129.0   \n",
       "1    -122.22     37.86              21.0      7099.0         1106.0   \n",
       "2    -122.24     37.85              52.0      1467.0          190.0   \n",
       "3    -122.25     37.85              52.0      1274.0          235.0   \n",
       "4    -122.25     37.85              52.0      1627.0          280.0   \n",
       "\n",
       "   population  households  medianIncome  medianHouseValue  \n",
       "0       322.0       126.0        8.3252            0.9052  \n",
       "1      2401.0      1138.0        8.3014            0.7170  \n",
       "2       496.0       177.0        7.2574            0.7042  \n",
       "3       558.0       219.0        5.6431            0.6826  \n",
       "4       565.0       259.0        3.8462            0.6844  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing_df.to_csv(f\"./data/raw/raw_data_all.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data s3 prefix:  pipeline-model-example/data/raw\n"
     ]
    }
   ],
   "source": [
    "rawdata_s3_prefix = \"{}/data/raw\".format(prefix)\n",
    "print(\"raw data s3 prefix: \", rawdata_s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data s3 path:  s3://sagemaker-pipeline-practice/pipeline-model-example/data/raw\n"
     ]
    }
   ],
   "source": [
    "raw_s3 = sagemaker_session.upload_data(\n",
    "    path=\"./data/raw/\",\n",
    "    bucket=bucket_nm,\n",
    "    key_prefix=rawdata_s3_prefix\n",
    ")\n",
    "print(\"input data s3 path: \", raw_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters to Parametrize Pipeline Execution\n",
    "- Define Pipeline parameters that you can use to parametrize the pipeline.\n",
    "- Parameters enable custom pipeline executions and schedules without having to modify the Pipeline definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "- ParameterString: represents a str Python type\n",
    "- ParameterInteger: represents an int Python type\n",
    "- ParameterFloat: represents a float Python type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputData - s3://sagemaker-pipeline-practice/pipeline-model-example/data/raw\n",
      "ModelApprovalStatus - Approved\n",
      "ProcessingInstanceCount - 1\n",
      "ProcessingInstanceType - ml.m5.large\n",
      "TrainingInstanceType - ml.m5.xlarge\n",
      "TrainingEpochs - 100\n",
      "AccuracyMseThreshold - 0.75\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "\n",
    "# raw input data\n",
    "input_data_info = {\n",
    "    \"name\": \"InputData\",\n",
    "    \"default_value\": raw_s3\n",
    "}\n",
    "\n",
    "input_data = ParameterString(**input_data_info)\n",
    "print(f\"{input_data.name} - {input_data.default_value}\")\n",
    "\n",
    "# status of newly trained model in registry\n",
    "model_approval_status_info = {\n",
    "    \"name\": \"ModelApprovalStatus\",\n",
    "    \"default_value\": \"Approved\"\n",
    "}\n",
    "\n",
    "model_approval_status = ParameterString(**model_approval_status_info)\n",
    "print(f\"{model_approval_status.name} - {model_approval_status.default_value}\")\n",
    "\n",
    "# processing step parameters\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\", \n",
    "    default_value=1\n",
    ")\n",
    "print(f\"{processing_instance_count.name} - {processing_instance_count.default_value}\")\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "print(f\"{processing_instance_type.name} - {processing_instance_type.default_value}\")\n",
    "\n",
    "# training step parameters\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", \n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "print(f\"{training_instance_type.name} - {training_instance_type.default_value}\")\n",
    "\n",
    "training_epochs = ParameterString(\n",
    "    name=\"TrainingEpochs\", \n",
    "    default_value=\"100\"\n",
    ")\n",
    "print(f\"{training_epochs.name} - {training_epochs.default_value}\")\n",
    "\n",
    "# model performance step parameters\n",
    "accuracy_mse_threshold = ParameterFloat(\n",
    "    name=\"AccuracyMseThreshold\", \n",
    "    default_value=0.75\n",
    ")\n",
    "print(f\"{accuracy_mse_threshold.name} - {accuracy_mse_threshold.default_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Processing Step for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocess.py\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import (\n",
    "        content_types,\n",
    "        encoders,\n",
    "        env,\n",
    "        modules,\n",
    "        transformer,\n",
    "        worker,\n",
    "        server,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "feature_columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "]\n",
    "label_column = \"medianHouseValue\"\n",
    "\n",
    "base_dir = \"/opt/ml/processing\"\n",
    "base_output_dir = \"/opt/ml/output/\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(f\"{base_dir}/input/raw_data_all.csv\")\n",
    "    feature_data = df.drop(label_column, axis=1, inplace=False)\n",
    "    label_data = df[label_column]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature_data, label_data, test_size=0.33)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    train_dataset = pd.concat([pd.DataFrame(x_train), y_train.reset_index(drop=True)], axis=1)\n",
    "    test_dataset = pd.concat([pd.DataFrame(x_test), y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    train_dataset.columns = feature_columns + [label_column]\n",
    "    test_dataset.columns = feature_columns + [label_column]\n",
    "\n",
    "    train_dataset.to_csv(f\"{base_dir}/train/train.csv\", header=True, index=False)\n",
    "    test_dataset.to_csv(f\"{base_dir}/test/test.csv\", header=True, index=False)\n",
    "    joblib.dump(scaler, \"model.joblib\")\n",
    "    with tarfile.open(f\"{base_dir}/scaler_model/model.tar.gz\", \"w:gz\") as tar_handle:\n",
    "        tar_handle.add(f\"model.joblib\")\n",
    "\n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "\n",
    "    We currently only take csv input. Since we need to process both labelled\n",
    "    and unlabelled data we first determine whether the label column is present\n",
    "    by looking at how many columns were provided.\n",
    "    \"\"\"\n",
    "    if content_type == \"text/csv\":\n",
    "        # Read the raw input data as CSV.\n",
    "        df = pd.read_csv(StringIO(input_data), header=None)\n",
    "\n",
    "        if len(df.columns) == len(feature_columns) + 1:\n",
    "            # This is a labelled example, includes the ring label\n",
    "            df.columns = feature_columns + [label_column]\n",
    "        elif len(df.columns) == len(feature_columns):\n",
    "            # This is an unlabelled example.\n",
    "            df.columns = feature_columns\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "\n",
    "    The default accept/content-type between containers for serial inference is JSON.\n",
    "    We also want to set the ContentType or mimetype as the same value as accept so the next\n",
    "    container can read the response payload correctly.\n",
    "    \"\"\"\n",
    "    if accept == \"application/json\":\n",
    "        instances = []\n",
    "        for row in prediction.tolist():\n",
    "            instances.append(row)\n",
    "        json_output = {\"instances\": instances}\n",
    "\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    elif accept == \"text/csv\":\n",
    "        return worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "    else:\n",
    "        raise RuntimeException(\"{} accept type is not supported by this script.\".format(accept))\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "\n",
    "    We implement this because the default predict_fn uses .predict(), but our model is a preprocessor\n",
    "    so we want to use .transform().\n",
    "\n",
    "    The output is returned in the following order:\n",
    "\n",
    "        rest of features either one hot encoded or standardized\n",
    "    \"\"\"\n",
    "    features = model.transform(input_data)\n",
    "\n",
    "    if label_column in input_data:\n",
    "        # Return the label (as the first column) and the set of features.\n",
    "        return np.insert(features, 0, input_data[label_column], axis=1)\n",
    "    else:\n",
    "        # Return only the set of features\n",
    "        return features\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted model\"\"\"\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SKLearnProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "\n",
    "sklearn_framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=sklearn_framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-housing-data-process\",\n",
    "    role=sagemaker_role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define step_process for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"scaler_model\", source=\"/opt/ml/processing/scaler_model\"),\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocess.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Training Step to Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/train.py\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "feature_columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "]\n",
    "label_column = \"medianHouseValue\"\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.1)\n",
    "\n",
    "    # data directories\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "\n",
    "    # model directory\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "def get_train_data(train_dir):\n",
    "    train_data = pd.read_csv(os.path.join(train_dir, \"train.csv\"))\n",
    "    x_train = train_data[feature_columns].to_numpy()\n",
    "    y_train = train_data[label_column].to_numpy()\n",
    "    print(\"x train\", x_train.shape, \"y train\", y_train.shape)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def get_test_data(test_dir):\n",
    "\n",
    "    test_data = pd.read_csv(os.path.join(test_dir, \"test.csv\"))\n",
    "    x_test = test_data[feature_columns].to_numpy()\n",
    "    y_test = test_data[label_column].to_numpy()\n",
    "    print(\"x test\", x_test.shape, \"y test\", y_test.shape)\n",
    "\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(8,))\n",
    "    hidden_1 = tf.keras.layers.Dense(8, activation=\"tanh\")(inputs)\n",
    "    hidden_2 = tf.keras.layers.Dense(4, activation=\"sigmoid\")(hidden_1)\n",
    "    outputs = tf.keras.layers.Dense(1)(hidden_2)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    args, _ = parse_args()\n",
    "\n",
    "    print(\"Training data location: {}\".format(args.train))\n",
    "    print(\"Test data location: {}\".format(args.test))\n",
    "    x_train, y_train = get_train_data(args.train)\n",
    "    x_test, y_test = get_test_data(args.test)\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    learning_rate = args.learning_rate\n",
    "    print(\n",
    "        \"batch_size = {}, epochs = {}, learning rate = {}\".format(batch_size, epochs, learning_rate)\n",
    "    )\n",
    "\n",
    "    model = get_model()\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    model.fit(\n",
    "        x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test)\n",
    "    )\n",
    "\n",
    "    # evaluate on test set\n",
    "    scores = model.evaluate(x_test, y_test, batch_size, verbose=2)\n",
    "    print(\"\\nTest MSE :\", scores)\n",
    "\n",
    "    # save model\n",
    "    model.save(args.sm_model_dir + \"/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define tensorflow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path:  s3://sagemaker-pipeline-practice/pipeline-model-example/model/\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "import time\n",
    "\n",
    "# Where to store the trained model\n",
    "model_path = f\"s3://{bucket_nm}/{prefix}/model/\"\n",
    "print(\"model path: \", model_path)\n",
    "\n",
    "hyperparameters = {\"epochs\": training_epochs}\n",
    "tensorflow_version = \"2.4.1\"\n",
    "python_version = \"py37\"\n",
    "\n",
    "tf2_estimator = TensorFlow(\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"train.py\",\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    framework_version=tensorflow_version,\n",
    "    role=sagemaker_role,\n",
    "    base_job_name=\"tensorflow-train-model\",\n",
    "    output_path=model_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    py_version=python_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define step_train_model for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tf2_estimator in a Sagemaker pipelines ProcessingStep.\n",
    "# NOTE how the input to the training job directly references the output of the previous step.\n",
    "step_train_model = TrainingStep(\n",
    "    name=\"TrainTensorflowModel\",\n",
    "    estimator=tf2_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Model Evaluation Step to Evaluate the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluate.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import tarfile\n",
    "\n",
    "\n",
    "feature_columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "]\n",
    "label_column = \"medianHouseValue\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path, \"r:gz\") as tar:\n",
    "        tar.extractall(\"./model\")\n",
    "    import tensorflow as tf\n",
    "\n",
    "    model = tf.keras.models.load_model(\"./model/1\")\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    df = pd.read_csv(test_path + \"/test.csv\")\n",
    "    x_test = df[feature_columns].to_numpy()\n",
    "    y_test = df[label_column].to_numpy()\n",
    "    scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "    print(\"\\nTest MSE :\", scores)\n",
    "\n",
    "    # Available metrics to add to model: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": scores, \"standard_deviation\": \"NaN\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluation docker image uri & evaluation model processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "tf_eval_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region_nm,\n",
    "    version=tensorflow_version,\n",
    "    image_scope=\"training\",\n",
    "    py_version=\"py37\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    role=sagemaker_role,\n",
    "    image_uri=tf_eval_image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define step_evaluate_model for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the evaluate_model_processor in a Sagemaker pipelines ProcessingStep.\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"EvaluateModelPerformance\",\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Register Model Step to Create a Model Package for the PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import PipelineModel\n",
    "\n",
    "\n",
    "# scaler model - preprocess\n",
    "scaler_model_s3 = \"{}/model.tar.gz\".format(\n",
    "    step_process.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "scaler_model = SKLearnModel(\n",
    "    model_data=scaler_model_s3,\n",
    "    role=sagemaker_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    entry_point=\"code/preprocess.py\",\n",
    "    framework_version=sklearn_framework_version,\n",
    ")\n",
    "\n",
    "# inference model using training model artifact\n",
    "tf_model_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region_nm,\n",
    "    version=tensorflow_version,\n",
    "    image_scope=\"inference\",\n",
    "    py_version=\"py37\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "tf_model = Model(\n",
    "    image_uri=tf_model_image_uri,\n",
    "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=sagemaker_role,\n",
    ")\n",
    "\n",
    "# A pipeline of SageMaker Model instances\n",
    "# This pipeline can be deployed as an Endpoint on SageMaker\n",
    "# Initialize a SageMaker Model instance\n",
    "pipeline_model = PipelineModel(\n",
    "    models=[scaler_model, tf_model], \n",
    "    role=sagemaker_role, \n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define step_register_pipeline_model for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "evaluation_s3_uri = \"{}/evaluation.json\".format(\n",
    "    step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=evaluation_s3_uri,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "step_register_pipeline_model = RegisterModel(\n",
    "    name=\"PipelineModel\",\n",
    "    model=pipeline_model,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    "    approval_status=model_approval_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Condition Step to Check Accuracy and Conditionally Register a Model in the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=accuracy_mse_threshold,\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=\"MSE-Lower-Than-Threshold-Condition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register_pipeline_model],  # step_register_model, step_register_scaler,\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Pipeline of Parameters, Steps and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        input_data,\n",
    "        model_approval_status,\n",
    "        training_epochs,\n",
    "        accuracy_mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train_model, step_evaluate_model, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.large'},\n",
       "  {'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.xlarge'},\n",
       "  {'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-pipeline-practice/pipeline-model-example/data/raw'},\n",
       "  {'Name': 'ModelApprovalStatus',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'Approved'},\n",
       "  {'Name': 'TrainingEpochs', 'Type': 'String', 'DefaultValue': '100'},\n",
       "  {'Name': 'AccuracyMseThreshold', 'Type': 'Float', 'DefaultValue': 0.75}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'PreprocessData',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocess.py']},\n",
       "    'RoleArn': 'arn:aws:iam::988889742134:role/service-role/AmazonSageMaker-ExecutionRole-20220315T092490',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/sklearn-housing-data-process-2022-04-14-12-46-23-111/input/code/preprocess.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'scaler_model',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/sklearn-housing-data-process-2022-04-14-12-40-06-316/output/scaler_model',\n",
       "        'LocalPath': '/opt/ml/processing/scaler_model',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/sklearn-housing-data-process-2022-04-14-12-40-06-316/output/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/sklearn-housing-data-process-2022-04-14-12-40-06-316/output/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'TrainTensorflowModel',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-training:2.4.1-cpu-py37',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-pipeline-practice/pipeline-model-example/model/'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'InstanceCount': 1,\n",
       "     'InstanceType': {'Get': 'Parameters.TrainingInstanceType'},\n",
       "     'VolumeSizeInGB': 30},\n",
       "    'RoleArn': 'arn:aws:iam::988889742134:role/service-role/AmazonSageMaker-ExecutionRole-20220315T092490',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'test'}],\n",
       "    'HyperParameters': {'epochs': {'Get': 'Parameters.TrainingEpochs'},\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-pipeline-practice/tensorflow-train-model-2022-04-14-12-46-23-212/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"train.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_job_name': '\"tensorflow-train-model-2022-04-14-12-46-23-212\"',\n",
       "     'sagemaker_region': '\"ap-northeast-2\"',\n",
       "     'model_dir': '\"s3://sagemaker-pipeline-practice/pipeline-model-example/model/tensorflow-train-model-2022-04-14-12-46-23-212/model\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-pipeline-practice/pipeline-model-example/model/',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1649940383',\n",
       "      'RuleEvaluatorImage': '578805364391.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "      'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-pipeline-practice/pipeline-model-example/model/'}}},\n",
       "  {'Name': 'EvaluateModelPerformance',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.TrainingInstanceType'},\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-training:2.4.1-cpu-py37',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::988889742134:role/service-role/AmazonSageMaker-ExecutionRole-20220315T092490',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.TrainTensorflowModel.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/tensorflow-training-2022-04-14-12-46-23-380/input/code/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/tensorflow-training-2022-04-14-12-43-47-918/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'MSE-Lower-Than-Threshold-Condition',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'LessThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.EvaluateModelPerformance.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'regression_metrics.mse.value'}},\n",
       "      'RightValue': {'Get': 'Parameters.AccuracyMseThreshold'}}],\n",
       "    'IfSteps': [{'Name': 'sklearnRepackModel',\n",
       "      'Type': 'Training',\n",
       "      'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "        'TrainingImage': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'},\n",
       "       'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-ap-northeast-2-988889742134/'},\n",
       "       'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "       'ResourceConfig': {'InstanceCount': 1,\n",
       "        'InstanceType': 'ml.m5.large',\n",
       "        'VolumeSizeInGB': 30},\n",
       "       'RoleArn': 'arn:aws:iam::988889742134:role/service-role/AmazonSageMaker-ExecutionRole-20220315T092490',\n",
       "       'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "           'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/sklearn-housing-data-process-2022-04-14-12-40-06-316/output/scaler_model',\n",
       "           'S3DataDistributionType': 'FullyReplicated'}},\n",
       "         'ChannelName': 'training'}],\n",
       "       'HyperParameters': {'inference_script': '\"preprocess.py\"',\n",
       "        'model_archive': '\"model.tar.gz\"',\n",
       "        'dependencies': 'null',\n",
       "        'source_dir': 'null',\n",
       "        'sagemaker_submit_directory': '\"s3://sagemaker-ap-northeast-2-988889742134/sagemaker-scikit-learn-2022-04-14-12-46-23-462/source/sourcedir.tar.gz\"',\n",
       "        'sagemaker_program': '\"_repack_model.py\"',\n",
       "        'sagemaker_container_log_level': '20',\n",
       "        'sagemaker_job_name': '\"sagemaker-scikit-learn-2022-04-14-12-46-23-462\"',\n",
       "        'sagemaker_region': '\"ap-northeast-2\"'},\n",
       "       'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-ap-northeast-2-988889742134/',\n",
       "        'CollectionConfigurations': []}}},\n",
       "     {'Name': 'PipelineModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'PipelineModelPackageGroup',\n",
       "       'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "          'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/tensorflow-training-2022-04-14-12-43-47-918/output/evaluation/evaluation.json'}},\n",
       "        'Bias': {},\n",
       "        'Explainability': {}},\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "          'Environment': {'SAGEMAKER_PROGRAM': 'preprocess.py',\n",
       "           'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sagemaker-ap-northeast-2-988889742134/sagemaker-scikit-learn-2022-04-14-12-43-48-276/sourcedir.tar.gz',\n",
       "           'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "           'SAGEMAKER_REGION': 'ap-northeast-2'},\n",
       "          'ModelDataUrl': {'Get': 'Steps.sklearnRepackModel.ModelArtifacts.S3ModelArtifacts'}},\n",
       "         {'Image': '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:2.4.1-cpu',\n",
       "          'Environment': {},\n",
       "          'ModelDataUrl': {'Get': 'Steps.TrainTensorflowModel.ModelArtifacts.S3ModelArtifacts'}}],\n",
       "        'SupportedContentTypes': ['text/csv'],\n",
       "        'SupportedResponseMIMETypes': ['text/csv'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large',\n",
       "         'ml.m5.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m5.xlarge']},\n",
       "       'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'}}}],\n",
       "    'ElseSteps': []}}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-northeast-2:988889742134:pipeline/trainingpipelineformodel',\n",
       " 'ResponseMetadata': {'RequestId': 'ea8474af-0624-4f5c-9368-fd124e082fb1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ea8474af-0624-4f5c-9368-fd124e082fb1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '97',\n",
       "   'date': 'Thu, 14 Apr 2022 12:47:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=sagemaker_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy latest approved model to a real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved packages:  [{'ModelPackageGroupName': 'PipelineModelPackageGroup', 'ModelPackageVersion': 2, 'ModelPackageArn': 'arn:aws:sagemaker:ap-northeast-2:988889742134:model-package/pipelinemodelpackagegroup/2', 'CreationTime': datetime.datetime(2022, 4, 14, 13, 5, 20, 770000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'Approved'}, {'ModelPackageGroupName': 'PipelineModelPackageGroup', 'ModelPackageVersion': 1, 'ModelPackageArn': 'arn:aws:sagemaker:ap-northeast-2:988889742134:model-package/pipelinemodelpackagegroup/1', 'CreationTime': datetime.datetime(2022, 4, 12, 2, 59, 3, 408000, tzinfo=tzlocal()), 'ModelPackageStatus': 'Completed', 'ModelApprovalStatus': 'Approved'}]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    SortBy=\"CreationTime\",\n",
    "    MaxResults=100\n",
    ")\n",
    "\n",
    "approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "print(\"Approved packages: \", approved_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import argparse\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def get_approved_package(model_package_group_name):\n",
    "    \"\"\"Gets the latest approved model package for a model package group.\n",
    "\n",
    "    Args:\n",
    "        model_package_group_name: The model package group name.\n",
    "\n",
    "    Returns:\n",
    "        The SageMaker Model Package ARN.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the latest approved model package\n",
    "        response = sm_client.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            MaxResults=100,\n",
    "        )\n",
    "        approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "        # Fetch more packages if none returned with continuation token\n",
    "        while len(approved_packages) == 0 and \"NextToken\" in response:\n",
    "            logger.debug(\"Getting more packages for token: {}\".format(response[\"NextToken\"]))\n",
    "            response = sm_client.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group_name,\n",
    "                ModelApprovalStatus=\"Approved\",\n",
    "                SortBy=\"CreationTime\",\n",
    "                MaxResults=100,\n",
    "                NextToken=response[\"NextToken\"],\n",
    "            )\n",
    "            approved_packages.extend(response[\"ModelPackageSummaryList\"])\n",
    "\n",
    "        # Return error if no packages found\n",
    "        if len(approved_packages) == 0:\n",
    "            error_message = (\n",
    "                f\"No approved ModelPackage found for ModelPackageGroup: {model_package_group_name}\"\n",
    "            )\n",
    "            logger.error(error_message)\n",
    "            raise Exception(error_message)\n",
    "\n",
    "        # Return the pmodel package arn\n",
    "        model_package_arn = approved_packages[0][\"ModelPackageArn\"]\n",
    "        logger.info(f\"Identified the latest approved model package: {model_package_arn}\")\n",
    "        return approved_packages[0]\n",
    "        # return model_package_arn\n",
    "    except ClientError as e:\n",
    "        error_message = e.response[\"Error\"][\"Message\"]\n",
    "        logger.error(error_message)\n",
    "        raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'PipelineModelPackageGroup',\n",
       " 'ModelPackageVersion': 2,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:ap-northeast-2:988889742134:model-package/pipelinemodelpackagegroup/2',\n",
       " 'CreationTime': datetime.datetime(2022, 4, 14, 13, 5, 20, 770000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "    'ImageDigest': 'sha256:1b1a557ceb336c12d1f8ade5f0cd79781a8df07dde3128544dfef6679feb261e',\n",
       "    'ModelDataUrl': 's3://sagemaker-ap-northeast-2-988889742134/pipelines-6d2jqq93h7sn-sklearnRepackModel-PYH9GtrZGW/output/model.tar.gz',\n",
       "    'Environment': {'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "     'SAGEMAKER_PROGRAM': 'preprocess.py',\n",
       "     'SAGEMAKER_REGION': 'ap-northeast-2',\n",
       "     'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sagemaker-ap-northeast-2-988889742134/sagemaker-scikit-learn-2022-04-14-12-43-48-276/sourcedir.tar.gz'}},\n",
       "   {'Image': '763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/tensorflow-inference:2.4.1-cpu',\n",
       "    'ImageDigest': 'sha256:82d4db66f767fd5dad7c2d9b44f7dc379a1f9c402dcc2f6dec8bc0d159d9d8c6',\n",
       "    'ModelDataUrl': 's3://sagemaker-pipeline-practice/pipeline-model-example/model/pipelines-6d2jqq93h7sn-TrainTensorflowModel-9fsGY43jBu/output/model.tar.gz',\n",
       "    'Environment': {}}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.xlarge'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large', 'ml.m5.xlarge'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'Approved',\n",
       " 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:ap-northeast-2:988889742134:pipeline/trainingpipelineformodel/execution/6d2jqq93h7sn'},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-ap-northeast-2-988889742134/tensorflow-training-2022-04-14-12-43-47-918/output/evaluation/evaluation.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'ResponseMetadata': {'RequestId': 'e321d269-6b9d-4d6b-96b3-56ba0b9ae402',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e321d269-6b9d-4d6b-96b3-56ba0b9ae402',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1955',\n",
       "   'date': 'Thu, 14 Apr 2022 13:37:26 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_approved_package\n",
    "\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "pck = get_approved_package(\n",
    "    model_package_group_name\n",
    ")\n",
    "\n",
    "model_description = sm_client.describe_model_package(\n",
    "    ModelPackageName=pck[\"ModelPackageArn\"]\n",
    ")\n",
    "\n",
    "model_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "\n",
    "model_package_arn = model_description[\"ModelPackageArn\"]\n",
    "\n",
    "model = ModelPackage(\n",
    "    role=sagemaker_role,\n",
    "    model_package_arn=model_package_arn,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint to deploy the model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName= DEMO-endpoint-2022-04-14-13-41-00\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"DEMO-endpoint-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"EndpointName= {}\".format(endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/raw/raw_data_all.csv\")\n",
    "house_values = data[\"medianHouseValue\"]\n",
    "data = data.drop(\"medianHouseValue\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
       "0    -122.23     37.88              41.0       880.0          129.0   \n",
       "1    -122.22     37.86              21.0      7099.0         1106.0   \n",
       "2    -122.24     37.85              52.0      1467.0          190.0   \n",
       "3    -122.25     37.85              52.0      1274.0          235.0   \n",
       "4    -122.25     37.85              52.0      1627.0          280.0   \n",
       "\n",
       "   population  households  medianIncome  \n",
       "0       322.0       126.0        8.3252  \n",
       "1      2401.0      1138.0        8.3014  \n",
       "2       496.0       177.0        7.2574  \n",
       "3       558.0       219.0        5.6431  \n",
       "4       565.0       259.0        3.8462  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count = 10\n",
    "payload = data.iloc[:pred_count].to_string(header=False, index=False).replace(\"  \", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-122.23,37.88,41.0, 880.0, 129.0, 322.0, 126.0,8.3252\\n-122.22,37.86,21.0,7099.0,1106.0,2401.0,1138.0,8.3014\\n-122.24,37.85,52.0,1467.0, 190.0, 496.0, 177.0,7.2574\\n-122.25,37.85,52.0,1274.0, 235.0, 558.0, 219.0,5.6431\\n-122.25,37.85,52.0,1627.0, 280.0, 565.0, 259.0,3.8462\\n-122.25,37.85,52.0, 919.0, 213.0, 413.0, 193.0,4.0368\\n-122.25,37.84,52.0,2535.0, 489.0,1094.0, 514.0,3.6591\\n-122.25,37.84,52.0,3104.0, 687.0,1157.0, 647.0,3.1200\\n-122.26,37.84,42.0,2555.0, 665.0,1206.0, 595.0,2.0804\\n-122.25,37.84,52.0,3549.0, 707.0,1551.0, 714.0,3.6912'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[0.820725203], [1.00937867], [0.807161331], [0.703612208], [0.518589854], [0.539785266], [0.561942577], [0.620703876], [0.43478477], [0.596874774]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "p = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(p.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \u001b[94m0.820725203\u001b[0m and Actual is: \u001b[94m0.9052\u001b[0m\n",
      "Predicted: \u001b[94m1.00937867\u001b[0m and Actual is: \u001b[94m0.7170000000000001\u001b[0m\n",
      "Predicted: \u001b[94m0.807161331\u001b[0m and Actual is: \u001b[94m0.7042\u001b[0m\n",
      "Predicted: \u001b[94m0.703612208\u001b[0m and Actual is: \u001b[94m0.6826\u001b[0m\n",
      "Predicted: \u001b[94m0.518589854\u001b[0m and Actual is: \u001b[94m0.6844\u001b[0m\n",
      "Predicted: \u001b[94m0.539785266\u001b[0m and Actual is: \u001b[94m0.5394\u001b[0m\n",
      "Predicted: \u001b[94m0.561942577\u001b[0m and Actual is: \u001b[94m0.5984\u001b[0m\n",
      "Predicted: \u001b[94m0.620703876\u001b[0m and Actual is: \u001b[94m0.4828\u001b[0m\n",
      "Predicted: \u001b[94m0.43478477\u001b[0m and Actual is: \u001b[94m0.4534\u001b[0m\n",
      "Predicted: \u001b[94m0.596874774\u001b[0m and Actual is: \u001b[94m0.5222\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "blue, stop = \"\\033[94m\", \"\\033[0m\"\n",
    "predictions = json.loads(p.decode(\"utf-8\"))[\"predictions\"]\n",
    "for i in range(pred_count):\n",
    "    print(\n",
    "        f\"Predicted: {blue}{predictions[i][0]}{stop} and Actual is: {blue}{house_values.iloc[i]}{stop}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:ap-northeast-2:988889742134:model-package/pipelinemodelpackagegroup/2\n",
      "arn:aws:sagemaker:ap-northeast-2:988889742134:model-package/pipelinemodelpackagegroup/1\n"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "for d in sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name\n",
    ")[\"ModelPackageSummaryList\"]:\n",
    "    print(d[\"ModelPackageArn\"])\n",
    "#     sm_client.delete_model_package(ModelPackageName=d[\"ModelPackageArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
